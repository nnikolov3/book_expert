
Transactional memory is a programming mechanism designed to simplify the development of concurrent software by allowing sequences of operations to execute as a single, indivisible unit. This means that either all the operations in a transaction succeed together, or none of them take effect if something goes wrong. The idea is similar to how transactions work in databases, where a set of changes is applied only if the entire set can be completed successfully.

One system that supports this concept is called Power TM. It introduces enhancements to the instruction set architecture of the processor, which allows certain blocks of code to run in a special transactional mode. This mode is different from normal, non-transactional execution because it isolates the effects of the code until the transaction is either committed or rolled back. A common pattern in transactional memory involves starting a transaction using an instruction like *tx begin*, followed by a series of operations that may include reading values from memory locations that are protected by locks.

If during the transaction, a condition arises that makes it unsafe to continue—such as the program realizing it does not hold a required lock—the transaction is aborted. This means all changes made during the transaction are discarded, and execution resumes from a safe point. On the other hand, if the transaction reaches a point where it is ready to complete, it uses an instruction like *tx commit*. If this commit condition is satisfied, the transaction’s changes are applied to memory, and any locks involved may be released as part of the commit process.

The idea of transactional memory was first formally proposed in a two thousand two doctoral thesis by Ravi Rajwar. His work laid the foundation for later implementations, including Intel's Transactional Synchronization Extensions, commonly known as TSX. TSX offered two main ways to use transactional memory: Hardware Lock Elision, or HLE, and Restricted Transactional Memory, or RTM. RTM gives developers the ability to explicitly tell the processor when to start a transaction, when to try to commit it, and when to cancel it. It also allows the software to check the current status of a transaction, which is useful for managing how the program responds to failures.

One technique used in transactional memory systems is called Lock Subscription. This method helps implement atomic blocks—sections of code that must run without interference from other threads. In this approach, a fallback transaction writes to a specific memory location, effectively subscribing to any changes that might affect it. If a hardware transaction is currently running, and the fallback transaction modifies a location that the hardware transaction has already read, the hardware transaction may be forced to abort. Similarly, if the hardware transaction tries to read a location that the fallback transaction has already updated, the hardware transaction may also be aborted to maintain consistency.

However, there are situations where this can lead to inconsistencies. For example, imagine a hardware transaction that reads two memory locations, X and Y, which are updated together in a coordinated way. If a fallback transaction modifies X after the hardware transaction has read Y but before it reads X again, the hardware transaction might commit with an inconsistent view of the data. This creates a race condition, where the outcome depends on the timing of the two transactions. The document also points out a potential issue with a technique called lazy subscription, where a hardware transaction might see inconsistent values or follow logically impossible paths if the hardware does not carefully isolate transactions from each other.

To illustrate how synchronization can be implemented in such systems, consider a ticket lock, which is a type of synchronization primitive. A ticket lock works like a queue system in a store: each thread that wants to enter a critical section gets a ticket number, and the lock keeps track of which ticket number is currently being served. The lock has two atomic integer variables: *next_ticket*, which starts at zero and keeps track of the next ticket to be issued, and *serving*, which also starts at zero and shows which ticket is currently being processed. There is also a constant called *base*, which is used in some way related to scheduling or timing.

When a thread wants to acquire the lock, it first gets its own ticket by atomically fetching and incrementing the *next_ticket* variable. Then, it enters a loop where it repeatedly checks the *serving* variable. The loop continues until the value of *serving* matches the thread's ticket number, which means it is now the thread's turn to proceed. To avoid using too much processor time while waiting, the thread executes a pause instruction, and the length of the pause is adjusted based on the difference between the base value and the thread's ticket number.

When the thread is done with the critical section and wants to release the lock, it first reads the current value of *serving*. Then, it tries to update this value by adding one, using a special operation called Compare-And-Swap, or CAS. This operation checks if the current value of *serving* is equal to the expected value, and if so, updates it. This is done using instructions tagged with *X Release*, which indicates that this is a release operation and ensures proper memory ordering.

Hardware Lock Elision, or HLE, is another optimization technique used in systems that support transactional memory. On older machines that do not support HLE, trying to run certain transactional instructions would result in an error. HLE solves this by allowing traditional lock instructions to be enhanced with special prefix bytes, called *X Acquire* and *X Release*, which enable the lock operations to behave as transactions when supported by the hardware, while still working as regular locks on older systems.

Hybrid transactional memory, or HTM, combines the strengths of hardware and software transactional memory. Hardware transactional memory can be very fast, but it has limitations, such as the number of operations it can handle or the size of the memory it can track. Software transactional memory is more flexible but can be slower. Hybrid systems aim to get the best of both worlds by using hardware to speed up the most performance-critical parts of transactions, while relying on software for more complex or less frequent operations.

There are different ways to build hybrid transactional memory systems. In some designs, the main logic of the transaction is handled in software, and hardware is used only to accelerate certain operations, like tracking memory changes or detecting conflicts. In other designs, the hardware manages most of the transaction, and software steps in only when the hardware can't handle something. For example, hardware might track which memory locations are being read and written, and software might handle what happens when two transactions try to modify the same location.

Studies of software transactional memory systems show that there is often a performance overhead when using atomic operations, sometimes making single-threaded operations three to ten times slower than normal. This overhead comes from several sources: detecting conflicts between transactions, storing temporary changes, checking that the data is consistent before committing, and resolving conflicts when they occur. These are all areas where hardware can help improve performance.

One way to reduce the overhead of conflict detection is to use special bits in the processor's cache, called mark bits. These bits can be set and checked by software to track which memory locations have been modified. When a cache line is no longer valid, the mark bits are automatically cleared. Another approach, proposed by Spear and colleagues, uses a system called alert-on-update, which notifies software when a memory location that is being tracked is accessed by another thread. This avoids the need for software to constantly check the status of memory locations.

Minh and colleagues proposed a different method using hardware-based signatures, such as Bloom filters, to track which memory locations are being read and written. Shriraman and colleagues suggested combining hardware buffers inside the cache with software-based conflict detection. This allows speculative changes to be stored in the cache, while software handles the detection and resolution of conflicts.

In later work, researchers added features like signatures and conflict summary tables, which allow hardware to detect conflicts more quickly, leaving software to handle only the resolution. This makes the system more flexible and efficient. Hill and colleagues pointed out that separating different aspects of transactional memory—like tracking memory access, buffering changes, and notifying software—makes the system more general and can be used for other purposes beyond transactional memory, such as debugging or memory management.

In hardware-assisted transactional memory, atomicity is a property that is enforced at the program level, even though it is built using multiple lower-level, non-atomic operations. Ideally, we would like to implement atomicity entirely in hardware for maximum speed. However, hardware transactions can sometimes fail for reasons unrelated to conflicts, such as running out of memory or encountering an unsupported operation. If falling back to a global lock is not acceptable, we need a more sophisticated fallback mechanism that works correctly with hardware transactions.

One approach is to design the hardware and software together, as proposed by Kumar and colleagues in two thousand six. Another approach, by Baugh and colleagues in two thousand eight, assumes that the hardware has fine-grained memory protection, which can be used to force hardware transactions to abort when they conflict with software transactions. However, a more common approach is to assume that the hardware is fixed and design the software to work with it.

A best-effort hybrid transactional memory system makes no guarantees that a transaction will complete, even if there are no conflicts, and does not assume anything about the software transactions that might be running at the same time. Most commercial hybrid transactional memory systems fall into this category. If hardware transactions often fail for no good reason, and falling back to a global lock is too slow, we need a way to ensure that hardware and software transactions do not interfere with each other in harmful ways.

One idea, proposed by Damron and colleagues in two thousand six, is to add extra instructions to hardware transactions so they can check and update metadata used by software transactions. This allows hardware transactions to detect conflicts with software transactions, but it adds overhead. Vallejo and colleagues in two thousand eleven reduced this overhead by moving some of the checking inside the transaction only when necessary. Tabba and colleagues in two thousand nine showed how to safely update objects in place when using software transactions that make copies of objects.

Lev and colleagues in two thousand seven suggested switching between hardware and software phases globally, so that only one type of transaction runs at a time. This can give good performance if software phases are rare, but it can also introduce delays when switching between phases. A more elegant solution, proposed by Dalessandro and colleagues in two thousand eleven, uses a software transactional memory algorithm called NOrec, which can detect hardware transactions without modifying the hardware transaction code. Hardware transactions must still check a global lock used by NOrec to ensure they abort if a software transaction is in the process of committing.

Matveev and Shavit in two thousand thirteen proposed a three-level system that avoids the need for special nontransactional instructions. In this system, most of the transaction is handled in software, using algorithms like TL2 or TinySTM to track memory reads and writes. Then, just before committing, a small hardware transaction is used to apply the changes. This reduces the chance of deterministic aborts in hardware. If the hardware transaction fails, the system falls back to a fully software-based path that prevents hardware transactions from running at the same time.

For transactional memory to be truly useful, it needs to be integrated into programming languages in a way that makes it easy and safe to use. While transactional memory can help build small, self-contained concurrent data structures without exposing it directly to programmers, its full potential lies in helping developers write correct and scalable parallel programs. This requires defining how transactions interact with other language features, especially memory models and synchronization primitives like locks.

Some operations, like interactive input or output, are not compatible with transactional memory because they cannot be rolled back. For example, you cannot undo a message that has already been printed to the screen or a command that has already been sent to a device. One way to handle this is to disallow such operations inside transactions, or to make transactions that perform them *inevitable*, meaning they are guaranteed to commit. However, inevitability can limit scalability because it prevents other transactions from running concurrently.

Researchers have debated how to define the behavior of transactions in the context of a language's memory model. Some argue that transactions should be treated like implicit locks, while others believe they should be defined alongside other synchronization primitives. The developers of the two thousand fourteen technical specification for transactional memory in C++ took the latter approach, defining transactions and locks together in a unified way. As of two thousand twenty-three, a simplified version of this specification is being considered for inclusion in the upcoming C++ twenty six standard.

While transactional memory is often promoted as a higher-level alternative to locks, there is a conceptual challenge in defining its behavior in terms of the very locks it is meant to replace. Any language that supports both transactions and locks must clearly explain how they interact. One promising idea is to define locks in terms of atomic blocks, reversing the traditional approach. In this model, a global order of transactions provides a natural synchronization order, which, when combined with the program's execution order, defines the overall *happens before* relationship in concurrent systems. This helps clarify how transactions and locks work together in complex, parallel programs.
