
In concurrent systems, fairness is a foundational principle that ensures reliable and predictable execution, especially in environments where multiple threads or processes are competing for shared resources. The core idea behind fairness is to prevent situations where certain threads are indefinitely postponed from executing, a condition known as starvation. Starvation occurs when a thread is perpetually denied the opportunity to proceed, even though it is eligible to run. To address this, different levels of fairness have been defined, each offering progressively stronger guarantees about how threads are scheduled and allowed to make progress.

One of the weaker forms of fairness is called weak fairness. It asserts that if a thread is continuously eligible to execute—meaning the conditions required for it to proceed remain true—then eventually, that thread will be given a chance to run. This does not mean the thread will run immediately, or even frequently, but that it will not be ignored forever. For example, imagine a thread that repeatedly checks whether a certain flag is set to true. If that flag remains true indefinitely, weak fairness ensures that the thread will not be completely overlooked, even if other threads are also eligible to run.

In contrast, strong fairness provides a stricter guarantee. It requires that if a thread becomes eligible to run infinitely often—meaning the conditions for its execution become true repeatedly over time—then the thread must eventually execute. This is a stronger condition than weak fairness because it applies even if the eligibility of the thread is not continuous, but only occurs intermittently. Strong fairness ensures that no opportunity for execution is missed indefinitely, even if those opportunities are fleeting or irregular.

To illustrate the difference between weak and strong fairness, consider a scenario involving two threads, thread one and thread two, and two atomic boolean variables, F and G. Both variables start as false. Thread one enters a loop that continues as long as the variable F evaluates to false under weak memory ordering. Inside this loop, thread one first sets the variable G to true using weak memory ordering, and then immediately sets G back to false using release memory ordering. Meanwhile, thread two waits until G becomes true. Once G is true, thread two sets F to true using the default memory ordering.

In this setup, weak fairness would ensure that thread one is not permanently ignored if F remains false. However, strong fairness would require that thread two eventually runs, even if the condition for it to run—G being true—only occurs intermittently. Achieving strong fairness in practice is challenging because it would require the scheduler to re-evaluate all waiting conditions every time any relevant variable changes. If the scheduler only considers a subset of waiting threads, it risks deterministically ignoring some threads indefinitely, even if they are eligible to run.

In most real-world systems, achieving strong fairness is not practical due to the complexity and overhead involved. Instead, systems often rely on statistical fairness, which uses randomization to reduce the probability of starvation to negligible levels. By randomly selecting a waiting thread whenever a scheduling decision is needed, the system ensures that no thread is systematically disadvantaged. While true randomness is difficult to achieve, pseudorandom techniques are often sufficient. For example, hardware interconnects and cache coherence protocols are designed to avoid consistently favoring one core over another in situations where multiple cores attempt to perform atomic operations simultaneously. Similarly, operating systems and runtime environments may introduce randomness in the timing of condition checks, using pseudorandom number generators or natural variations in execution time caused by modern processor architectures.

Statistical fairness does not eliminate the possibility of starvation entirely, but it makes it extremely unlikely. This approach often results in behavior that feels intuitively fair, even if it does not meet the strictest theoretical guarantees. For instance, a thread might occasionally be delayed, but over time, all threads receive a roughly proportional share of execution opportunities.

The theoretical foundations of fairness in concurrent systems were laid by Nissim Francez in the mid-1980s. His work introduced formal methods for reasoning about fairness using temporal logic, a branch of logic that deals with statements involving time and sequences of events. Temporal logic provides operators such as "always" and "eventually," which are essential for expressing properties like "a thread will eventually be scheduled" or "a certain condition will always hold." These logical tools are used to formally prove that concurrent systems behave fairly under specific scheduling policies.

Another important concept in concurrent programming is the Consensus Hierarchy, which was developed by Maurice Herlihy. This hierarchy classifies atomic operations based on their ability to solve the wait-free consensus problem. Wait-free consensus is a fundamental challenge in distributed and concurrent computing, where multiple threads must agree on a single value, even in the presence of failures or delays. The goal is for all non-faulty threads to eventually reach agreement, without any thread being indefinitely blocked or waiting.

Herlihy's work showed that different atomic operations have different levels of power when it comes to solving this problem. At the top of the hierarchy are universal atomic primitives, such as Compare And Swap, or C A S, and Load Link / Store Conditional, or L L / S C. These operations are considered universal because they can be used to implement any other atomic operation in a wait-free manner. More importantly, they can achieve wait-free consensus for an arbitrary number of threads, making them extremely powerful tools in concurrent programming.

In contrast, simpler operations like Test And Set, or T A S, have more limited capabilities. While they can solve the wait-free consensus problem for two threads, they cannot do so for more than two. This limitation means that T A S objects, even when used in large numbers, are not sufficient for building scalable concurrent systems that require coordination among many threads. Similarly, basic memory operations like ordinary loads and stores cannot achieve wait-free consensus at all, even for just two threads.

The Consensus Hierarchy defines an infinite progression of atomic objects, where each level corresponds to the maximum number of threads for which a given operation can guarantee wait-free consensus. Objects that support C A S or L L / S C are said to have consensus number infinity, meaning they can solve consensus for any number of threads. Objects like T A S, swap, and Fetch And Add, or F A A, have consensus number two, meaning they are only suitable for coordinating two threads. Intermediate levels of the hierarchy exist in theory, but they are rarely implemented in real hardware.

The behavior of concurrent systems is governed by their memory model, which defines how memory operations from different threads interact and become visible to one another. A key property of modern multicore systems is cache coherence, which ensures that all reads to a specific memory location eventually reflect the most recent write to that location, regardless of which core performed the write. However, cache coherence alone does not guarantee sequential consistency, which is a stronger property.

Sequential consistency requires that the result of any execution appears as if all operations from all threads were executed in some global order, and that each thread's operations appear in the same order as specified in its program. While this model is intuitive and easy to reason about, it is not always enforced by modern hardware, which often reorders memory operations to improve performance. This reordering can lead to situations where different threads observe memory operations in different orders, making it difficult to predict program behavior.

To manage this complexity, memory models define a partial order known as "happens-before," which captures the essential ordering guarantees between operations. The happens-before order is built from two fundamental principles: program order and synchronization order. Program order ensures that each thread's operations follow the sequence dictated by its code. Synchronization order, on the other hand, defines a global sequence for synchronizing operations, such as lock acquisitions and releases, which are used to coordinate between threads.

A related concept is the "synchronizes-with" order, which is a subset of synchronization order. It captures the relationships between specific synchronization operations, such as a release operation followed by an acquire operation on the same lock. The happens-before order is the transitive closure of program order and synchronizes-with order, meaning it includes all the ordering constraints implied by these two principles.

In addition to ordering guarantees, memory models must also define a "writes-seen" relation, which determines which writes a read operation may observe. This relation is crucial for understanding data races, which occur when two conflicting ordinary operations—such as two writes to the same variable—are not ordered by happens-before. Data races lead to non-deterministic behavior, making it difficult to reason about program correctness.

In a data-race-free program, the writes-seen relation is well-defined: all reads and writes to a given memory location are ordered by happens-before, and each read returns the value written by the most recent prior write in that order. This property ensures that all executions of a data-race-free program are sequentially consistent, providing a formal basis for building reliable concurrent systems.

The design of a memory model involves a careful balance between performance and programmability. On one hand, it must allow compilers and hardware to perform optimizations that improve performance, such as reordering instructions or caching values. On the other hand, it must provide enough guarantees to ensure that concurrent programs behave correctly. This balance is achieved by requiring programmers to explicitly specify where ordering constraints are necessary, while allowing maximum freedom for optimization elsewhere.

To enforce these constraints, memory models often use special instructions called memory fences or barriers. These instructions prevent certain types of reordering across synchronization points, ensuring that the program behaves as intended. In addition to hardware-level fences, software-level compiler fences are also used to prevent the compiler from reordering instructions in ways that could violate the memory model.

Ultimately, the memory model defines a contract between the hardware, the compiler, and the programmer. It ensures that programs can be written in a way that is both correct and efficient, by providing clear rules about how memory operations interact and what guarantees are provided. This contract is essential for building reliable concurrent systems in the modern multicore era, where performance and correctness must be carefully balanced.
