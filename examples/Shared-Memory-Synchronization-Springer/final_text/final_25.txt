
The design and analysis of nonblocking concurrent data structures, particularly queues and double-ended queues—often called deques—presents a challenging but essential area of study in computer science. These structures are built to allow multiple threads to operate simultaneously without relying on traditional locking mechanisms, which can cause delays or deadlocks when one thread becomes unresponsive. Instead, nonblocking algorithms ensure that the system as a whole continues to make progress, even if some threads are slow or stalled.

Let’s begin with queues. A queue is a data structure where elements are added at one end—called the tail—and removed from the other end—called the head. In a nonblocking queue, an enqueue operation involves two key steps: first, updating the next pointer of the previously enqueued node to point to the new node, and second, advancing the tail pointer to the new node. The moment when this operation becomes visible to other threads—its linearization point—comes only after both of these updates have been successfully completed. This ensures that the enqueue appears to happen atomically, as if it occurred at a single point in time, even though it involves multiple steps.

To maintain consistency during these updates, the code must carefully read both the tail pointer and the next pointer of the current tail node. Then, it re-reads the tail pointer to confirm that no other thread has changed it in the meantime. This double-checking helps prevent inconsistencies that could arise from concurrent access.

Now, for the dequeue operation, which removes an element from the head of the queue. This also requires careful coordination. After reading the head pointer, the code must check the head’s successor to ensure it is valid. If the head and tail pointers are not equal—meaning the queue is not empty—and the successor is valid, the dequeue can proceed. This is typically done using a Compare And Swap, or CAS, operation on the head pointer. The CAS checks whether the head still has its original value before updating it to point to the next node, effectively removing the first node from the queue.

One of the major challenges in implementing these structures is memory management. When a node is removed from the queue, it must not be immediately freed, because another thread might still be accessing it. To prevent this, techniques like hazard pointers or counted pointers are used. These mechanisms help track which nodes are currently in use by any thread, ensuring that memory is only reclaimed when it is safe to do so.

Moving on to deques—double-ended queues—these allow insertions and deletions at both ends, but not in the middle. While deques are less commonly used in sequential programming, they are highly valuable in concurrent systems. One of the earliest and most influential lock-free deque implementations was developed by Michael. His approach uses a three-step update mechanism for push and pop operations, which helps maintain consistency in a concurrent environment.

The Michael and Scott queue, a well-known lock-free queue, uses a two-step update mechanism. In this design, the second step can sometimes be assisted by another thread, which helps prevent stalls. In contrast, other lock-free deques, such as those proposed by Herlihy and Shavit, often use a three-step update process. This added complexity is necessary because deques must manage concurrent access to both the head and the tail, which introduces more potential for race conditions.

An important application of deques is in work-stealing schedulers. These are used in parallel computing environments where idle processors can "steal" tasks from busy ones. This helps balance the workload and improve overall system efficiency. In such systems, each worker thread typically has its own local deque of tasks. The thread pushes new tasks onto the right end of its deque and pops tasks from the right end when it needs to execute them. When a thread runs out of tasks, it attempts to steal from the left end of another thread’s deque. This design minimizes contention and improves data locality, as most operations are performed on the local deque.

Michael’s lock-free deque uses a special memory location—called an anchor—that holds both the head and tail pointers along with a two-bit status flag. This flag can have one of three values: STABLE, LPUSH, or RPUSH. These values indicate the current state of the deque and help manage concurrent operations. To safely manage memory and avoid the ABA problem—a situation where a pointer appears unchanged but the underlying data has been modified—the algorithm can be enhanced with hazard pointers or modified to use counted pointers. In some implementations, the pointers are stored as indices into a fixed-size pool of nodes, allowing them to fit within the anchor along with the status flag.

The deque’s behavior can be visualized through a series of states. For example, in state S zero, the deque is empty, and both the head and tail pointers are null. In state S one, there is a single node, and both pointers point to it. In states S two and beyond, there are two or more nodes, connected by left and right pointers. These states transition based on operations like push, pop, push_left, and push_right. Each transition must be carefully managed to ensure consistency, especially when multiple threads are involved.

For instance, when performing a push_right operation, the first step is to allocate a new node and initialize it with the value to be inserted and a left pointer to the previous tail node. Then, a Compare And Swap operation is used to update the anchor, changing the status flag and moving the tail pointer to the new node. A second CAS operation follows, which finalizes the state change by updating the status flag again and adjusting the conceptual tail to point to the second-to-rightmost node. If this second pointer is incorrect, it indicates that the deque is in an inconsistent state and needs further processing.

One limitation of Michael’s deque is that it requires the head and tail pointers to be stored together in a single word, or anchor. This limits the flexibility of the structure, as all operations must serialize access to this shared anchor. This means that even operations on opposite ends of the deque—like pushing to the head and popping from the tail—must wait for each other, which can reduce performance.

To address this, Herlihy and his colleagues introduced an obstruction-free deque that uses a fixed-length circular array instead of a linked list. In this design, the array contains a sequence of left nulls, data values, and right nulls. A push_right operation replaces the leftmost right null with a data value, while a pop_right operation reads the rightmost data value and replaces it with a right null. Similar operations exist for the left side of the deque.

To ensure correctness, each element in the array includes a count, and operations modify pairs of adjacent elements in a specific order. For example, a push_right operation identifies the index of the leftmost right null. If this is the last slot in the array, the deque is full. Otherwise, the operation performs two CAS operations: the first increments the count of the previous element, and the second replaces the current element with the new data value and an incremented count. A pop_right operation works in reverse, identifying the rightmost data value and performing a similar pair of CAS operations to remove it.

The key to linearizability in this design is that only the second CAS in each pair actually changes the content of the deque. The first CAS ensures that any concurrent operation will be detected. If either CAS fails, the operation can simply be restarted, as no substantive change has been made.

To make the array circular, a new dummy null value—called a D N—is introduced. This allows the deque to wrap around the array, supporting unbalanced operations where more pushes occur on one side than pops on the other. The structural invariant ensures that there are always at least two different kinds of null values present, maintaining the integrity of the deque.

Graichen and others later extended this idea by using a linked list of arrays instead of a single circular array. This allows the deque to grow or shrink dynamically, making it unbounded. The same two-CAS protocol used to manipulate data and dummy values in the array can also be used to manage pointers between arrays, enabling efficient expansion and contraction.

Finally, let’s revisit the concept of work-stealing queues. These are especially important in parallel programming, where each worker thread maintains its own deque of tasks. Push_right and pop_right operations are fast and unsynchronized, as they are performed only by the local thread. However, when a thread needs to steal a task, it performs a pop_left operation on another thread’s deque, which requires synchronization. This design minimizes contention and improves performance, as most operations are local and do not require coordination with other threads.

In summary, nonblocking concurrent data structures like queues and deques are essential for building high-performance, scalable systems. They rely on careful coordination of memory updates, use of atomic operations like Compare And Swap, and advanced memory management techniques to ensure correctness and efficiency in a concurrent environment. Whether used in lock-free queues, obstruction-free deques, or work-stealing schedulers, these structures enable modern software to fully leverage the power of parallel computing.
