
In concurrent systems, the concept of atomicity is rooted in the idea of sequential consistency. Sequential consistency ensures that all memory operations across multiple processing units appear to happen in a single, unified order, as though they were executed one after another. Within this global order, each thread or processing core must still follow the sequence dictated by its own program. This means that even though operations from different threads may interleave, the final outcome must be as if they all occurred in some specific order that respects each thread's original instruction sequence.

A key question arises when we consider high-level operations on concurrent objects: does sequential consistency make it easier to design these operations correctly? The answer is usually no, unless we use proper synchronization. Even with a sequentially consistent memory system, if threads are not explicitly coordinated, their concurrent modifications to shared data can lead to incorrect behavior. In fact, many modern systems use weaker memory models to improve performance, and rely on synchronization tools like locks or memory fences to enforce the necessary ordering and visibility of operations.

Designing high-level concurrent objects requires careful use of these synchronization tools, even in systems with strong memory guarantees. From the perspective of a memory architect, the goal is to create a memory model that makes it easier for software developers to reason about correctness. Similarly, a designer of concurrent objects aims to make high-level operations appear as if they happen all at once, without any observable intermediate states.

An operation is considered atomic if all of its internal steps—steps that may involve multiple memory accesses—appear to complete instantly and as a single, indivisible unit. This means that from the perspective of other threads, either all of the operation's effects are visible, or none are. There is no point in time where another thread can observe a partially completed operation. This "all or nothing" behavior is the essence of atomicity.

When a high-level operation behaves this way, it is said to execute atomically. This means that in any execution trace, the operation appears to occur as a single, indivisible step, consistent with the order of operations within each thread. Expanding on this, a concurrent object is considered sequentially consistent if, for every possible execution, the sequence of operations on that object can be rearranged into a hypothetical total order. This total order must preserve the original order of operations within each thread and must produce the same results as if the operations had actually occurred in that exact order.

However, a major challenge arises when we try to combine multiple high-level concurrent objects, even if each one individually satisfies sequential consistency. This is known as the problem of non-composability. Imagine a system where each memory access is like a method call on a large concurrent object—memory itself. Even if the system ensures that individual memory operations are sequentially consistent, this guarantee does not automatically extend to higher-level operations that combine multiple memory accesses.

For example, suppose we have two concurrent objects, A and B. Each has been proven to behave correctly when used in isolation. But when a program uses both A and B together, there is no guarantee that their combined operations will appear to occur in a single, unified order that respects the program order of each thread. This means that simply combining two correct components does not necessarily result in a correct composite system. This limitation led to the development of a stronger consistency model called linearizability.

Linearizability requires that each operation on a concurrent object appears to take effect at a unique, specific moment in time—somewhere between when the operation starts and when it finishes. This ensures that the system behaves as if all operations are executed one after another in a global total order. Importantly, this order must respect the real-time sequence of non-overlapping operations and preserve the order of operations within each thread. The requirement that operations appear to happen instantaneously is crucial—it prevents any thread from observing a partially completed operation.

For instance, in a shared counter, if different threads see different values for the counter at the same time, that violates linearizability. Similarly, if a thread performs a `put` operation but the change is not immediately visible to other threads, that also fails the linearizability condition. In parallel and distributed systems, there is no single, universal clock that defines the exact time of an event. What matters is the observable sequence of events. For an operation to be considered to happen at a single point in time, it must be impossible for one thread to see the operation as completed while another thread sees it as not yet started.

To help analyze whether a concurrent object is linearizable, we often identify a special moment in each operation's execution called the linearization point. This is the exact moment when the operation becomes globally visible and takes effect as a single, atomic action. If we can correctly assign these points, then we can say that one operation happens before another if its linearization point comes first.

In the simplest case, when a method is protected by a lock, the linearization point can be placed anywhere between acquiring the lock and releasing it. But in more complex algorithms that use fine-grained locking, determining the linearization point becomes more involved. It often corresponds to the moment when a specific lock is released after modifying a critical part of the object's state.

Ensuring correctness in concurrent systems is a major challenge, especially when many different thread interleavings are possible. Nonblocking algorithms are designed to allow the system to make progress even if one thread is delayed or stops. To prove that such algorithms are correct, we need a formal framework that accounts for all possible ways threads can interleave their operations. This often involves identifying a linearization point for each operation.

For example, in a nonblocking stack, a successful push or pop operation might become visible at the moment it performs a Compare And Swap instruction. An unsuccessful pop might become visible when it reads a value that indicates failure. In more complex algorithms, identifying these points can require checking runtime conditions or observing the behavior of other threads. The goal is to establish a total order of all operations that is consistent with the object's expected behavior when used in a single-threaded context.

The power of linearizability lies in its ability to show that, in any possible execution of a concurrent program, the operations appear to happen in a single, unified order that respects each thread's original sequence and any observable ordering. This property, sometimes called local linearizability, means that we can reason about the correctness of a composite system by analyzing the correctness of its individual components. This is a major advantage for building and verifying complex concurrent data structures.

One practical way to achieve linearizability is through a technique called Hand Over Hand Locking, also known as Lock Coupling. This is especially useful when working with dynamic data structures like a sorted, singly-linked list that supports operations such as insertion, deletion, and lookup. Without proper synchronization, concurrent modifications could corrupt the list's structure.

A global lock would ensure correctness by allowing only one thread to access the list at a time, but this would severely limit performance. Hand Over Hand Locking improves performance by allowing different threads to work on different parts of the list simultaneously. The key idea is that as a thread moves through the list, it acquires a lock on the next node before releasing the lock on the current node. This ensures that at any time, a thread holds at most two locks: one for the current node and one for the next node it plans to access or modify.

This careful pattern of acquiring and releasing locks ensures that the list remains structurally consistent. For example, if one thread is inserting a new node while another is removing a node, the Hand Over Hand protocol prevents the new node from being lost or disconnected. The inserting thread must hold locks on both the predecessor and successor nodes during the insertion, ensuring that no other thread can interfere with the chain of nodes being modified.

Similarly, the thread removing a node must acquire locks on both the node before and after the one it wants to remove. This locking discipline ensures that the list's structure remains intact during concurrent operations, providing the strong guarantee of linearizability. Any thread that wants to look up a node must also acquire the appropriate locks as it traverses the list, ensuring coordinated access.

This leads us to the broader concept of serializability, which is essential for ensuring correctness in systems that support transactional operations. The core idea is that a transaction must appear to complete as a single, indivisible unit, with all its effects becoming visible at once. This prevents other threads from seeing partial or inconsistent states.

Linearizability is a stronger model that builds on atomicity and applies to concurrent objects. It ensures that the order in which operations appear to happen is consistent with their real-time execution. If one operation finishes before another starts, then the effects of the first must be visible to the second. This provides a strong guarantee of real-time ordering for operations on individual objects.

However, linearizability for individual operations does not automatically extend to operations that involve multiple objects. This is especially important in transactional systems, where a single operation may affect several data items. A classic example is a banking system where one thread transfers money between two accounts, and another thread calculates the total balance.

Suppose both accounts start with five hundred dollars. The first thread transfers one hundred dollars from account A to account B, making A's balance four hundred and B's balance six hundred. The total system balance remains one thousand. The second thread reads A's balance and then B's balance. If it reads A's updated balance of four hundred but B's original balance of five hundred, it calculates a total of nine hundred, which is incorrect.

This inconsistency happens because the transfer is not treated as a single atomic operation, even though the individual operations on each account are linearizable. This shows the need for transactional atomicity or serializability at a higher level, covering multiple objects or operations. This often requires more advanced concurrency control techniques, such as two-phase locking or multi-version concurrency control.

Multi-object atomic operations are central to database systems, where they are called transactions. Transactional memory brings this idea to shared-memory parallel computing, allowing programmers to specify that a multi-object operation should execute as a single atomic unit. The simplest way to ensure correctness for transactions is serializability, which means that the transactions must have the same effect as if they were executed one at a time in some order.

For transactional memory, and sometimes for databases, we can require that the global order of transactions be consistent with the order of operations within each thread. Determining whether a set of transactions is serializable is computationally difficult, but in practice, we usually only need to ensure that the current execution is serializable. This can be done using conservative strategies.

A global lock would ensure serializability but would eliminate concurrency. Instead, databases and transactional memory systems use more sophisticated fine-grain locking or nonblocking techniques to allow parallel execution. However, implementing serializability with fine-grain locks introduces the risk of deadlock, where transactions wait indefinitely for each other to release resources.

To avoid deadlock, systems must detect and resolve such situations. This often involves releasing locks, rolling back partial transactions, and retrying conflicting operations. Some systems use an optimistic approach, allowing transactions to proceed even if they might conflict, and rolling them back only if a conflict actually occurs.

Lazy transactional memory systems take this further by deferring the commit decision until a transaction is ready to finish, allowing multiple transactions to run in parallel until one is ready to commit. At that point, any conflicting transactions are aborted and retried.

One example of a fine-grain locking technique for achieving serializability is Two-Phase Locking. In this protocol, a transaction goes through two phases: a growing phase, where it acquires all necessary locks but cannot release any, and a shrinking phase, where it releases locks but cannot acquire any new ones. This ensures that any concurrent execution of transactions following this protocol will be equivalent to some serial order, preserving data consistency.

For example, consider two transactions that both need to read and update two shared variables. Under Two-Phase Locking, each transaction acquires all the necessary locks during the growing phase. Once all locks are held, it performs its updates and releases the locks during the shrinking phase. This strict separation of lock acquisition and release ensures that the transactions can be ordered in a way that maintains consistency, even when they run concurrently.
