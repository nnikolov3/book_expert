
The discussion centers on the complexities of managing linked list operations in concurrent environments, particularly focusing on deletion and the challenges that arise when multiple threads interact with the same data structure. At the heart of this discussion is the issue of safely removing a node from a singly linked list while ensuring that other threads can continue to traverse the list without encountering inconsistencies or errors.

Imagine a linked list where each node contains a value and a pointer to the next node in the sequence. Now, suppose one thread is in the process of deleting a node containing the value twenty, and another thread is currently examining the node containing the value ten, which is the predecessor of twenty. The deletion operation involves updating the next pointer of the node containing ten so that it now points directly to the node after twenty, effectively removing twenty from the list.

However, complications arise when another operation, such as an insertion, occurs during this deletion process. For example, if a deletion is initiated in a scenario illustrated in a diagram labeled eight point three b, and then an insertion is attempted in a different scenario labeled eight point three a before the deletion is fully completed, the node containing twenty-five—which should be inserted after the node containing twenty—might mistakenly be linked to the wrong predecessor. This can happen because the node containing twenty has been logically removed but its pointer is still in use by other threads. If not handled carefully, this can lead to data loss or corruption.

To address this issue, a solution was developed based on an early algorithm for queues and later generalized to linked lists by a researcher named Harris. This solution introduces a two-step deletion process. The first step involves marking the node for deletion, often by modifying a bit in its next pointer. This marking serves as a signal to other threads that the node is in the process of being removed, but it is not yet physically disconnected from the list. The second step, which may not always be explicitly shown, involves the actual removal of the node once it is safe to do so. This two-step approach allows other threads to continue traversing the list past the marked node, preventing them from prematurely terminating or following an incorrect path.

In this model, the point at which a deletion becomes visible to other threads—known as the linearization point—occurs when the initial pointer-marking operation is successfully completed using a mechanism called compare-and-swap, or C A S. Similarly, insertions are linearized at the C A S operation that adds the new node to the list. However, this approach introduces a subtle but important problem known as the A B A problem.

The A B A problem occurs when a thread reads a value from a memory location, then another thread modifies that value to something else and then restores it back to the original value before the first thread performs its intended operation. In the context of linked lists, this can lead to a situation where a thread mistakenly believes it is operating on the original node, when in fact that node may have been deleted and its memory reused for a new node. This can result in incorrect behavior or data corruption.

Harris's original algorithm relied on the presence of a general-purpose garbage collection mechanism, such as reference counting, to safely reclaim memory from nodes that are no longer referenced. However, this requirement can be limiting in systems where garbage collection is not available or desirable. A refinement of Harris's algorithm, developed by Michael, addressed this limitation by introducing a technique that does not require garbage collection for correctness.

Michael's approach uses a concept known as counted pointers, which are pointers augmented with additional information—typically a version number or a counter—that helps track how many times the pointer has been modified. This allows threads to detect when a pointer has been changed and restored, thereby avoiding the A B A problem. Another key innovation in Michael's algorithm is the use of hazard pointers, which allow threads to safely traverse the list even when nodes are in a transitional deletion state, as long as they do not dereference marked pointers.

A double-width C A S operation is used to atomically update both the pointer and its associated counter. This ensures that even if a node is deleted and its memory is reused, the counter changes, making it impossible for another thread to confuse the new node with the old one. This mechanism provides a robust way to manage memory and synchronization in a concurrent environment.

The core of the Harris and Michael algorithm is a search routine that supports insert, delete, and lookup operations. This routine returns three important values: a reference to the predecessor of the target node, a reference to the current node being examined, and a reference to the node that follows the current node. These references are maintained using counted pointers, which include both the actual pointer and a synchronization counter. This structured return of information is essential for implementing atomic operations on the linked list.

The algorithm is implemented using a node structure that contains an atomic value and an atomic next pointer. The use of atomic types ensures that operations on these fields are indivisible and maintain memory consistency even when accessed by multiple threads. The list itself is managed by a class that holds an atomic pointer to the head of the list.

Each thread maintains its own set of private variables: a pointer to the previous node, a pointer to the current node, and a pointer to the next node. These variables are used to navigate the list during operations. The algorithm begins by initializing the previous pointer to point to the head of the list and the current pointer to the node pointed to by the head. It then enters a loop that continues as long as the current pointer is not null.

Inside the loop, the algorithm checks whether the end of the list has been reached and whether the current node's value is greater than the target value being searched for. If so, it means the target is not present in the list. A critical part of the algorithm involves using a C A S operation to update the previous pointer if it hasn't changed since it was last read. If the C A S operation fails, it indicates that the list has been modified by another thread, and the search must be restarted from the beginning.

If the C A S operation succeeds, the algorithm checks whether the next pointer is marked as deleted. If it is, the algorithm attempts to bypass the deleted node by updating the current node's next pointer to point directly to the node after the deleted one. If this operation fails due to concurrent modification, the search is restarted.

When the target value is found to be less than or equal to the current node's value, the algorithm determines whether it has found an exact match or the first node that satisfies the condition. In either case, the loop terminates, and the algorithm returns the appropriate result.

The correctness of this algorithm relies on the concept of linearizability, which ensures that concurrent operations on a data structure behave as if they were executed in some sequential order. For the Harris and Michael algorithm, insertions and deletions are linearized at their respective C A S operations. This means that the point at which an operation becomes visible to other threads is precisely when the C A S operation completes successfully.

One limitation of the Harris and Michael algorithm is that when a C A S operation fails, the entire search must be restarted from the head of the list. This can be inefficient, especially in highly concurrent environments. To address this, researchers Fomitchev and Ruppert introduced a modification that adds a back pointer to each node. This back pointer allows operations to continue from a known safe point rather than restarting from the beginning, improving performance.

Another variation, developed by Heller and colleagues, uses fine-grained locking for updates but allows searches to be wait-free, meaning they can complete in a bounded number of steps without waiting for other threads. This approach combines the benefits of both lock-based and lock-free designs.

The Michael and Scott queue, often referred to as the M and S queue, is a well-known example of a lock-free data structure that builds on these principles. It is implemented as a singly linked list with a dummy node at the head, which simplifies edge cases like empty or single-element queues. The queue maintains two atomic pointers: one to the head and one to the tail.

Enqueue operations involve adding a new node to the end of the list. A thread attempting to enqueue first allocates a new node and sets its value. It then reads the current tail pointer and attempts to link the new node to the end of the list using a C A S operation on the next pointer of the current tail node. If this succeeds, the thread attempts to update the tail pointer to point to the new node.

Dequeue operations involve removing a node from the front of the list. A thread reads the head and tail pointers, then reads the next pointer of the head node to find the first actual element. It then attempts to update the head pointer using a C A S operation to bypass the removed node. If this succeeds, the value of the removed node is returned.

The M and S queue ensures that even in the presence of concurrent operations, the queue remains consistent and progresses correctly. It uses the concept of linearization points to determine when operations take effect, ensuring that the queue behaves as if operations were executed in a sequential order.

A key challenge in implementing such a queue is managing memory safely. Because nodes cannot be immediately deallocated after removal, the queue uses counted pointers to track how many threads are referencing each node. Only when the count reaches zero is the node safely deallocated, preventing the A B A problem and ensuring memory safety.

In summary, the Harris and Michael algorithms, along with their refinements, provide a robust framework for implementing nonblocking linked lists and queues in concurrent environments. These algorithms use atomic operations, counted pointers, and careful synchronization to ensure correctness, efficiency, and safety in the face of concurrent access. They represent a significant advancement in the design of lock-free data structures, enabling high-performance, scalable systems that can handle complex concurrent workloads without the limitations of traditional locking mechanisms.
