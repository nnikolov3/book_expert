9.3 Challenges 209

as expert programmers use CAS and other atomic hardware instructions to build library-
level synchronization mechanisms and concurrent data structures, so might they use HTM
to improve performance “under the hood,” without directly impacting “ordinary” program-
mers. Much of the appeal of TM, however, is its potential to help those programmers write
parallel code that is both correct and scalable. To realize this potential, TM must be inte-
grated into language semantics and implementations. In this final section of the monograph,
we discuss some of the issues involved in this integration. Note that the discussion raises
more questions than it answers: 30 years after its original conception, language support for
TM is still a work in progress.

9.3.1 Semantics

The most basic open question for TM semantics is “what am I allowed to do inside?” Some
operations—interactive I/0 in particular—are incompatible with speculation. (We cannot
tell the human user “please forget I asked you that.”) Rollback of other operations—many
system calls among them—may be so difficult as to force a nonspeculative implementa-
tion. The two most obvious strategies for such irreversible (irrevocable) operations are to
(1) simply disallow them in transactions, or (2) force a transaction that performs them to
become inevitable—i.e., guaranteed to commit. While Spear et al. (2008b) have shown that
inevitability does not always necessitate mutual exclusion, it nonetheless imposes severe
constraints on scalability.

In its role as a synchronization mechanism, language-level TM must be integrated into the
language memory model (Sec. 3.3). Some researchers have argued that since locks already
form the basis of many memory models, the behavior of transactions should be defined in
terms of implicit locking (Menon et al. 2008). Others have suggested that transactions should
be defined along with locks and other synchronization primitives, in a co-equal fashion—all
varieties of synchronization will then contribute to a program’s ordering. This approach
was taken by the developers of the 2014 “technical specification” (draft feature set) for
transactional memory in C++ (Wong et al. 2015), based on an earlier proposal from Intel,
Oracle, IBM, and Red Hat (Adl-Tabatabai et al. 2012). As of 2023, a simpler version of that
specification (Boehm et al. 2021) is under consideration for inclusion in C++’26.

At the same time, given that TM is often promoted as a higher-level, more intuitive
alternative to locks, there 1s something conceptually unsatisfying about defining transactional
behavior in terms of (or even in concert with) the thing it is supposed to replace. Clearly
any language that allows transactions and locks in the same program must explain how
the two interact. Considering that locks are typically implemented using lower-level atomic
operations like CAS, a potentially appealing approach is to turn the tables, as it were, and
define locks in terms of atomic blocks (Dalessandro et al. 2010b). In the framework of
Sec. 3.3, a global total order on transactions provides a trivial synchronization order, which
combines with program order to yield the overall notion of happens-before. In the resulting
Nine point three Challenges. Two hundred nine. As expert programmers use C A S and other atomic hardware instructions to build library level synchronization mechanisms and concurrent data structures, so might they use H T M to improve performance, under the hood, without directly impacting ordinary programmers. Much of the appeal of T M, however, is its potential to help those programmers write parallel code that is both correct and scalable. To realize this potential, T M must be integrated into language semantics and implementations. In this final section of the monograph, we discuss some of the issues involved in this integration. Note that the discussion raises more questions than it answers: thirty years after its original conception, language support for T M is still a work in progress.

Nine point three point one Semantics. The most basic open question for T M semantics is what am I allowed to do inside? Some operations, interactive I O in particular, are incompatible with speculation. We cannot tell the human user please forget I asked you that. Rollback of other operations, many system calls among them, may be so difficult as to force a nonspeculative implementation. The two most obvious strategies for such irreversible, or unrevocable, operations are to simply disallow them in transactions, or force a transaction that performs them to become inevitable, I E, guaranteed to commit. While Spear et al. two thousand eight b have shown that inevitability does not always necessitate mutual exclusion, it nonetheless imposes severe constraints on scalability. In its role as a synchronization mechanism, language level T M must be integrated into the language memory model, see section three point three. Some researchers have argued that since locks already form the basis of many memory models, the behavior of transactions should be defined in terms of implicit locking, Menon et al. two thousand eight. Others have suggested that transactions should be defined along with locks and other synchronization primitives, in a co equal fashion, all varieties of synchronization will then contribute to a program's ordering. This approach was taken by the developers of the two thousand fourteen technical specification, draft feature set, for transactional memory in C plus plus, Wong et al. two thousand fifteen, based on an earlier proposal from Intel, Oracle, I B M, and Red Hat, Adl Tabatabai et al. two thousand twelve. As of two thousand twenty three, a simpler version of that specification, Boehm et al. two thousand twenty one, is under consideration for inclusion in C plus plus twenty six. At the same time, given that T M is often promoted as a higher level, more intuitive alternative to locks, there is something conceptually unsatisfying about defining transactional behavior in terms of, or even in concert with, the thing it is supposed to replace. Clearly any language that allows transactions and locks in the same program must explain how the two interact. Considering that locks are typically implemented using lower level atomic operations like C A S, a potentially appealing approach is to turn the tables, as it were, and define locks in terms of atomic blocks, Dalessandro et al. two thousand ten b. In the framework of section three point three, a global total order on transactions provides a trivial synchronization order, which combines with program order to yield the overall notion of happens before. In the resulting.
The text delves into the intricate challenges of integrating transactional memory, or TM, into programming paradigms, particularly concerning its semantics and the implications for concurrent systems. It begins by framing the discussion around expert programmers who leverage atomic hardware instructions, such as Compare And Swap, or C A S, and other atomic primitives to construct library level synchronization mechanisms and concurrent data structures. These programmers often operate "under the hood," abstracting away the low-level details to enhance performance in parallel code, aiming for correctness and scalability. The core appeal of TM, as presented, lies in its potential to simplify the development of such correct and scalable parallel applications by offering a higher-level abstraction for managing shared memory.

A significant challenge identified is the proper definition of TM semantics, specifically addressing what operations are permissible within a transaction. The text poses the fundamental question: "what am I allowed to do inside?" and highlights the incompatibility of certain operations, particularly interactive Input Output, or I O, with speculative execution within transactions. The difficulty arises because speculative operations, if they involve side effects like I O, might need to be rolled back, a process that can be complex or even impossible if the side effect is irreversible. The text notes that rollback of such operations could be so difficult as to necessitate non speculative implementations, effectively negating the benefits of speculation. Two primary strategies are proposed for handling these irreversible operations: either disallowing them entirely within transactions, thereby guaranteeing atomicity, or forcing a transaction to commit. However, the latter approach, forcing commit, carries its own risks, as it may lead to a state where the transaction cannot be undone even if it conflicts with other concurrent operations, thus guaranteeing it to commit.

The text further explores the relationship between TM and language memory models, positioning TM as a potential component of these models. Researchers suggest that transactions should be defined in a manner consistent with existing synchronization primitives like locks, perhaps in a co equal fashion. This integration aims to provide a unified framework for defining program behavior, particularly regarding ordering. The significance of this is underscored by the ongoing efforts to integrate transactional memory into mainstream computing. The 2014 "technical specification" for C++, a draft feature set, along with earlier proposals from companies like Intel and IBM, and a simpler version developed for C++'26, are cited as evidence of this trend. The work by Boehm et al. in 2021, which provides a specification for inclusion in C++, is mentioned as a key development.

A central difficulty in defining TM semantics revolves around its interaction with traditional synchronization mechanisms like locks. While TM is often promoted as a more intuitive and higher-level alternative to locks, the text points out the conceptual challenge of defining transactional behavior in the presence of locks. The question arises of whether locks should be defined in terms of transactions or vice versa, or if they should be treated as equivalent primitives. This becomes particularly relevant when considering how to combine transactional operations with locks to achieve predictable synchronization. A potential solution discussed involves defining locks using atomic blocks, a concept akin to atomic memory operations. This approach, referencing work by Dalessandro et al. in 2010b, suggests that by providing a global total order on transactions, a trivial synchronization order can be established, thereby yielding the overall notion of happens before. This mechanism ensures that the outcome of concurrent operations is deterministic and predictable, a crucial aspect for both correctness and performance in parallel systems. The text implicitly emphasizes the importance of a well-defined memory model that can accurately capture the ordering of events in a system employing both transactions and locks, as failing to do so can lead to subtle and difficult-to-diagnose concurrency bugs.
