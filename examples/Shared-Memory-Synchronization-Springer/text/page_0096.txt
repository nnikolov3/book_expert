5.3 Barrier Extensions 99

Figure 5.8 Dynamic modification of the arrival tree in an adaptive combining tree barrier.

of the children of the root. Any thread that finds a flipped flag on its way up the tree knows
that it can stop and flip flags in the children of that node during departure. Races among
threads take a bit of care to get right, but the code can be made to work. Unfortunately, the
last thread to call the arrive operation still requires €2 (log n) time to realize that the barrier
has been achieved.

To address this remaining issue, Gupta and Hill (1989) proposed an adaptive combining
tree, in which early-arriving threads dynamically modify the structure of the tree so that
late-arriving peers are closer to the root. With modest skew in arrival times, the last-arriving
thread realizes that the barrier has been achieved in constant time.

The code for this barrier is somewhat complex. The basic idea is illustrated in Figure 5.8.
It uses a binary tree. Each thread, in its arrive operation, starts at its (statically assigned)
leat and proceeds upward, stopping at the first node (say, w) that has not yet been visited
by any other thread. Having reached w through, say =n, it then modifies the tree so that w’s
other child, o, 1s one level closer to the root. Specifically, it changes o’s parent to be p (the
parent of w) and makes o a child of p. A thread that reaches p through w’s sibling, x, will
promote o another level, and a later-arriving thread, climbing through o, will traverse fewer
levels of the tree than it would have otherwise.

In their paper, Gupta and Hill (1989) present both standard and fuzzy versions of their
adaptive combining tree barrier. Unfortunately, both versions retain the remote spins of the
original (non-adaptive) combining tree. They also employ test_and_set locks to arbitrate
access to each tree node. To improve performance—yparticularly but not exclusively on NRC
NUMA machines—Scott and Mellor-Crummey (1994) present versions of the adaptive
combining tree barrier (both regular and fuzzy) that spin only on local locations and that
adapt the tree in a wait-free fashion, without the need for per-node locks. In the process they
also fix several subtle bugs in the earlier algorithms. Shavit and Zemach (2000) generalize
the notion of combining to support more general operations than simply “arrive at barrier”;
we will return to their work in Sec. 5.4.

Scott and Mellor-Crummey report mixed performance results for adaptive barriers: if
arrival times are skewed across threads, tree adaptation can make a significant difference,
both by reducing departure times in the wake of the last arrival and by making fuzzy intervals
compatible with a logarithmic critical path. If thread arrival times are very uniform, however,
the overhead of adaptation may yield a net loss in performance. As with many other tradeoffs,
the break-even point will vary with both the machine and workload.
Five point three Barrier Extensions.

Figure five point eight shows the dynamic modification of an arrival tree in an adaptive combining tree barrier. On the left side, an initial tree structure is depicted. It includes several nodes labeled p, w, o, n, and x, each with corresponding subtrees. A blue wavy line indicates a thread arriving at node n. From node n, a solid arrow points to node o, and a dashed arrow extends from node o towards node p, suggesting a conceptual shift or re-parenting. A large blue arrow points from this initial configuration to a modified tree structure on the right. In the modified tree, node n and its original subtree are no longer present as distinct entities from the first diagram. Instead, the subtree previously associated with n appears to have been integrated as a child of node o. This effectively promotes node o and its newly acquired child closer to the root, while the overall structural relationships with nodes p and x are maintained. This visual illustrates how the tree structure dynamically adapts in response to thread arrivals, as described in the accompanying text.

Any thread that finds a flipped flag on its way up the tree knows that it can stop and flip flags in the children of that node during departure. Races among threads take a bit of care to get right, but the code can be made to work. Unfortunately, the last thread to call the arrive operation still requires Omega open parenthesis log n close parenthesis time to realize that the barrier has been achieved.

To address this remaining issue, Gupta and Hill open parenthesis one nine eight nine close parenthesis proposed an adaptive combining tree, in which early arriving threads dynamically modify the structure of the tree so that late arriving peers are closer to the root. With modest skew in arrival times, the last arriving thread realizes that the barrier has been achieved in constant time.

The code for this barrier is somewhat complex. The basic idea is illustrated in Figure five point eight. It uses a binary tree. Each thread, in its arrive operation, starts at its statically assigned leaf and proceeds upward, stopping at the first node, say w, that has not yet been visited by any other thread. Having reached w through, say n, it then modifies the tree so that w's other child, o, is one level closer to the root. Specifically, it changes o's parent to be p, the parent of w, and makes o a child of p. A thread that reaches p through w's sibling, x, will promote o another level, and a later arriving thread, climbing through o, will traverse fewer levels of the tree than it would have otherwise.

In their paper, Gupta and Hill open parenthesis one nine eight nine close parenthesis present both standard and fuzzy versions of their adaptive combining tree barrier. Unfortunately, both versions retain the remote spins of the original non adaptive combining tree. They also employ test and set locks to arbitrate access to each tree node. To improve performance, particularly but not exclusively on N R C N U M A machines, Scott and Mellor Crummey open parenthesis one nine nine four close parenthesis present versions of the adaptive combining tree barrier, both regular and fuzzy, that spin only on local locations and that adapt the tree in a wait free fashion, without the need for per node locks. In the process they also fix several subtle bugs in the earlier algorithms. Shavit and Zemach open parenthesis two thousand close parenthesis generalize the notion of combining to support more general operations than simply arrive at barrier. We will return to their work in Section five point four.

Scott and Mellor Crummey report mixed performance results for adaptive barriers. If arrival times are skewed across threads, tree adaptation can make a significant difference, both by reducing departure times in the wake of the last arrival and by making fuzzy intervals compatible with a logarithmic critical path. If thread arrival times are very uniform, however, the overhead of adaptation may yield a net loss in performance. As with many other tradeoffs, the break even point will vary with both the machine and workload.
The page delves into advanced synchronization mechanisms within parallel computing, specifically focusing on extensions to barrier primitives, particularly the concept of adaptive combining tree barriers. Barriers are fundamental synchronization points in concurrent programming, ensuring that all participating threads reach a designated point in their execution before any thread is allowed to proceed further. This is critical for maintaining program correctness in parallel algorithms, for instance, when all threads must complete a phase of computation before the next phase, which might depend on the results of the previous, can begin.

The primary challenge with traditional barriers, especially on large-scale systems, is performance scalability. A naive barrier implementation involving a single global flag can become a serious bottleneck, as all threads contend for access to this single shared resource. This contention leads to serialization, where threads wait for their turn to update the flag, severely limiting parallelism. To mitigate this, combining tree barriers were introduced. In a combining tree barrier, threads arrive at the leaves of a binary tree and propagate their arrival upwards. Each internal node of the tree acts as a local synchronization point, combining arrivals from its children before signaling its own parent. The very last thread to arrive at the root node effectively signals the completion of the barrier for all threads. While this structure improves scalability by distributing contention across multiple nodes, the arrival operation still requires a time complexity proportional to the logarithm of the number of threads, specifically Omega of log `n`, where `n` is the number of threads. This logarithmic complexity arises because each thread must traverse a path from a leaf to the root of the tree.

A key limitation of static combining trees, however, is their rigid structure, which can lead to suboptimal performance when threads exhibit skewed arrival times. Early arriving threads may be forced to wait unnecessarily long if their path through the tree is blocked by a very late-arriving thread at a higher level. To address this, Gupta and Hill in nineteen eighty nine proposed an innovative solution: the adaptive combining tree barrier. The core principle behind this adaptation is to dynamically reconfigure the tree structure during execution, specifically to bring late arriving peers closer to the root. This dynamic modification aims to reduce the critical path length for the last arriving thread, thereby accelerating the overall barrier release.

Figure five point eight visually illustrates a dynamic modification within such an adaptive combining tree. On the left side, we observe an initial tree segment involving nodes `p`, `w`, `o`, `n`, and `x`. Node `p` is the parent of `w` and `x`. Node `w` is the parent of `o` and `n`. A thread associated with node `n` is shown as a late-arriving entity, indicated by the wavy blue arrow. The dashed line from `p` to `o` signifies the original parent child relationship that `o` might have had, implicitly through `w`. The solid arrow from `w` to `o` explicitly states `o` is `w`'s child. The transformation, represented by the large cyan arrow pointing right, shows the altered tree structure. In the new configuration on the right, node `o` is no longer a child of `w`. Instead, `o` has been promoted to become a direct child of `p`, appearing as a sibling to `x`. This structural change implies that the branch involving `w` and `n` has been effectively pruned or re-rooted elsewhere to allow `o` to bypass `w` and `n`'s potential delay. The underlying mechanism is that a thread, during its upward traversal from a leaf, stops at the first node, say `w`, that has not yet been visited by any other thread in its current arrival wave. Upon reaching `w` through its child `n`, the system then modifies the tree such that `w`'s other child, `o`, becomes one level closer to the root. Specifically, `o`'s parent changes from `w` to `p`, the original parent of `w`. This allows `o`, and by extension the threads arriving through its subtree, to traverse fewer levels to reach the root, thereby reducing overall synchronization latency. A thread climbing through `o` will consequently encounter a shorter path than it would have otherwise, assuming `o` was indeed a child of `w` on a longer path.

The paper by Gupta and Hill presented both standard and fuzzy versions of their adaptive combining tree barrier. Fuzzy barriers introduce a bounded interval during which threads may depart, rather than requiring strict simultaneous release. This can improve throughput by allowing threads to proceed slightly out of lockstep. Both versions, however, retained the remote spins of the original non adaptive combining tree. To resolve potential contention and ensure atomicity during tree modifications, they employed `test_and_set` locks. A `test_and_set` operation is a fundamental atomic read-modify-write primitive crucial for implementing locks and other synchronization structures. It atomically checks the value of a memory location and, if certain conditions are met, sets it to a new value, returning the old value. This prevents race conditions during tree modifications.

Further advancements in this domain include the work by Scott and Mellor Crummey in nineteen ninety four, who presented versions of the adaptive combining tree barrier specifically optimized for `N U M A` or Non Uniform Memory Access machines. On `N U M A` architectures, memory access times vary significantly based on whether the memory is local to the processor or located in a remote node. To enhance performance on such systems, their approach emphasizes spinning on local locations, thereby avoiding the high latency associated with remote memory access when threads are waiting. They also designed their adaptive tree in a wait free fashion, a strong property in concurrent computing guaranteeing that every operation completes in a finite number of steps, regardless of the execution speed or failures of other threads. This eliminates the need for per node locks, simplifying the implementation and improving robustness. Their work also addressed and fixed several subtle bugs present in earlier barrier algorithms. Shavit and Zemach in two thousand further generalized the notion of combining to support more complex operations beyond simple "arrive at barrier" functionality, allowing for richer forms of collective operations.

While adaptive barriers offer significant advantages, particularly when thread arrival times are skewed, their performance benefits are not universal. Scott and Mellor Crummey reported mixed results, indicating that the tree adaptation process, although designed to reduce departure times for early arrivals and manage fuzzy intervals for later ones, introduces its own overhead. If thread arrival times are already very uniform, the overhead incurred by dynamically modifying the tree structure may lead to a net loss in performance compared to a static barrier. This highlights a crucial trade off: the complexity and computational cost of adaptation must be justified by the benefits it provides in specific workload and machine architectures. The break even point, where the benefits of adaptation outweigh its costs, is highly dependent on both the underlying hardware and the characteristics of the parallel workload.
