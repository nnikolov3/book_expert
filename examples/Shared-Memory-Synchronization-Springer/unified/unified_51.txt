The discussion revolves around advanced techniques for achieving nonblocking data structures, specifically focusing on hash tables and skip lists, in the context of concurrent programming. One approach to enhancing hash table performance involves rehashing for high load factors by requiring inserts to reorganize keys in a way that reduces probing. This is achieved through a multi-location compare-and-swap operation, as described in Section eight point ten, which allows for the atomic shifting of a sequence of keys to different buckets.

Another strategy is the use of a wait-free resizable hash table, attributed to Fatourou et al., which relies on a powerful wait-free universal construction. This construction enables the transformation of a sequential object into a concurrent one, allowing each bucket of the hash table to be accessed independently as long as resizing is not needed. The universal construction also facilitates table resizing while synchronizing accesses to buckets to ensure linearizability.

An alternative approach to resizing involves storing the hash table buckets at the leaves of a trie, as proposed by Prokopec et al. This method allows individual buckets to be expanded or contracted dynamically by splitting or joining nodes. Although this might increase lookup times due to the need to traverse the tree, the authors demonstrate that the expected time to locate buckets or nearby nodes can remain constant by caching pointers to buckets at various levels of the tree.

The conversation then shifts to skip lists, introduced as an alternative to balanced trees for implementing sets and dictionaries with O logarithm n search time complexity. Skip lists are notoriously difficult to parallelize using traditional locking mechanisms but can be implemented in a nonblocking fashion. A skip list, conceptualized by Pugh in nineteen ninety, is a probabilistic data structure that uses random decisions to achieve expected logarithmic time complexity for operations.

While conceptually complex, skip lists are considered substantially simpler than nonblocking trees. The fundamental structure of a skip list involves nodes appearing on multiple levels, with each node present in a skip list appearing on a single, sorted, level zero list. With a given probability, typically one half, a node also appears on a level one list. More generally, a node on a level i list appears on a level i plus one list with probability p. All nodes with a given key are linked together, forming a tower. Searching in a skip list commences by traversing the highest level list and then descending through the towers to lower levels, effectively skipping over many nodes until the target key or the appropriate insertion point is found.

Recent developments have improved various properties of skip lists. For instance, Dick et al. replaced towers with wheels that contain many keys, enhancing memory locality and enabling more efficient searches by shrinking the list height. Crain et al. introduced background threads to lazily construct these towers, potentially improving insertion speed at the cost of search performance until the background thread completes. Daly et al. presented a practical skip list implementation called N U M A S K, designed for systems with multiple processor sockets, where the bottom level of the skip list is replicated across sockets to reduce inter-socket communication. Aksenov et al. introduced a distribution-aware skip list, termed a splay list, which dynamically moves frequently accessed keys to the top of the list for faster access.

The text then delves into search trees, questioning why a skip list might be preferred over a search tree for certain operations. The primary reason cited is the lack of known efficient lock-free algorithms for search trees. This is in contrast to the advancements in lock-free linked list designs, which emerged in the mid-nineties. The development of efficient lock-free binary search trees lagged significantly, suggesting inherent complexities in achieving lock-freedom for tree structures compared to linear ones.

The section on the EFRB tree further elaborates on the challenges of binary search trees, especially in concurrent settings. It notes that even though lock-free linked list designs existed as early as nineteen ninety-five, it took fifteen years for comparable binary search tree implementations to appear. This implies that the algorithms for maintaining the search tree property in a concurrent, lock-free manner are considerably more intricate.

Two specific challenges are presented for binary search trees that do not typically manifest in lists. The first is the complexity of deleting a node with two children in a traditional, internal or node-oriented binary search tree. While deleting a leaf or a node with one child is straightforward, deleting a node with two children requires finding its in-order successor, swapping keys, and then deleting the successor. In a multithreaded, lock-free environment, atomically performing these steps is particularly challenging.

The second challenge arises because a binary search tree node has two child pointers. Marking a single pointer, as in the Harris and Michael list, is not sufficient to prevent a node from being erroneously modified by a compare-and-swap operation after it has been deleted. This is because marking only one child pointer would still allow the other to be changed.

To overcome these challenges, the concept of external trees is introduced, as proposed by Ellen et al. In this model, the tree is structured as a leaf-oriented or external binary search tree, where each key is logically present in a leaf node. Internal nodes, while also containing keys, function primarily as routing nodes, directing searches to the appropriate leaf. This simplification is significant because deletions in an external binary search tree are streamlined, as a key to be deleted is always located in a leaf.

The sequential algorithms for insertion and deletion in an external binary search tree are illustrated in Figure eight point thirteen. A successful insertion involves adding a new leaf node and a new routing node, with the new routing node holding a duplicate of the inserted key, and the new leaf containing the key itself. For deletions, a successful delete operation removes both the leaf and its associated routing node. The search tree property is slightly relaxed in this model: a node's left subtree contains keys that are strictly smaller than the node's key, while its right subtree contains keys that are greater than or equal to the node's key.

Consequently, the number of nodes in an external binary search tree is at most twice that of an equivalent internal binary search tree containing the same keys. The text further elaborates on lock-free locking, a technique to overcome the second challenge of concurrent binary search tree operations, which involves managing the pointers of a node slated for deletion. In this approach, each node possesses a dedicated update field that functions similarly to a sorted list or a linked list of updates, allowing threads to atomically append their intended modifications.

Crucially, these lock-free locks enable threads to gain exclusive access to the operation itself, rather than locking the node for an extended period. This mechanism ensures that updates are applied in a controlled and non-blocking manner, preventing the data races that would occur with traditional locking mechanisms when multiple threads attempt to modify the same node concurrently. Figure eight point twelve illustrates a critical concurrency issue in binary search trees, specifically when atomic operations are not properly handled.

The scenario depicts thread T one attempting to search for the key sixty, while concurrently, thread T two is executing a delete operation on the key seventy. Initially, the tree consists of nodes with keys forty, fifty, sixty, and eighty. In panel (a), thread T one has begun its search, reaching the node with key fifty, and then proceeds to the node with key sixty, where it pauses. Subsequently, in panel (b), thread T two initiates a delete operation on key seventy. This operation involves swapping the keys sixty and seventy, effectively relocating the key sixty.

After this swap, T two completes the deletion of seventy. In panel (c), thread T one resumes its search from the node with key fifty. However, due to T two's modification, the structure has changed. T one's search path, which would have naturally led to the node with key sixty, is now disrupted. When T one eventually examines the node that previously held sixty, it might now contain a different value, or the node itself might have been removed or restructured. The consequence highlighted is that thread T one returns an incorrect answer for its search, demonstrating how a lack of atomicity in the delete operation can lead to data races and corrupted search results.

Figure eight point thirteen demonstrates sequential operations on an external binary search tree, where changes to nodes are visually indicated by gray highlighting. The diagrams illustrate the step-by-step evolution of the external binary search tree under common tree operations, such as insertion and deletion. The text concludes by emphasizing the importance of careful synchronization mechanisms in concurrent binary search tree implementations to prevent data races and ensure correct operation.
