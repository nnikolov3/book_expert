To build some intuitive understanding of why this lookup algorithm is linearizable, consider the following scenario. Suppose a lookup operation, which we can refer to as lookup of key, finds a leaf containing the key and returns true. If that leaf is in the tree when the lookup operation reads its key, then the lookup operation can be linearized at that read. However, the leaf might have been deleted by the time the lookup operation reads its key. In this case, note that the leaf was in the tree at some point during the lookup operation, otherwise it could not have been found. Since a node's key is never changed, the key read by the lookup operation is the same key that was in the leaf when the leaf was last in the tree, and the lookup operation can be linearized at that time.

On the other hand, if the lookup operation does not find the key, we need to argue that it is correct to return false. This is where the difference between internal and external binary search trees becomes clear. In an internal binary search tree, a lookup operation could miss the key it is looking for, even though that key is present in the tree throughout the entire lookup operation, because that key is swapped to a higher location in the tree. In an external binary search tree, no such swap can occur. If a key is present in the tree throughout an entire lookup operation, then the lookup operation will find the leaf that contains it. On the other hand, if a key is present for part of a lookup operation and is deleted during the lookup operation, we can linearize a return value of false just after the key is deleted.

To perform an insert operation, a thread first searches the tree for the key to determine the leaf, target, where the key should be inserted, as well as the parent of that leaf. This search is similar to the lookup operation, but before reading a node's child pointer, its update field is read. Let parent update be the value read from the update field of the parent during the search. This value will be used as the expected value of a compare and swap operation if and when the insert operation attempts to lock the parent. By remembering parent update, we will be able to detect any changes to the parent between the search and a subsequent lock attempt.

If the search finds the key in the tree already, the insert operation returns false and is linearized as a lookup operation. Suppose, then, that the search does not find the key. In this case, the thread would like to lock the parent so it can insert the key. Locking the parent involves creating a new descriptor and storing it in the parent's update field, and we would like to avoid the overhead of allocating that object if the parent is already locked. So, if the parent is already locked by another operation, then the thread helps that operation to complete, by using the information encoded in that operation's descriptor, and then restarts its own operation from the beginning.

If the parent is not already locked, either initially or after helping and restarting, the insert operation uses a compare and swap operation to try to lock the parent by changing the parent's update field from parent update to a new state. If the compare and swap operation fails, the insert operation restarts from the beginning. If the compare and swap operation succeeds, successfully locking the parent, then the parent has not changed since its contents were read during the search. Briefly, this is because modifying the parent would have required locking it, changing the contents of the parent's update field to point to a different descriptor, and ensuring that the compare and swap operation would fail.

When the insert operation restarts, it can either free or reuse the insert flag descriptor that it allocated, since the compare and swap failure means no other thread can have a pointer to that descriptor. The text discusses the nuances of linearizable nonblocking algorithms, specifically focusing on the behavior of lookup and insert operations within a data structure, likely a binary search tree or a similar ordered structure. Linearizability is a strong correctness condition for concurrent objects, requiring that each operation appears to execute atomically at some point between its invocation and its response.

Consider a lookup operation on a data structure. If a lookup operation successfully finds a key, and that key is contained within a leaf node, then the lookup operation can be linearized to the point in time when it reads the key. However, if the leaf containing the key is deleted by another thread after the lookup has read the key but before the lookup operation completes its linearization, a potential issue arises. In such a scenario, the lookup would still return true, which is consistent with the key having been present at some point. The critical aspect here is the timing of the read relative to the deletion. If the lookup reads the key from a node that is then modified or removed, and the lookup is linearized to the time of the read, this maintains consistency with the state of the data structure at that linearized instant.

The discussion then contrasts this with a situation where a lookup fails to find a key. In the context of an internal binary search tree node, if the node's key is swapped to a higher position in the tree, a common optimization in certain tree implementations, a lookup might miss the key. This is because the key's logical position relative to its descendants might change. However, if the data structure is an external binary search tree, meaning leaves represent the actual data values and internal nodes guide the search, such key swaps do not occur. In an external binary search tree, if a key is present for part of the lookup operation but is deleted during that operation, the lookup may incorrectly return false if the deletion happens before the lookup reaches the relevant leaf. Alternatively, if the key is present and the lookup completes successfully, but the key is deleted immediately after, the lookup can still be linearized to a point where the key was present.

The text then delves into the insert operation. To perform an insert, a thread first searches for the key's position. This search is similar to a lookup. The crucial aspect for linearization is often an update field associated with nodes, potentially storing version information or a pointer to a descriptor. Before reading this update field, the thread needs to capture its current value, referred to as parent update. This captured value serves as the expected value for a compare and swap operation. The insert operation then attempts to lock the parent node. This locking typically involves creating a new descriptor and attempting to atomically update the parent's update field to point to this new descriptor, using a compare and swap operation. This compare and swap operation effectively reserves the insertion spot and marks the parent as being in the process of modification.

If the parent node has not been modified since the parent update was read, meaning its update field still holds the parent update value, the compare and swap operation succeeds, signifying that the parent has been successfully locked. The thread then proceeds with the insertion, often by creating a new node and linking it appropriately, and then updates the parent's update field to point to this new node, effectively completing the insertion and committing the change.

However, if the parent node has been modified by another thread between the reading of parent update and the compare and swap attempt, the compare and swap operation will fail. This failure indicates a conflict. The parent update field would likely have been modified by another operation, perhaps an operation which could be a delete or another insert. In such a failure scenario, the thread must restart its operation. The reason for this restart is that the state of the data structure has changed in a way that invalidates the assumptions made during the initial search and the parent update read. The thread would re-read the parent's update field and retry the locking process.

The text highlights a specific scenario: if the parent is already locked, perhaps by another concurrent operation, and the current thread's compare and swap to lock it fails, it means another operation has already claimed responsibility for modifying this parent node. If the thread that is attempting to insert finds that the parent is already locked and it cannot acquire the lock, it might assist the ongoing operation. This assistance could involve completing the operation that is currently holding the lock, thereby helping to maintain progress and eventual consistency. After assisting, the thread would then restart its own operation.

A critical detail is what happens if a parent is not already locked but the thread attempting to insert needs to lock it. The insert operation uses a compare and swap to attempt to change the parent's update field from parent update to a value representing the new state. If this compare and swap succeeds, it means the parent has been successfully locked. If the compare and swap fails, it implies that the parent's state changed since parent update was read, meaning another operation modified it. The thread then restarts its operation. The explanation provided indicates that when an insert restarts due to a compare and swap failure, the compare and swap failure implies that the parent's state has changed. This change could be due to a deletion or another modification. The insert operation would then need to re-evaluate its position and potential actions. It is noted that a compare and swap failure means no other thread can have a pointer to the descriptor that the failed compare and swap attempted to allocate. This is because if the compare and swap failed, the parent's update field was not updated to point to this new descriptor, and thus, this descriptor was not incorporated into the data structure's linearization. It can either be freed or potentially reused in a subsequent attempt.

The algorithm for a delete operation begins much as the insert operation. It first searches for the key to determine the target, parent, and also grandparent nodes. Let parent update and grandparent update be the values read from the update fields of the parent and grandparent, respectively, during the search. If the search does not find the key, the delete operation returns false and is linearized as a lookup operation, returning true. Suppose, then, that the search does find the key. In this case, the thread would like to lock the grandparent and parent, and replace the parent and target with the sibling of the target, removing the parent and target from the tree. If the grandparent or parent are already locked by another operation, the thread helps that operation, then restarts its own delete. Otherwise, the thread proceeds as in the described figure.

The steps are similar to those in the insert operation, except here two nodes are locked. The first is locked with state DFlag in step c; the second is locked with state Mark in step d, since it is being removed from the tree. There is no need to lock, or Mark, the leaf target that is being removed, since leaves cannot be changed. If the compare and swap operation in step c fails, the delete operation restarts from the beginning. If the compare and swap operation in step d fails, the delete operation performs a compare and swap to try to unlock the grandparent by changing its update field from DFlag to Clean, before restarting.

The accompanying figure illustrates the step-by-step deletion process in a nonblocking algorithm, specifically focusing on the Efficient Redundant Binary tree. The diagrams depict various states of the tree during a delete operation, highlighting the use of atomic primitives to maintain consistency in a concurrent environment. The scenario depicted in the figure supposes that a thread searches for the key ninety, locating the target node containing ninety, and its parent and grandparent. Crucially, this thread observes that neither the parent nor the grandparent nodes are initially locked.

The initial state of the relevant portion of the tree is shown, with a grandparent node, a parent node, and their respective children. The parent node has an update field, which is initially in a Clean state. The delete operation involves creating a new DeleteFlag descriptor, which is conceptually associated with the node to be deleted, marking it for removal. The parent node's update field is then locked using a compare and swap operation, which atomically changes its state to DFlag, indicating it is locked for deletion. The grandparent node's update field is also locked, and the node ninety is marked for deletion.

The delete operation then replaces the parent with its sibling, effectively removing the target node from the tree. This operation is contingent on the grandparent and parent nodes not being locked by other concurrent operations. If either the grandparent or parent is already locked, the delete operation might fail or require retrying. The text implies that if another thread encounters this deletion operation, it might help the ongoing deletion and then restart its own operation, proceeding as shown in the figure. The steps are described as similar to an insert operation, with a key difference: two nodes are encountered in a locked state. The first locked node is the target node marked in step d of the deletion, which is being removed from the tree. In this case, there's no need to lock the leaf target node further because its leaves cannot be changed. If the compare and swap operation in step d fails, the deleting thread performs a compare and swap to try to transition the grandparent's update from DFlag to Clean, with a descriptor, effectively rolling back or retrying the operation. This handling of compare and swap failures is crucial for the progress and correctness of nonblocking algorithms, ensuring that operations can complete even in the face of concurrent modifications.
