In the domain of parallel computing and shared memory architectures, maintaining the correct observable order of memory operations across multiple threads is a fundamental challenge. A core concept in addressing this is the use of memory fences, sometimes referred to as full fences. A full fence is a synchronizing instruction that guarantees all memory operations initiated by a given thread before the fence become globally visible and complete before any memory operations initiated by the same thread after the fence are allowed to begin, from the perspective of all other threads in the system.

Central to robust concurrent programming is the principle of write atomicity. This ensures that a multi-byte store operation to a memory location is perceived by all other threads as an indivisible unit. That is, other threads will observe either the data before the write, or the data after the write, but never an inconsistent intermediate state where only a portion of the data has been updated. This property is crucial for the integrity of shared data structures. Modern hardware, particularly through sophisticated cache coherence protocols like M E S I or M O E S I, inherently supports write atomicity for individual cache lines.

The behavior of memory operations is often more complex in real-world systems due to performance optimizations. Modern machine architectures frequently employ relaxed memory models, which permit significant reordering of memory accesses to maximize instruction-level parallelism and hide memory latencies. This reordering can occur within the processor core, the cache subsystem, or even the interconnects between processors. Consequently, a program written to assume sequential consistency – where all memory operations appear to execute in the order specified by the program, across all threads – may exhibit incorrect behavior on such weakly ordered machines.

Architects, recognizing the overhead of full ordering, often provide weaker synchronizing instructions that offer only the minimal ordering guarantees necessary for specific synchronization tasks. These weaker semantics allow for optimizations like local bypassing of memory operations, where data can be forwarded directly from one stage of the pipeline to another without waiting for full global commit, thereby improving performance.

The challenge for programmers then becomes how to precisely specify the required ordering constraints without incurring the prohibitive cost of full fences where they are not strictly necessary. This is precisely what modern programming language memory models, such as the one introduced in C plus plus eleven and its successors, aim to address. These models provide atomic operations with fine-grained memory ordering semantics, allowing developers to express exactly what ordering guarantees are needed for particular memory accesses.

A formal notation can be employed to describe these local ordering requirements within a thread. For example, an instruction can be annotated with the form "P double pipe S", indicating that this instruction is ordered with respect to a preceding set of memory accesses, denoted by 'P', and a subsequent set of memory accesses, denoted by 'S'. The sets 'P' and 'S' are subsets of all possible read 'R' and write 'W' memory accesses within the thread. This notation precisely defines the local dependencies that a synchronizing instruction establishes, thereby enabling the use of less than fully ordered synchronizing accesses and optimizing performance by avoiding unnecessary global barriers.

The ability to specify these minimal ordering requirements is crucial for developing high-performance, correct parallel algorithms that scale efficiently on contemporary multi-core and many-core architectures. Throughout the remainder of this discussion, pseudocode will be used to illustrate key concepts, with code in real programming languages set in typewriter font. The term synchronizing access will refer to explicit loads and stores, fences, and atomic read-modify-write operations. Other memory accesses will be referred to as "ordinary."

Coherence, per location, dictates that for any given location, all accesses, both ordinary and synchronizing, to that location appear in some global total order. Global order, for synchronizing accesses, establishes a total order on synchronizing accesses to all locations, by all threads. Program order, per thread, describes the sequence of operations as specified by the programming language semantics within the context of a single thread. However, this order does not necessarily correspond to physical reality in the implementation, as both the compiler and the hardware may reorder assembly-level instructions if they are able to prove that a sequential program cannot tell the difference.

Local order, within a given thread, each synchronizing access is ordered with respect to previous and subsequent accesses, both ordinary and synchronizing, as specified by implicit or explicit R W or R W annotations. For fully ordered R W or R W synchronizing instructions, global and program order are consistent. Values read may return the value written by the most recent write to the same location that is ordered before the read, or in some cases, the value written by an unordered write.

Read-modify-write instructions, such as fetch and Phi operations, count as both reads and writes in such annotations. These operations encapsulate a read, a modification, and a write as a single, indivisible unit, preventing other threads from observing any intermediate state. Such atomicity is crucial for correctly implementing locks, semaphores, and other synchronization constructs.

To determine the need for synchronizing instructions in the code of a given synchronization algorithm, one must consider both the correctness of the algorithm itself and the semantics it is intended to provide to the rest of the program. The acquire operation of Peterson's two-thread spin lock, for example, employs synchronizing stores to arbitrate between competing threads, but this ordering is not enough to prevent a thread from reading or writing shared data before the lock has actually been acquired, or after it has been released. For that, one needs accesses or fences with local double bar read write and read write double bar ordering.

In the absence of annotations, it is assumed that read write double bar read write ordering is used for synchronizing instructions. To indicate a synchronizing instruction with no ordering constraints, the annotation double bar is used. The main difference between an ordinary access and a synchronizing access annotated with double bar is that the former can participate in a data race, and the latter cannot. Compiler writers or assembly language programmers interested in porting pseudocode to some concrete machine will need to restrict their code improvement algorithms accordingly and issue appropriate synchronizing instructions for the hardware at hand.

The principle of "Order Proactively, not Defensively" underscores the danger of relying on intuition regarding memory ordering. Processors and compilers can introduce surprising amounts of reordering. For instance, parts of a subroutine might be executed out of order, or a compiler might inline a subroutine, intermixing its instructions with those of the caller. This can lead to unexpected behaviors where memory writes are not visible in the expected order, or reads fetch stale data.

Rather than imagining all of the ways in which optimizations can violate expectations, authors of synchronization mechanisms and concurrent data structures are advised to determine the order in which steps must occur for correctness and then insert appropriate instructions to guarantee that ordering. It is crucial to note that while some programming language constructs provide read write double bar read write semantics by default for synchronizing instructions, general unannotated loads and stores may not be globally ordered, emphasizing the need for explicit attention to memory consistency in the design of robust concurrent software.
