The design and analysis of nonblocking concurrent data structures, specifically focusing on queues and double-ended queues, or deques, is a complex topic. Nonblocking algorithms aim to ensure that the progress of a system as a whole does not depend on the responsiveness of any single thread. This is achieved through mechanisms that prevent threads from blocking each other indefinitely, a common issue in lock-based concurrency.

In the context of queues, an enqueue operation requires a pair of updates: one to set the next pointer of the previously enqueued node, and one to advance the tail pointer to the new node. The linearization point for an enqueue is typically after these two updates have successfully completed, ensuring that the operation's effect is atomic from the perspective of other threads. To ensure consistent snapshots, the code must read both the tail pointer and its successor, and then re-read the tail pointer to ensure that no other thread has modified it in between.

The dequeue operation has its own set of challenges, including re-reading the head and tail pointers after reading the head's successor to ensure consistency. If the head and tail are not equal, and the read of the head's successor is valid, the operation can proceed. A successful Compare And Swap, or CAS, operation on the head pointer, predicated on the original value of head, effectively removes the node.

Memory management in concurrent data structures, particularly for reclaiming memory from removed nodes, is a significant concern. Techniques such as hazard pointers or counted pointers can be used to prevent race conditions where a thread might access a node that has already been freed or is in the process of being modified by another thread.

Double-ended queues, or deques, permit insertions and deletions at both ends, but not in the middle. While deques offer fewer practical uses compared to stacks and queues in sequential contexts, their utility in concurrent programming is substantial. The original CAS-based lock-free deque is due to Michael, and it employs a three-step update mechanism for push and pop operations.

The Michael and Scott queue, a well-known lock-free queue, is referenced as a precursor, employing a two-step update mechanism where a second step might be assisted by another thread. In contrast, other lock-free deques, like those described by Herlihy and Shavit, often involve three-step updates. The complexity arises from managing concurrent access to both the head and tail of the deque, requiring careful handling of potential race conditions.

The concept of a work-stealing scheduler is also introduced, implying that deques can be used to manage tasks in a distributed or parallel computing environment, where idle processors can steal work from busy ones. This demonstrates a practical application of efficient concurrent data structures in task distribution and load balancing.

The lock-free deque of Michael uses a single, double-width, CAS-able memory location to hold the head and tail pointers of the list, together with a two-bit status flag that can take on any of three possible values: STABLE, LPUSH, and RPUSH. For ABA-safe memory allocation, the algorithm can be augmented with hazard pointers. Alternatively, it can be modified to rely on counted pointers, but to fit two of these plus the status flag in a single CAS-able anchor, the pointers must be indices into a bounded-size pool of nodes.

Operations on the deque are illustrated in a figure, which shows seven distinct functional states of the deque, visualized through nodes and state transitions. Each node within the deque can be thought of as a memory element containing data and pointers, potentially to other nodes. The states are characterized by the combination of head and tail pointers, and a status flag. The status flag can assume one of three values: STABLE, LPUSH, and RPUSH.

The operation is presented as a three-step process, where nodes in the process of insertion are depicted with dashed arrows. Interior nodes are marked with a value, and pointers. Some pointers might be marked with a question mark, indicating an immaterial value that is not inspected during the operation, or an X signifying a temporarily incorrect pointer.

The diagram shows transitions between states through operations labeled push, pop, push_left, and push_right. For example, state S zero, representing an empty deque where head and tail pointers are null, can transition to other states upon push operations. State S one depicts a deque with a single node, where the head and tail pointers refer to the same node. State S two and subsequent states represent deques containing two or more nodes, with nodes linked via left and right pointers.

The text elaborates on the underlying mechanisms for ensuring correctness in a concurrent environment, particularly focusing on memory allocation and ABA problem mitigation. For ABA-safe memory allocation, hazard pointers are mentioned as a common technique. Alternatively, the algorithm can be augmented to rely on counted pointers. A more compact approach involves consolidating the status flag and pointers within a single CAS-able anchor, utilizing double width for storage.

The operational states of the deque are further detailed. Three states are designated as STABLE, indicating states where a completed operation requires no further cleanup. In state S zero, the deque is empty, and both head and tail pointers are null. In state S one, there is a single node, and both head and tail pointers point to this node. In states S two and beyond, there are two or more nodes, linked together with left and right pointers.

The figure depicts the states and transitions that allow for efficient and lock-free manipulation of the deque data structure, crucial for high-performance concurrent systems. The state transitions, such as push_left and push_right, are fundamental to the deque's functionality, allowing elements to be added to either end of the structure without requiring mutual exclusion locks. The pop operations similarly facilitate removal from either end. The states labeled LPUSH and RPUSH represent intermediate states during left and right insertions, respectively, where the structure is temporarily in a state that needs careful handling to maintain consistency across concurrent accesses.
