Six point three, Read Copy Update. 

Read Copy Update, or R C U, is a sophisticated approach to concurrency control in multi-processor systems, particularly valuable for scenarios dominated by read operations. At its core, R C U is a non-blocking synchronization primitive that permits concurrent readers to access shared data without explicit locking, thereby minimizing overhead and enhancing scalability. The fundamental principle revolves around the notion of a "grace period," during which writers create a new version of a data structure, while existing readers continue to access the old version. Only after all readers that were active when the update began have completed their access to the old data is the old memory safely reclaimed, often through a garbage collection mechanism or explicit deallocation.

A common implementation strategy for enforcing this grace period utilizes a global counter, denoted as C, and a per-thread set of counters, S, indexed by thread I D. The global counter C is designed to be monotonically increasing, incrementing at the conclusion of each write operation. This increment serves as a timestamp for the completion of a writer's work. Concurrently, each thread maintains an entry in the S array, specifically S index I. This entry is set to zero if thread I is not actively executing a reader operation. If it is a reader, S index I stores the value of C that was current when thread I commenced its reader operation. To ensure that all pre-existing readers have completed their access to the old data, a writer performs a critical validation step: it iterates through the entire S array, waiting for each element S index I to either be zero, indicating no active reader, or to be a value greater than or equal to the C value that the writer just recorded. This waiting phase is the essence of the grace period, guaranteeing that all readers initiated prior to the writer's update have observed the state of the data before the writer's modifications became visible.

The architectural design decision to place each element of S in a separate cache line is a strategic optimization to mitigate false sharing, a common issue in multi-core systems where unrelated data residing in the same cache line causes unnecessary cache invalidations. This separation ensures that updates to one thread's S entry do not inadvertently invalidate the cache line containing another thread's S entry, thereby improving cache coherency and overall performance.

The integrity of R C U hinges critically on precise memory ordering, particularly in weakly ordered memory models prevalent in modern C P U architectures. When a thread initiates a read operation under R C U, it must update its corresponding entry in the S array. This update can be performed using a Read Or Store operation, or by explicitly following the update with a Write Or Read fence. The choice of barrier type dictates the strictness of the ordering guarantees. Similarly, upon concluding a read operation, the thread updates its S entry, typically using a Read Or Write store or by following the update with a Read Or Read fence. These fences are essential for ensuring that the writer observes the reader's entry and exit from its critical section in a causally consistent manner. Furthermore, when a reader accesses a pointer that might have been concurrently updated by a writer, it must employ a Read Or Load or follow the read with a Read Or Read fence. This ensures that the pointer value read by the thread is consistent with its ongoing operation.

The Write Or Read fence is generally the most expensive due to its strong ordering semantics, often involving a global memory barrier that flushes write buffers and ensures visibility across all processors. To circumvent this performance penalty in common scenarios, an alternative approach is to avoid the explicit Write Or Read ordering by employing mechanisms such as a P O S I X signal. This allows the writer to interrupt potential readers, effectively achieving the grace period via an operating system level inter-process communication rather than direct memory ordering constraints. For writers, the rules for managing R C U-updatable pointers are akin to those for seqlock mechanisms, which often require careful handling of causality loops to prevent readers from observing inconsistent intermediate states. Writers must sequentially consistently inspect multiple R C U-updatable pointers and use write-atomic synchronizing stores to ensure that modifications to these pointers appear as a single, atomic operation to other concurrent actors.

Beyond single-pointer updates, R C U can be extended to manage more complex data structures and multi-word modifications, although this often introduces additional design challenges. The inherent "single-pointer update property" of basic R C U implies that the most straightforward application involves atomically changing a single pointer to point from an old version of data to a new one. However, for data structures that require simultaneous modification of multiple related fields or pointers, such as a doubly-linked list or a tree, application-specific knowledge becomes paramount for correct traversal and space management. For instance, in their seminal work from two thousand one, McKenney and colleagues demonstrated an R C U-compatible version of doubly-linked lists. Their innovation involved ensuring that readers traverse the list exclusively using forward pointers. Backward pointers, while essential for efficient deletion, were treated as mere hints, enabling constant-time deletion without requiring readers to synchronize on them. This design decouples the complex update of backward pointers from the high-concurrency read path.

In a similar vein, Clements and collaborators in two thousand twelve explored the application of R C U to balanced external binary trees. They illustrated how complex operations like tree rebalancing, insertion, and deletion could be decomposed into semantically neutral steps. By separating the rebalancing process from the fundamental insertion and deletion operations, it becomes possible to perform the rebalancing as an asynchronous, R C U-safe operation, ensuring that concurrent readers always operate on a consistent, if not perfectly balanced, version of the tree, while the new balanced structure is gradually made available. This exemplifies a powerful design pattern in concurrent programming: separating computationally intensive or highly contended operations from the read path to maximize concurrency and throughput.

The illustration depicts a binary tree rebalancing operation performed through an internal subtree replacement, a technique fundamental to maintaining the performance characteristics of tree-based data structures. Central to this process is the concept of a tree rotation, which rearranges nodes to alter the tree's structure while preserving the inorder traversal of its elements, thereby maintaining the semantic ordering of the data. Spatially, the diagram presents a hierarchical structure with a root node at the top. Below the root, connected by a dashed line, is node p. From p, a solid line descends to node z prime, which is the newly created version of an existing node. To the right of z prime and slightly below it, the original node z is shown in a faded, greyed out representation, indicating its eventual obsolescence. Below z prime, two children, x prime and x, are depicted. x prime is a new node, similar to z prime, connected to z prime by a solid line. The original x node, also greyed out, is positioned slightly to the left and above x prime. From x prime and z prime, solid lines descend to three distinct subtrees, labeled A, B, and C.

This rebalancing mechanism is particularly relevant in the context of concurrent data structures, where atomicity, consistency, isolation, and durability, often abbreviated as A C I D properties, are paramount. The text explains that rotation-based rebalancing can be designed to affect only a small internal subtree. This localization of change is critical for concurrent systems. By restricting modifications to a small, self-contained portion of the tree, the complexity of atomic updates is significantly reduced. The strategy described involves creating a new version of the affected subtree and then atomically swinging a single pointer from the parent node to the root of this new subtree. This "single incoming pointer" ensures that the update from the perspective of an external observer appears instantaneous.

The underlying principle here is Read Copy Update, or R C U, a synchronization mechanism designed for read-mostly workloads in which readers incur essentially no synchronization overhead. When a writer needs to modify the data structure, it creates a new version of the affected nodes, makes its changes to these new nodes, and then updates a single pointer to point to the new structure. The old nodes are not immediately deallocated. Instead, they remain in memory for a "grace period," during which any readers traversing the old pointers can complete their operations. Once the grace period expires, meaning all active readers are guaranteed to have either finished or switched to the new version of the data structure, the old nodes can be safely reclaimed. This avoids the need for read locks, allowing readers to proceed without contention, which is highly beneficial for performance in multi-core and multi-processor systems.

The text also highlights a crucial trade-off inherent in Read Copy Update: while it provides extremely low overhead for readers, it incurs significant overhead for writers. This writer overhead stems from the need to copy parts of the data structure, perform the actual modifications, and then wait for a grace period before the memory for the old versions can be deallocated. For operations like trivial updates, specifically single leaf modifications associated with demand page-in operations in an O S kernel, this write overhead can become a performance bottleneck, especially for page tables which are frequently accessed and modified.

To mitigate this, a hybrid approach combining Read Copy Update with other synchronization primitives like sequence locks is proposed. Sequence locks provide a mechanism for concurrent readers and writers where readers can check if a write has occurred and retry their operation if necessary, offering a different balance of overheads. The solution discussed is a hybrid of Read Copy Update and sequence locks, indicating that different synchronization strategies can be composed to address specific performance requirements and access patterns.

The application of Read Copy Update to page tables is a sophisticated example. A page table is a critical data structure in virtual memory management, mapping virtual addresses to physical addresses. When an O S performs a demand page-in operation, it modifies a page table entry to establish this mapping. This modification must be atomic and non-blocking to other concurrent operations, such as other page faults or memory accesses. By using Read Copy Update, the O S can update page table entries without blocking active C P U cores that are performing memory accesses, allowing them to continue traversing the old page table structure until the next context switch or synchronization point effectively updates their view. The Read Copy Update writers coordinate by excluding one another, installing their changes via single pointer updates, and then waiting for the grace period before the no longer needed space is reclaimed. This approach underscores the theoretical and practical significance of Read Copy Update in achieving high concurrency and responsiveness in kernel-level operations.

This relaxation of the rules introduces a variety of synchronization challenges. For example: a fault handler that overlaps in time with a major update, for example, an munmap operation that invalidates a broad address range, may end up modifying the about-to-be-reclaimed version of a page table entry, in which case it should not return to the user program as if nothing had gone wrong. If each major update acquires and updates a per-address-space sequence lock, however, then the fault handler can check the value of the lock both before and after its operation. If the value has changed, it can retry, using the new version of the data. Alternatively, if starvation is a concern, it can acquire the lock itself. Similarly, if fault handlers cannot safely run concurrently with one another, for example, if they need to modify more than a single word in memory, then they need their own synchronization, perhaps a separate sequence lock in each page table entry. If readers may inspect more than one word that is subject to in-place update, then they, too, may need to inspect such a local sequence lock, and repeat their operation if they see a change. This convention imposes some on the presumably dominant read-only code path, but the overhead is still small. In particular, readers still make no updates to shared data.

The principle of Read-Copy Update, or R C U, represents a sophisticated approach to concurrency control in computer systems, particularly within operating system kernels where data structures are frequently read but only occasionally modified. This mechanism is fundamentally about relaxing traditional synchronization rules to achieve high scalability for read operations, offering a significant advantage over pessimistic locking schemes such as mutexes or semaphores.

At its core, R C U operates on an optimistic concurrency model for readers. Unlike traditional locking, where readers would acquire a shared lock before accessing data, R C U allows read-only operations to proceed without explicit locks, thereby eliminating contention and context switching overhead for the dominant read path. This is achieved by ensuring that writers never modify data in place. Instead, a writer creates a new, updated copy of the data structure, performs its modifications on this private copy, and then atomically publishes the pointer to the new version. The original version of the data remains accessible for any readers that might have been in progress at the time of the update.

To manage consistency, R C U introduces a mechanism often involving "sequence locks" or similar versioning counters. When a writer initiates an update, it increments a sequence number before modifying the data structure and again after the new version is fully published. A reader, before accessing the shared data, first records the current value of this sequence lock. It then proceeds to read the data. Upon completing its read, the reader checks the sequence lock value again. If the initial and final sequence lock values are identical, it indicates that no writer interfered with the data during the reader's critical section, and the read is valid. However, if the sequence lock value has changed, it signifies that a writer performed an update concurrently. In this scenario, the reader's optimistic assumption was violated, and it must retry its entire operation using the newly published version of the data. This retry mechanism is crucial for maintaining correctness without blocking readers.

Consider the illustrative example of a fault handler interacting with page table entries. A munmap operation, which deallocates a range of virtual memory, necessitates changes to the page table. In an R C U context, this munmap operation would create a new version of the relevant page table entries or the entire table structure. A concurrent fault handler, upon encountering a page fault, might attempt to translate a virtual address using the page table. Under R C U, it could initially access an "about to be reclaimed" version of a page table entry. If the munmap operation completes while the fault handler is still processing, the sequence lock would be updated. The fault handler's post-read check of the sequence lock would then reveal the change, prompting it to retry its address translation using the updated page table information. This approach ensures the fault handler never returns an incorrect translation to the user program, even though it temporarily operated on stale data. It avoids the complexities and performance penalties of a full lock acquisition by the reader in this critical path.

The trade-off for this high read concurrency is borne by the writers and the system's memory management. Writers must manage the creation of new data copies and ensure atomic publication. Furthermore, the system must determine a "grace period" â€“ a time after which all readers that might have accessed the old data version are guaranteed to have completed their operations. Only after this grace period can the old data version be safely reclaimed and freed. This reclamation process adds complexity and can involve garbage collection-like mechanisms.

The text highlights an interesting edge case: if a fault handler cannot safely run concurrently with another because it needs to modify more than a single word in memory, it then requires its own synchronization. This underscores that R C U is primarily a read-side optimization for non-modifying readers. If a "reader" process itself needs to perform multi-word modifications, it fundamentally acts as a writer and must employ conventional synchronization primitives, perhaps even per-page-table entry sequence locks for fine-grained control, to ensure atomicity and consistency of its own modifications.

The mention of starvation concern for readers acquiring the lock themselves is a nuanced point. While R C U is designed to eliminate reader blocking, a continuously retrying reader in a highly contended scenario could theoretically "starve" by never completing its operation successfully. However, in practice, the more common starvation concern with R C U is writer starvation, where a continuous stream of readers might perpetually delay the grace period required for old data to be freed. If a reader must complete its operation without retrying, it could, as an alternative, temporarily acquire the writer's sequence lock, thus serializing its operation and ensuring a stable view of the data. This strategy, however, deviates from the primary R C U benefit of lock-free reads and would typically be reserved for exceptional cases demanding absolute consistency without retries.

Ultimately, R C U offers a compelling design pattern for systems requiring extreme read performance on shared data. The overhead for the dominant read-only code path is minimal, involving only a few instructions for sequence number checks. The fundamental strength of R C U lies in the premise that readers do not modify shared data, allowing them to proceed with remarkable concurrency, with writers bearing the burden of copy and atomic publication, managed through careful memory reclamation policies.
