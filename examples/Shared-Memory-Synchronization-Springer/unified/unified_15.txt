The concept of liveness in concurrent systems refers to the property that a system, or at least some part of it, will eventually make progress. This is a fundamental consideration in the design of robust and responsive multi-threaded applications. Non-blocking algorithms are a class of concurrent algorithms specifically designed to ensure this progress by avoiding traditional locking mechanisms. A key advantage of these algorithms is their resilience to inopportune preemption, where a thread holding a critical resource or lock might be temporarily suspended by the operating system. In a blocking system, such an event could lead to a deadlock or indefinite stall. Non-blocking algorithms, however, are engineered such that the preemption or even crash of one thread does not prevent other threads from making forward progress, thereby contributing to higher fault tolerance.

While the primary focus is on overall system progress, fairness, which concerns the relative rates of progress among competing threads, is also an important aspect to consider. The definition of progress in non-blocking algorithms is often given in terms of abstract program steps, rather than absolute time, due to the inherent variability introduced by factors such as time-sharing, cache misses, and page faults. This allows for a more deterministic analysis of progress guarantees.

The strongest variant of non-blocking progress is wait freedom. A method is considered wait-free if it guarantees that every individual thread attempting an operation will complete its task within a bounded number of its own program steps. This guarantee holds true regardless of the execution speed of other threads or even if other threads crash. Wait freedom inherently ensures both starvation freedom and livelock freedom. Starvation freedom means that no individual thread will be indefinitely prevented from making progress, ensuring that every thread eventually gets its turn. Livelock freedom means that threads will not continuously perform unproductive work, repeatedly attempting operations that fail without actual progress.

A more common, and slightly weaker, form of non-blocking progress is lock freedom. A method is lock-free if it guarantees that at least one thread attempting an operation on a shared object will complete its task within a bounded number of system-wide program steps. The crucial distinction from wait freedom is that while the system as a whole is guaranteed to make progress, individual threads are not guaranteed to make progress and may still suffer from starvation. Lock freedom prevents system-wide deadlocks and livelocks by ensuring that at least one operation will always succeed, even under contention.

The weakest form of non-blocking progress discussed is obstruction freedom. An operation is obstruction-free if it is guaranteed to complete within a bounded number of program steps, provided that no other thread takes any steps during that specific execution interval. In essence, if a thread runs in isolation without interference from other concurrent operations, it will complete. However, if multiple threads are actively contending, an obstruction-free algorithm can suffer from starvation, as threads might repeatedly conflict and retry their operations without success.

Most wait-free algorithms, and many lock-free algorithms, employ some variant of helping, in which a thread that has begun but not completed its operation may be assisted by other threads, which need to get it out of the way so they can perform their own operations without an unbounded wait. Other lock-free algorithms, and even a few wait-free algorithms, are able to make do without helping. As a simple example, consider the implementation of an increment-only counter. On a machine with a Fetch And Increment instruction, the natural single-word implementation of the counter will indeed be wait-free.

The code defines an atomic integer array named C, indexed by T, and initialized to all zeros. It includes two functions: `increment` and `val`. The `increment` function computes a `newval` by loading the current value of `C` at `self` with write ordering and then incrementing it by one. This `newval` is then stored back into `C` at `self` with read ordering. The `val` function returns an integer by iterating through `i` from one to N, where `N` represents the total number of threads or counter segments, and summing up the values of `C` at each index `i`.

The behavior of this aggregate counter `val` and the per-thread increment `increment` operations merits closer examination in terms of correctness and concurrency properties. The aggregate value is derived from a set of per-thread values, each of which is monotonically increasing. Given this property, it is provable that the value returned by the `val` method will be correct at some point between its invocation and its return. Specifically, the value returned by `val` will be bounded from above by the actual number of `increment` operations that were called before `val` returned, and bounded from below by the number that returned before `val` was called. This demonstrates the critical concept of linearizability.

Moving to the discussion of fairness, this property is distinct from obstruction freedom and lock freedom, though related to wait freedom. Obstruction freedom asserts that if a thread executes its operation without interference from any other threads, it will complete in a finite number of steps. Lock freedom, as discussed, guarantees that at least one thread will make progress in a concurrent system. However, neither obstruction freedom nor lock freedom inherently guarantees fairness. An individual thread may still starve, repeatedly failing to acquire resources or complete its operation, even as the system as a whole continues to advance.

Fairness, in contrast, specifically addresses this issue by ensuring that every thread attempting an operation will eventually complete it. Wait freedom is a stronger guarantee than lock freedom, as it implies that every individual operation completes within a bounded number of steps, thereby inherently ensuring fairness for individual threads. The text rightly points out that even wait freedom permits an operation to execute an arbitrary number of steps, whether helping or deferring to peers, before completion, so long as this arbitrary number remains bounded in any given situation.

In any practical system, forward progress relies on the assumption that any continually unblocked thread will eventually execute another program step. Without such minimal fairness within the implementation, a system could be "correct" without doing anything at all. Significantly, even this minimal fairness depends on scheduling decisions at multiple system levels: in the hardware, the operating system, and the language runtime, all of which ensure that runnable threads continue to run.

When threads may block for mutual exclusion or condition synchronization, we shall in most cases want to insist that the system display what is known as weak fairness. This property guarantees that any thread waiting for a condition that is continuously true, or a lock that is continuously available, eventually executes another program step. Without such a guarantee, program behavior may be highly unappealing. Imagine a web server, for example, that never accepts requests from a certain client connection if requests are available from any other client.

The provided program fragment illustrates the concept of weak fairness using atomic operations and spin waiting. An atomic boolean variable, named `f`, is initialized to `false`. Thread one is defined as awaiting `f` to become `true`, while thread two awaits `f` to become `false` before setting it to `true`. The `await` notation is a shorthand for a busy waiting or spin loop structure, which includes a fence operation with read or read-write memory ordering. This ensures that any memory accesses required to evaluate the condition are marked as synchronizing reads.

The significance of this example lies in demonstrating how weak fairness guarantees liveness. If weak fairness holds, the described execution in which thread one spins forever, never observing `f` becoming `true`, is precluded. This implies that thread two must eventually be scheduled, observe `f` as `false`, execute its operation to set `f` to `true`, and this write must eventually become visible to thread one. Consequently, thread one will eventually observe `f` as `true`, exit its await loop, and make progress. This guarantees that despite the use of busy-waiting, a pattern often prone to starvation, both threads ultimately complete their intended tasks due to the system-level guarantee of weak fairness on condition variables.
