The concept of fairness within concurrent systems is a fundamental aspect of reliable and predictable execution, particularly in multithreaded or distributed environments. It addresses the challenge of ensuring that all competing processes or threads make progress and do not suffer from indefinite postponement, known as starvation. Multiple definitions of fairness exist, each imposing progressively stronger guarantees.

Weak fairness, for instance, postulates that if a condition for a thread to execute is continuously true, then that thread will eventually be given an opportunity to run. This means that while a thread might repeatedly check a condition that remains true, it will not be permanently ignored. In contrast, strong fairness demands a more rigorous guarantee: if a condition for a thread to execute becomes true infinitely often, then the thread will eventually execute. This subtle but critical distinction ensures that even transient opportunities for execution are not missed indefinitely.

Consider a scenario involving two threads, thread one and thread two, using atomic boolean variables F and G. Both variables are initially set to false. Thread one enters a loop that continues as long as the atomic variable F, when loaded with weak memory ordering, evaluates to false. Inside this loop, thread one first stores true into the atomic variable G with weak memory ordering, and then immediately stores false into G with release memory ordering. Meanwhile, thread two waits until the atomic variable G becomes true. Once G is true, thread two then stores true into the atomic variable F with default memory ordering.

Strong fairness is difficult to truly achieve. It may, for example, require a scheduler to re-check every awaited condition whenever one of its constituent variables is changed, to make sure that any thread at risk of starving is given a chance to run. Any deterministic strategy that considers only a subset of the waiting threads on each state change risks the possibility of deterministically ignoring some unfortunate thread every time it is able to run.

Fortunately, statistical guarantees typically suffice in practice. By considering a randomly chosen thread, instead of all threads, when a scheduling decision is required, we can drive the probability of starvation arbitrarily low. A truly random choice is difficult, of course, but various pseudorandom approaches appear to work quite well. At the hardware level, interconnects and coherence protocols are designed to make it unlikely that a race between two cores, for example, when performing near-simultaneous Compare And Swap instructions on a previously uncached location, will always be resolved the same way. Within the operating system, runtime, or language implementation, one can randomize the interval between checks of a condition using a pseudorandom number generator or even the natural jitter in execution time of nontrivial instruction sequences on complex modern cores.

Weak and strong fairness address worst-case behavior and allow executions that still seem grossly unfair from an intuitive perspective, for example, executions in which one thread succeeds a million times more often than another. Statistical randomization, by contrast, may achieve intuitively very fair behavior without absolutely precluding worst-case starvation.

Much of the theoretical groundwork for fairness was laid by Nissim Francez in nineteen eighty-six. Proofs of fairness are typically based on temporal logic, which provides operators for concepts like always and eventually. A brief introduction to these topics can be found in the text of Ben-Ari, two thousand six, Chapter four. Much more extensive coverage can be found in Schneider's comprehensive work on the theory of concurrency, nineteen ninety-seven.

The concept of the Consensus Hierarchy in concurrent programming is a framework largely established by Herlihy. This hierarchy classifies atomic primitives based on their inherent ability to solve the wait-free consensus problem for varying numbers of processes. Central to this classification are universal atomic primitives, such as Compare And Swap, or C A S, and Load Link / Store Conditional, or L L / S C. These primitives are deemed universal because they can be used to implement any other atomic operation in a wait-free manner, and crucially, they can achieve wait-free consensus for an arbitrary number of participating threads.

The wait-free consensus problem itself is a cornerstone of distributed and concurrent computing. Originally conceptualized by Fischer and colleagues in nineteen eighty-five for asynchronous message passing systems, it describes a scenario where multiple potentially unreliable threads each propose a value, and the objective is for all non-faulty threads to eventually agree on a single, common value from those proposed. Herlihy ingeniously adapted this problem to the shared memory paradigm, demonstrating how the computational impossibility results previously observed in message passing could be circumvented through the judicious use of powerful atomic operations.

The key metric in this hierarchy is the consensus number, which quantifies the maximum number of threads for which a given atomic object can guarantee wait-free consensus. The provided pseudocode illustrates how a Test And Set, or T A S, object can achieve wait-free consensus specifically for two threads. It defines two atomic variables: L, an atomic boolean initialized to false, which serves as a synchronization flag, and proposal, an array of two atomic integers, used to store the values proposed by each thread.

Herlihy was able to show that this is the best one can do: T A S objects, even an arbitrary number of them, cannot achieve wait-free consensus for more than two threads. Moreover, ordinary loads and stores cannot achieve wait-free consensus at all, even for only two threads. An object supporting C A S, on the other hand, or equivalently L L / S C, can achieve wait-free consensus for an arbitrary number of threads.

One can, in fact, define an infinite hierarchy of atomic objects, where those appearing at level k can achieve wait-free consensus for k threads but no more. Objects supporting C A S or L L / S C are said to have consensus number infinity. Objects with other common primitives, including T A S, swap, and F A A, have consensus number two. Atomic objects at intermediate levels of the hierarchy are not typically encountered on real hardware.

The behavior of these concurrent systems is rigorously defined by their memory model, a crucial concept that dictates how memory operations performed by different processors interact and become visible to one another. Most modern multicore systems exhibit cache coherence, which ensures that all reads to a specific memory location eventually reflect the latest written value for that location, irrespective of which core performed the write or read. However, coherence alone does not guarantee sequential consistency.

Sequential consistency is a much stricter property, demanding that the result of any execution appears as if all operations from all processors were executed in some global sequential order, and that operations from each individual processor appear in this sequence in the order specified by its program. The divergence between coherence and sequential consistency is where the complexity arises. In a coherent but not sequentially consistent system, while writes to a single variable are serialized and eventually propagate to all cores, operations targeting different memory locations may appear to occur in different orders from the perspective of different threads.

This reordering, often performed by compilers or hardware to optimize performance, can lead to apparent causality loops, where events seem to violate causal relationships, making concurrent program behavior difficult to reason about. Consequently, a formal memory model is indispensable for programmers to predict and control the behavior of their concurrent applications. Such models can be defined at the hardware level, exemplified by architectures employing Total Store Order semantics, or at the programming language level, such as those governing Java or C plus plus.

A well-defined language-level memory model provides guidance for compiler writers and library developers on where to inject special ordering instructions, often referred to as memory fences, and empowers application programmers to correctly employ synchronization primitives and atomic variables to achieve their desired program semantics. The extensive body of literature on language-level memory models underscores their importance. These models, while varying in their specific rules, typically share a common framework centered on balancing the twin goals of performance and programmability.

This balance is often achieved by requiring programmers to explicitly label specific points in their code where precise ordering of memory operations really matters for correctness, allowing compilers maximum freedom for optimization elsewhere. A primary objective in designing any practical memory model is to preserve, to the greatest extent possible, the latitude for compiler writers to apply code improvement techniques originally developed for sequential programs. However, the ordering constraints imposed by synchronization operations necessitate not only hardware-level ordered accesses, enforced by memory fences, but also software-level compiler fences.

These fences inhibit compiler optimizations, like code motion, that might reorder instructions across synchronization points. This restriction is crucial for maintaining correctness in concurrent programs but can impact performance benefits traditionally gained from techniques such as latency tolerance, redundancy elimination, and other aggressive performance enhancements. Thus, the memory model fundamentally defines the contract between the hardware, compiler, and programmer, enabling both correct and performant execution in the multicore era.
