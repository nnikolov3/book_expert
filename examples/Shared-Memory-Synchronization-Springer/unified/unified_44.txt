Seven point five Kernel User Interactions. Indicates that the user wishes not to be preempted. The second flag is written by the kernel and read by the user thread; it indicates that the kernel wanted to preempt the thread, but refrained because the first flag was set. A test and set spin lock might use these flags as follows: Atomic boolean do not preempt me is false. Atomic boolean kernel wanted to preempt me is false. 

The lock acquire function demonstrates a typical spin lock acquisition process. It first sets do not preempt me to true, signaling that the thread is unwilling to be preempted. This is followed by a loop that uses a test and set operation. The core of the spin lock logic is while not f test and set, where f is a boolean flag indicating whether the lock is acquired. The loop continues as long as the test and set operation fails to acquire the lock, meaning the lock is already held by another thread. 

Inside the loop, do not preempt me is set to true, indicating that the thread should not be preempted while spinning. It then checks if kernel wanted to preempt me is true. If the kernel has signaled its intent to preempt this thread, the current thread yields, relinquishing the CPU to allow other threads, potentially including the one signaling preemption, to run. This yield is a form of cooperative multitasking, allowing the scheduler to decide the next thread to execute. 

The kernel might want to preempt a thread to ensure fairness or to respond to higher-priority tasks. However, user threads might need to perform critical operations that cannot be interrupted. The do not preempt me flag serves as a notification to the kernel. If a thread is spinning on a lock and this flag is set, it indicates that the thread is in a critical section and should not be preempted. The kernel, upon observing this flag, might defer preemption. 

The discussion then broadens to consider variations and improvements upon this basic model. The kernel might need to ignore the do not preempt me flag if a thread holds a lock for an excessively long period, as this could lead to system unresponsiveness. Researchers have proposed mechanisms to address this, such as Solaris's schedctl, which allows for more sophisticated scheduling decisions. 

The text then mentions that the test and set spin lock implementation can be adapted for various scenarios, including those requiring backoff, locality awareness, timeout, or double-checked or asymmetric locking. Fair queuing, which ensures that threads acquire locks in the order they requested them, is noted as being more challenging to implement. The problem of lock convoying, where a line of waiting threads is formed, is also mentioned. 

A significant challenge arises when a thread attempting to acquire a lock is preempted while holding the lock. Kontothanassis et al proposed extensions to the kernel interface to address this. These extensions allow a thread to pass a lock to another thread atomically. This is particularly useful in distributed systems or complex multithreaded applications. He et al further elaborate on this by describing queue-based locks where a releasing thread can estimate the waiting time of the next thread in line. 

This approach aims to optimize lock transfer efficiency and reduce contention. The mechanism involves periodically writing the wait time into a lock queue node. If the difference between the current time and the time in the successor's queue node exceeds a certain threshold, it indicates that the successor thread has likely been preempted or is otherwise unavailable. In such cases, the lock is not passed directly, and the thread that just released the lock can resume its execution or attempt to pass the lock to the next eligible thread. 

One hundred thirty eight. Seven Synchronization and Scheduling. Seven point five point three Resource Minimization. In addition to avoiding unnecessary crossings in and out of kernel mode, the futexes of Linux and the lwp_park-based mutexes of Solaris also eliminate the need to allocate a kernel-level condition queue for every lock. Lists of blocked threads are kept in user-level memory; within the kernel, a waiting thread is simply descheduled, with a note in its context block that indicates what it is waiting for. 

Since kernel address space is often a scarce resource, especially for preallocated structures, this migration of information into user space may significantly increase the maximum number of locks a system can support. A similar observation regarding kernel resources was made by the designers of the NT kernel, the foundation for Microsoft OS releases starting with Windows two thousand. Compared to Unix variants, the Windows API includes a much larger number of standard library routines. 

These in turn declare a very large number of internal locks, Windows mutex objects, most of which are never used in a typical program. To economize on kernel resources, NT delays allocating a kernel queue for a given lock until some thread actually tries to acquire the lock. Kernel space is still required for every active lock, and kernel-mode crossings occur on every acquire and release, but space is never wasted on locks that are not used. 

Unfortunately, delayed allocation of kernel queues raises the possibility of a run-time exception if space is not available. This possibility was a source of considerable complexity and brittleness in Windows two thousand. To eliminate the run-time exception, the designers of Windows XP introduced the notion of keyed events, which allow logically distinct conditions to share a single kernel-level queue. Every call to wait or set must specify both an event and a thirty-two-bit key. 

Every thread waiting in the queue is then tagged with the key it provided, and set will only awaken a thread with a matching key. Under most circumstances, the kernel allocates a new keyed event for every active lock. If it runs out of memory, however, it falls back to a preexisting per-address-space keyed event with a new lock-specific key. In Windows XP, which used a linked list for the per-address-space queues, performance could sometimes be a problem. Windows Vista replaced the list with a hash table for fast key-based lookups. 

It also introduced a new family of synchronization objects, including a slim reader-writer lock, or SRWL. Like futexes and lwp_park-based mutexes, these objects maintain state in user-level memory and avoid kernel-mode crossings whenever possible. When a thread does need to block, it always employs the per-address-space queue. The concept of resource minimization in operating systems, particularly concerning synchronization primitives, is explored. 

The text discusses techniques to reduce overhead associated with locks, which are fundamental for managing concurrent access to shared resources in multiprocessor systems. One approach mentioned is the use of futexes, or fast userspace mutexes, exemplified by their implementation in Linux and Solaris. These futexes allow certain synchronization operations to be handled entirely in user space, thereby avoiding the performance cost of context switching into kernel mode for every lock acquisition or release. 

The foundational concept explored here is that of nonblocking algorithms, which are a class of concurrent algorithms designed to avoid issues such as deadlock and livelock, often associated with traditional lock-based synchronization mechanisms. When constructing concurrent data structures, the primary goal is typically to achieve atomicity, meaning that operations appear to execute as a single, indivisible unit. Most conventional algorithms accomplish this through mutual exclusion, commonly implemented using locks. 

Locks, however, can lead to undesirable behaviors. A thread attempting to acquire a lock might become blocked, either through spinning—repeatedly checking if the lock is available—or by being descheduled by the operating system. If a thread holding a lock is preempted by the system, or if it encounters an error, other threads requiring that lock can be stalled indefinitely. This scenario, where a thread is unable to make progress due to the state of the system or the actions of other threads, is a critical concern. 

Nonblocking algorithms aim to circumvent these issues by ensuring that at least one thread always makes progress. This is often achieved through optimistic approaches, where threads attempt operations without explicit locks, and if a conflict is detected, they retry. The requirement of atomicity remains paramount, and the formal definition of atomicity in this context is often related to linearizability, a strong correctness condition that ensures operations appear to execute instantaneously at some point between their invocation and completion. 

While lock-based algorithms are prevalent due to their conceptual simplicity, nonblocking algorithms offer a robust alternative, especially in environments with high contention or where fairness and guaranteed progress are critical. For certain data structures, such as counters, stacks, queues, and linked lists, nonblocking implementations can even outperform their lock-based counterparts, particularly under heavy load. This performance advantage stems from their ability to avoid the overhead and latency associated with lock acquisition and release, and their resilience to thread preemption. 

Hash tables, and even skip lists, are examples of data structures that have benefited from efficient nonblocking designs. The field of nonblocking algorithms is a dynamic and extensive area of research. The study of nonblocking data structures and algorithms is further supported by significant contributions in the literature, including the work by Herlihy, Shavit, and others, who have provided extensive surveys and foundational theoretical frameworks. Hakan Sundell's Ph.D. thesis and the survey by Moir and Shavit are highlighted as valuable resources for understanding the core concepts and techniques in this domain.
