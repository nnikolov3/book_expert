Four point three, Queued Spin Locks. 

Queued spin locks represent a class of synchronization primitives crucial for managing access to shared resources in multi-processor systems, aiming to reduce contention and ensure fairness. The fundamental challenge they address is the high cache invalidation traffic inherent in simple test and set spin locks, where all waiting processors contend for the same cache line.

Early designs, such as those proposed by Anderson, and by Graunke and Thakkar, conceptually implement the queue as an array of n flag words, where n represents the maximum number of threads in the system. Each thread is assigned a distinct element in this array to spin upon, effectively distributing the contention. In Anderson's scheme, a thread acquires its lock by knowing its assigned index. The release mechanism involves using an atomic fetch and increment operation on a shared counter, which then dictates the next element in a circular order to be released. The releasing thread updates the element corresponding to its original spin location. Conversely, Graunke and Thakkar's approach uses an atomic swap operation on an extra tail element to manage the queue, where array elements are statically allocated. This design allows a thread to identify its designated spin element by performing a swap that effectively enqueues it.

Inspired by the Q O L B hardware primitive of the Wisconsin Multicube, Goodman et al. in one thousand nine hundred eighty nine, and the I triple E S C I standard, Aboulenein et al. in one thousand nine hundred ninety four, section two point three point three, Mellor Crummey and Scott in one thousand nine hundred ninety one b devised a queue-based spin lock that employs a linked list instead of an array. Craig and, independently, Magnussen et al. devised an alternative version that, in essence, links the list in the opposite direction. Unlike the locks of Anderson et al. and Graunke and Thakkar, these list-based locks do not require a static bound on the maximum number of threads; equally important, they require only Order of n plus j space for n threads and j locks, rather than Order of n j. They are generally considered the methods of choice for F I F O locks on large-scale systems. Note, however, that strict F I F O ordering may be inadvisable on a system with preemption; see section seven point five point two.

The M C S lock, or Mellor-Crummey and Scott lock, is a notable example of such a queued spin lock. It operates by having each thread allocate a qnode record, which contains a queue link and a Boolean flag. The lock itself is represented by a pointer to the qnode of the thread at the tail of the queue, or null if the lock is free. When a thread wishes to acquire the lock, it initializes its qnode, sets its next pointer to null, and swaps it into the tail of the queue. If the value returned by the swap is null, the calling thread has acquired the lock. If the value returned by the swap is non-null, it refers to the qnode of the caller's predecessor in the queue, and the caller must update its predecessor's qnode to point to its own qnode.

Upon completion of its critical section, the lock-holding thread executes the release method. This process involves reading the next pointer of its own qnode to identify its immediate successor in the queue. It then modifies the Boolean waiting flag within this successor's qnode, setting it to false. This action signals the successor thread to cease spinning and proceed with its own critical section, effectively handing off the lock in a F I F O manner. If the lock-holding thread's qnode's next pointer is null when it attempts to release the lock, it implies there are no pending successors, and the lock simply becomes free.

The M C S lock has several important properties. Threads join the queue in a wait-free manner, utilizing a swap operation, after which they receive the lock in F I F O order. Each waiting thread spins on a separate memory location, eliminating contention for cache and interconnect resources. In fact, because each thread provides its own qnode, it can arrange for it to be local, even on an N R C N U M A machine. The total time for remote access to pass the lock from one thread to the next is constant. The total space requirement is linear with respect to the number of threads and locks.

As written, the M C S lock requires both swap and compare and swap operations. Compare and swap can, of course, be used to emulate the swap operation within the acquire method, but the entry cost to the queue drops from wait-free to lock-free, implying that a thread could theoretically starve. Mellor Crummey and Scott, in their 1991 publication B, also demonstrate how to achieve this with only a swap operation in the release method. However, F I F O ordering may be lost when a thread enters the queue just as its predecessor is releasing the lock.

One disadvantage of the M C S lock is the need to pass a qnode pointer to acquire and release. Test and set and ticket locks pass only a reference to the lock itself. If a programmer wishes to convert code from traditional to queued locks, or to design code in which the lock implementation can be changed at system configuration time, it is natural to wish for a version of the M C S lock that omits the extra parameters, and can be substituted in without rewriting all the call points. Auslander et al. two thousand three devised such a version as part of the K forty two project at I B M Research, Appavoo et al. two thousand five. Their code exploits the fact that once a thread has acquired a lock, its qnode serves only to hold a reference to the next thread in line. Since the thread now owns the lock, it can move its next pointer to an extra field of the lock, at which point the qnode can be discarded.

The management of shared resources in concurrent systems necessitates robust synchronization primitives. Traditional spin locks, while simple, introduce significant performance bottlenecks due to cache line contention and excessive bus traffic under high concurrency. This arises as multiple processors repeatedly attempt to read and modify the same lock variable, leading to cache invalidations and memory system thrashing. To mitigate this, queued spin locks, such as the M C S lock, were devised. The core principle of a queued spin lock is to distribute the waiting overhead among the contending threads, thereby reducing global contention on a single lock variable.

Consider the operational mechanics of the M C S lock, illustrated through a series of states. Initially, in state one, the global lock variable, denoted as 'L', points to a null or empty state, indicating that no thread holds the lock and the waiting queue is empty. When a thread, let us call it A, attempts to acquire the lock, as seen in state two, it performs an atomic Compare And Swap operation on 'L'. If 'L' is null, A successfully acquires the lock, and 'L' is updated to point to A's own dedicated queue node, or 'Q node'. This Q node for thread A is depicted as a rectangular box, and the '(R)' inside it signifies that thread A is currently running its critical section, having successfully acquired the lock. Importantly, with M C S locks, each waiting thread spins on a flag within its own Q node, rather than on the global lock variable, thus localizing cache invalidations to only the Q node memory location.

In state three, while thread A holds the lock, a second thread, B, arrives and attempts to acquire it. Since 'L' is not null, B cannot acquire the lock immediately. Instead, B atomically updates 'L' to point to its own Q node, and critically, it sets its predecessor pointer to A's Q node. This forms a linked list structure for the queue. B's Q node is shown to the right of A's, with a solid arrow from A's Q node pointing to B's. The '(W)' in B's Q node indicates that thread B is waiting. A dashed arrow originates from an abstract point associated with B's Q node and points back to A's Q node, representing B's local pointer to its predecessor in the queue, which is essential for the handoff mechanism.

As concurrency increases, depicted in state four, a third thread, C, arrives while A is running and B is waiting. Similar to B, C cannot acquire the lock directly. C appends its Q node to the end of the queue, atomically updating 'L' to point to its Q node, and B's Q node's successor pointer is updated to point to C's Q node. C's Q node also contains '(W)', signifying it is waiting, and a dashed arrow from C's Q node points back to B's, representing C's local pointer to its predecessor. At this juncture, the lock 'L' consistently points to the tail of the queue, which is C's Q node, while the queue itself is formed by A pointing to B, and B pointing to C.

The lock release mechanism is a critical aspect of the M C S design. When thread A completes its critical section and releases the lock, as shown in state five, it does not modify the global 'L' variable if there are successors. Instead, it directly notifies its successor in the queue, which is thread B. Thread A does this by writing to a specific field within B's Q node, typically changing its waiting flag from 'W' to 'R' (conceptually, setting a flag that B is spinning on). Upon detecting this change, B ceases spinning and enters its critical section. A's Q node then effectively detaches from the active queue. The global lock 'L' continues to point to C, as C is still the tail of the conceptual queue.

Subsequently, in state six, when thread B finishes its critical section and releases the lock, it follows the same protocol. B notifies its successor, thread C, by modifying C's Q node, changing its state from 'W' to 'R'. Thread C then proceeds into its critical section. Again, the global lock 'L' remains pointing to C.

Finally, in state seven, when thread C completes its critical section and releases the lock, it finds no successor in the queue. In this scenario, C atomically attempts to set the global lock variable 'L' back to null. This C A S operation ensures that if no other thread has concurrently appended itself to the queue, the lock is properly released and reset to its initial idle state. If another thread had managed to append its Q node after C acquired the lock but before C released it and attempted to nullify 'L', C's C A S would fail, and it would then proceed to notify that newly appended thread, maintaining the queue integrity.

A notable design consideration for the M C S lock, highlighted in the discussion, is its inherent requirement to pass a Q node pointer to the acquire and release routines. This deviates from more traditional spin lock Application Programming Interfaces, such as those for simple Test And Set or ticket locks, which typically only require a reference to the lock variable itself. This difference poses a challenge for integrating M C S locks into existing codebases designed for simpler lock interfaces without extensive modifications. To address this, a variant, notably implemented in the K forty two project at I B M Research, proposes a modification to the lock's structure. Instead of a single pointer to the tail, an idle, unheld lock is represented by a Q node that contains two null pointers. One serves as the conventional tail pointer for the M C S queue. The other is a "next" pointer, which specifically refers to the Q node of the first waiting thread. This dual pointer structure allows a newly arriving thread to use a C A S operation to replace a null tail pointer, implicitly managing the initial queuing, thus potentially simplifying the A P I for legacy systems. This adaptation effectively embeds some of the Q node management logic directly within the lock's state, enabling a more seamless transition from simpler spin lock paradigms to the more efficient M C S queuing mechanism.
