The field of concurrent algorithms and synchronization techniques is characterized by its profound complexity and extensive historical development. Achieving correct and efficient concurrent execution necessitates a deep understanding of formal methods, given that informal approaches often prove inadequate. The foundational principles are extensively formalized in seminal texts, providing the necessary mathematical rigor for practitioners and theoreticians alike.

At its core, concurrent computing addresses the challenge of coordinating multiple computational agents, whether threads or processes, that operate simultaneously. Within this domain, shared memory concurrency represents a critical paradigm where these agents directly access and modify a common memory space. This direct interaction mandates sophisticated synchronization mechanisms to prevent data inconsistencies and race conditions, which arise when multiple threads access shared data without proper coordination, leading to unpredictable outcomes.

A critical aspect of analyzing concurrent systems involves defining and ensuring specific correctness properties. Foremost among these are safety and liveness. Safety properties guarantee that bad things never happen, meaning the system always remains in a valid state and avoids erroneous computations or transitions. This is often framed as maintaining system invariants or ensuring that all reachable states are correct. Conversely, liveness properties ensure that good things eventually do, meaning the system makes progress and desired events or computations are ultimately completed. This mitigates issues like deadlock, where processes halt indefinitely waiting for each other, or starvation, where a process never gets the resources it needs.

The theoretical underpinnings of concurrent systems also encompass the consensus hierarchy and formal memory models. The consensus hierarchy provides a fundamental classification of synchronization primitives based on their computational power, specifically their ability to solve the consensus problem. Primitives higher in this hierarchy, such as compare and swap, can implement any lower-level primitive, while the reverse is not true. This hierarchy dictates the expressiveness and limitations of various hardware and software constructs available for concurrent programming. For instance, the test and set primitive, a basic atomic read-modify-write operation, occupies a lower level in this hierarchy compared to compare and swap. Test and set atomically reads a value from a memory location, sets that location to a specific value, typically a binary one, and returns the original content. This is a common building block for simple locks. Compare and swap, on the other hand, is a more versatile atomic instruction. It takes an address, an expected value, and a new value. If the content of the memory address matches the expected value, it is updated to the new value; otherwise, the operation fails. The atomicity of both test and set and compare and swap is paramount in preventing concurrent updates from corrupting shared data.

Formal memory models are indispensable for precisely defining the semantics of memory operations in multiprocessor systems. They specify the rules governing when a write operation performed by one processor becomes visible to other processors, and how memory operations may be reordered by the hardware or compiler for performance optimization. Understanding these models is crucial because out of order memory references, a common optimization technique where the execution order of memory operations deviates from program order, can lead to unexpected behaviors if not properly managed through explicit memory barriers or fences defined by the chosen memory model. These models range from strong consistency models like sequential consistency, which is intuitive but often expensive, to more relaxed models that allow greater reordering for performance but require programmers to reason more carefully about concurrency.

The concept of safety is further elaborated in the context of concurrent data structures, often referred to as objects. These are adaptations of sequential data structures designed to operate correctly and efficiently when accessed concurrently by multiple threads. Each method exposed by such an object must possess its own sequential semantics, meaning its behavior, when viewed in isolation or as part of a single thread's execution, must be well defined. The correctness of these methods is formally specified through preconditions and postconditions. A precondition defines the state that must be true before a method is invoked for it to behave correctly. A postcondition describes the state that will be true upon the successful completion of the method. Furthermore, all methods must preserve invariants, which are properties of the data structure that must hold true before and after any method execution, thereby ensuring the structural and semantic integrity of the object across all concurrent operations. A sequential implementation of such an object is considered safe if, provided its preconditions are met, any method invocation terminates in a finite number of steps, establishes its postconditions, and meticulously preserves all defined invariants, even in a highly concurrent environment. This rigorous approach to formal specification is essential for constructing robust and correct concurrent systems.

When designing a concurrent object, a primary objective is to ensure that its method calls, often referred to as operations, appear to occur atomically. This atomicity is fundamental for maintaining program correctness and predictability in a multi-threaded environment. Achieving this objective necessitates addressing several critical safety issues. The first safety issue arises from the inherent difficulty of managing preconditions in concurrent programs. In a sequential program, if an attempt is made to invoke a method whose precondition does not hold, it is typically deemed an error. A single thread of execution possesses complete control over the order in which methods are invoked and can reliably verify the precondition before proceeding. However, in a parallel program, the state of shared data can change unexpectedly between the time a precondition is checked and the actual method invocation occurs. To mitigate this race condition, three principal approaches exist. Firstly, a method can be designed to be total, meaning its precondition is always satisfied, allowing it to run under any circumstances, perhaps by returning a specific error value if the operation cannot logically complete. Secondly, condition synchronization mechanisms, such as monitors or condition variables, can be employed to compel the invoking thread to wait until the precondition becomes true. This ensures that the method executes only when its necessary conditions are met. Thirdly, the method can be designed to return a special bottom value, indicating that the operation was not valid at the time of invocation, such as returning this value when attempting to dequeue from an empty queue. This approach shifts the responsibility for error handling to the caller.

The second safety issue in concurrent object design is the possibility of deadlock. This occurs when threads become perpetually blocked, each waiting for a resource that is held by another thread within the waiting set. Deadlocks are a consequence of particular resource allocation policies and thread interactions, often stemming from the use of locking mechanisms or explicit condition synchronization. Understanding and preventing lock-based deadlock is crucial, as it represents a permanent cessation of progress for the involved threads. Such deadlocks are primarily an application-level semantic problem and require careful, program-by-program analysis to identify and resolve.

The third safety issue revolves around the precise notion of atomicity. While the goal is for operations to appear atomic, the actual interleaving of instructions from different threads can lead to complex and unintuitive behaviors if atomicity is not rigorously defined and enforced. If operations are not truly executed in a mutually exclusive manner, the specific order in which they appear to occur becomes critical for correctness. This mandates a clear understanding and specification of ordering properties within concurrent systems. Various models of atomicity, such as linearizability or sequential consistency, address these challenges by providing formal guarantees about how operations from different threads appear to interleave.

Delving deeper into the concept of Deadlock Freedom, it is formally classified as a safety property in concurrent systems. A system is considered deadlock-free if there is no reachable state in which a set of threads are indefinitely waiting for one another, leading to system stasis. This foundational concept was rigorously articulated by Coffman and colleagues in nineteen seventy-one, who identified four simultaneous necessary and sufficient conditions for deadlock to occur. All four of these conditions must be present for a deadlock to manifest.

The first condition is exclusive use, also known as mutual exclusion. This principle dictates that at least one resource involved in the potential deadlock must be non-sharable, meaning it can only be used by one thread at a time. Examples include a printer or a write lock on a data structure. If resources were freely shareable, conflicts over their access would not arise.

The second condition is hold and wait. This describes a scenario where a thread holds at least one allocated resource while simultaneously waiting to acquire additional resources that are currently held by other threads. A thread does not release its existing resources until it has successfully acquired the new ones it needs.

The third condition is irrevocability, or no preemption. This means that resources cannot be forcibly taken away from a thread that is currently holding them. A resource can only be released voluntarily by the thread that acquired it, once that thread has completed its operation with the resource.

Finally, the fourth condition is circularity, also known as circular wait. This signifies the existence of a circular chain of two or more threads, where each thread in the chain is waiting for a resource that is held by the next thread in the chain. For instance, thread A holds resource X and waits for resource Y, which is held by thread B; thread B holds resource Y and waits for resource Z, held by thread C; and thread C holds resource Z and waits for resource X, held by thread A. This circular dependency is the hallmark of a deadlock. The absence of any one of these four conditions is sufficient to prevent the occurrence of deadlock.

In shared-memory parallel programs, non-sharable resources often correspond to portions of a data structure, with access protected by mutual exclusion mutex locks. Given that exclusive use is fundamental, deadlock can then be addressed by breaking any one of the remaining three conditions. For example, one can break the hold-and-wait condition by requiring a thread that wishes to perform a given operation to request all of its locks at once. This approach is impractical in modular software, or in situations where the identities of some of the locks depend on conditions that cannot be evaluated without holding other locks. Suppose, for example, that we wish to move an element atomically from set A to set F of V, where V is the value of the element drawn from set A.

Alternatively, one can break the irrevocability condition by requiring a thread to release any locks it already holds when it tries to acquire a lock that is held by another thread. This approach is commonly employed automatically in transactional memory systems, which are able to back a thread out and retry an operation that encounters a locking conflict. It can also be used, more manually, in any system capable of dynamic deadlock detection. Retrying is complicated by the possibility that an operation may already have generated externally visible side effects, which must be rolled back without compromising global invariants.

The third method aims to disrupt the circularity condition by imposing a static order on locks, and requiring that every operation acquire its locks according to that static order. This approach is slightly less onerous than requiring a thread to request all its locks at once, but still far from general. It does not, for example, provide an acceptable solution to the move from A to F of V example in strategy one above.

Strategy three is widely used in practice. It appears, for example, in every major operating system kernel. The lack of generality, however, and the burden of defining and respecting a static order on locks, makes strategy two quite appealing, particularly when it can be automated, as it typically is in transactional memory. An intermediate alternative, sometimes used for applications whose synchronization behavior is well understood, is to consider, at each individual lock request, whether there is a feasible order in which currently active operations might complete, under worst-case assumptions about the future resources they might need in order to do so, even if the current lock is granted. The best-known strategy of this sort is the Banker's algorithm of Dijkstra, originally developed for the THE operating system. Where strategies one and three may be said to prevent deadlock by design, the Banker's algorithm is often described as deadlock avoidance, and strategy two as deadlock recovery.

In the realm of shared memory parallel programs, a core challenge arises from the contention for non-sharable resources, which are typically safeguarded by mutual exclusion locks, often referred to as mutexes. The presence of mutual exclusion is a fundamental prerequisite for the occurrence of deadlocks. Therefore, to address the issue of deadlock, one must systematically break one of the additional necessary conditions that, alongside mutual exclusion, collectively constitute the classic definition of a deadlock state.

One approach involves breaking the hold and wait condition. This strategy mandates that any thread aiming to execute a specific operation must simultaneously request and acquire all necessary locks upfront in an atomic fashion. The underlying principle is to ensure that a thread either obtains all the resources it requires for its operation or none at all, thereby preventing it from holding some resources while indefinitely awaiting others that are currently held by different threads. However, this method presents significant practical hurdles, particularly in modular software architectures where the complete set of required locks for an operation may not be known a priori. Furthermore, the identities of certain locks might be dynamically dependent on runtime conditions that can only be evaluated after some initial resources have been acquired. For instance, consider an operation to move an element from set A to set F of V, where V represents the value of the element; the specific lock for F of V cannot be determined until V is accessed, making static pre-acquisition problematic.

A second strategy focuses on breaking the irrevocability condition, which is fundamentally the principle of no preemption. This is achieved by requiring a thread to relinquish any locks it currently holds if it attempts to acquire a lock that is already held by another thread. This mechanism often underpins deadlock recovery or optimistic concurrency control. It is commonly implemented automatically in transactional memory systems, which are designed to support atomic transactions. When a transaction encounters a locking conflict, it can be backed out or aborted, causing it to release all its held resources and then typically retry the operation. This approach can also be applied through dynamic deadlock detection, where deadlocks are allowed to occur, subsequently identified, and then resolved through explicit manual preemption and retry. A critical complexity with this strategy arises when an operation has already generated externally visible side effects. For instance, if data has been written to persistent storage or a network message sent, merely rolling back the internal state of the thread and releasing its locks is insufficient. The system must then devise intricate mechanisms to undo or compensate for these external changes to maintain global invariants, which poses a substantial design and implementation challenge.

The third method aims to disrupt the circular wait condition. This is accomplished by imposing a static, predefined order on all locks within the system. Every operation is then strictly required to acquire its necessary locks according to this established sequential order. Conceptually, by enforcing a total ordering of resource acquisition, it becomes impossible for a circular chain of dependencies to form, thereby preventing deadlocks. This approach is generally considered less onerous than requiring a thread to acquire all its locks at once, as seen in the first strategy, because threads do not need to know all future lock requirements immediately, only that any subsequent lock must be acquired in increasing order. Despite its advantages, this strategy suffers from a lack of generality and can impose a significant burden in terms of defining and rigorously respecting the static lock order, especially in complex systems. It is, however, widely adopted in practice, particularly within major operating system kernels, where the system has precise control over resource allocation and can enforce strict ordering rules.

While strategy three is prevalent in operating system kernels, its lack of generality can be limiting. The complexities of defining and adhering to a strict static order for all resources often make strategy two, based on preemption and rollback mechanisms such as transactional memory, quite appealing, particularly due to its potential for automation. An intermediate alternative, which examines synchronization behavior from a different perspective, involves a form of deadlock avoidance. This entails dynamically assessing whether a feasible order exists for currently active operations to complete, even under worst-case assumptions about their future resource requirements, and irrespective of whether the current lock request is granted. The most well-known algorithm for this type of strategy is the Banker's algorithm, originally conceived by Dijkstra in the early nineteen sixties and later refined. This algorithm requires processes to declare their maximum resource needs in advance and then verifies that granting a resource request will not lead to an unsafe state, one from which a deadlock could potentially occur. Thus, broadly categorizing these approaches, strategies one and three are considered forms of deadlock prevention, as they structure the system to inherently preclude deadlock. The Banker's algorithm exemplifies deadlock avoidance, as it dynamically checks for safe states to prevent entry into unsafe ones. Conversely, strategy two, with its reliance on preemption and rollback, falls under the umbrella of deadlock recovery, as it addresses deadlocks after they manifest.
