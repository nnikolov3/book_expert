Memory models are a crucial aspect of programming language design, defining the interface between a program's abstract semantics and its concrete execution environment. At the foundational level, a memory model specifies which values a read operation may observe, given a history of writes to that variable by other program steps. In a single-threaded program, the memory model operates under the principle of sequential consistency, where there exists a total, linear order of all program steps within any given execution. A read operation is valid if and only if it retrieves the value written by the most recent preceding write operation to that same variable within this total order.

However, in a multi-threaded program, the memory model becomes substantially more complex. A read operation in one thread may observe a value written by a distinct thread, and for an execution to be deemed sequentially consistent, there must exist a single, global total order of all memory operations originating from all threads. Most modern hardware architectures do not strictly enforce sequential consistency for all memory operations, leading to the need for a partial order relationship known as "happens-before." This partial order is established on the steps of an abstract execution and forms the basis for defining a "writes-seen" relation, which identifies, for every read operation, the set of writes whose values might legitimately be observed by that read.

The "happens-before" order is constructed by distinguishing between two fundamental categories of program steps: "ordinary" steps and "synchronizing" steps. Ordinary steps typically encompass simple reads and writes of scalar variables, while synchronizing steps are explicitly designed to impose ordering constraints and facilitate inter-thread communication. Examples of synchronizing steps include operations such as acquiring or releasing locks, initiating or concluding transactions, entering or exiting monitors, sending or receiving messages, and performing reads or writes on special atomic variables.

Given this distinction, the overall memory model incrementally defines two critical ordering principles: "program order" and "synchronization order." Program order represents a collection of disjoint total orders, one for each individual thread in the program, where each thread's sequence of steps must adhere to the sequential semantics of the language. Synchronization order, on the other hand, is a total order that spans across all threads and applies specifically to all synchronizing steps. This order must be consistent with the individual program order within each thread for those synchronizing steps, ensuring that properties such as mutual exclusion are guaranteed.

A related concept is the "synchronizes-with" order, which is a subset of the synchronization order induced by language semantics. In a language based on transactional memory, the subset may be trivial, with all transactions being globally ordered. In a language based on locks, each release operation may synchronize with the next acquire of the same lock in synchronization order, but may be unordered with respect to other synchronizing steps. The "happens-before" order is the transitive closure of program order and synchronizes-with order, capturing all the ordering guarantees provided by the programming language and its underlying memory model.

To complete a memory model, these order definitions must be augmented with a "writes-seen" relation. This relation is crucial for understanding the notion of a "data race," which occurs when a program contains two conflicting ordinary steps that are adjacent in a sequentially consistent execution. Data races are problematic because they lead to non-deterministic program behavior, making it difficult to reason about correctness. An abstract execution has a data race if it contains a pair of conflicting steps that are not ordered by "happens-before," and a program has a data race if, for some input, it has an execution containing a data race.

In an execution without any data races, the "writes-seen" relation is straightforward: all reads and writes of a given location are ordered by "happens-before," and each read can return the value written by the unique most recent prior write of the same location in "happens-before" order. This property allows one to formally prove that all executions of a data-race-free program are sequentially consistent, providing the formal basis for ensuring program determinism in concurrent environments. The connection between the absence of data races and the guarantee of sequential consistency is a cornerstone of modern memory model design, enabling the creation of predictable and correct concurrent systems.
