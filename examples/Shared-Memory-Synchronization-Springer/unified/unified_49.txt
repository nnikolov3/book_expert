The discussion centers on the intricacies of nonblocking algorithms, specifically addressing challenges in implementing concurrent data structures like deques. A key concept explored is the state management within a deque implementation, utilizing four states characterized by status flags, specifically L PUSH and R PUSH. These flags permit nonblocking progress, and a state transition, exemplified by a push right operation, can involve an initial Compare And Swap, or C A S, operation. This C A S modifies the status flag of an anchor, transitioning it from a STABLE state to one referencing a newly allocated node, and simultaneously updates a tail pointer.

The newly allocated node would have been initialized with a to-be-inserted value and a left pointer, referencing the previous tail node. Following this initial C A S, a second C A S operation serves to finalize the state change, updating the status flag to a coherent state, and simultaneously moving the deque's conceptual tail to point to the second-to-rightmost node. If this second pointer is incorrect, it indicates an incoherent state. The complexity of these state transitions is highlighted, noting that the actual code for such deque operations can be quite involved, and in some scenarios, an operation might fail and require a restart, especially when concurrent operations interfere.

The text then introduces Obstruction Free Bounded and Unbounded Deques, pointing out a principal shortcoming of Michael's deque implementation: the need to collocate head and tail pointers within a single word, often referred to as an anchor word. This colocation is necessary for efficient use of space, particularly when fitting these pointers into a C A S able word. However, it creates a dependency where all operations on the deque must serialize access to this anchor word, meaning that operations on opposite ends of the deque, such as a push to the head and a pop from the tail, must effectively serialize on this shared anchor.

The discussion references work by Herlihy et al. from Oracle Labs in Boston, specifically a paper from two thousand three, which introduced the concept of obstruction freedom. An obstruction-free algorithm guarantees that any thread will make progress within a bounded number of steps, provided it runs in isolation. This is contrasted with lock-free algorithms, which provide progress guarantees even under contention. The authors argue that by separating contention management mechanisms from the main algorithm, one can simplify the system and address issues of safety and liveness more effectively.

Double-ended queues provide an illustrative example, and nonblocking versions of transactional memory provide another. Michael's lock-free deque employs a linked list structure, whose length is limited only by the range of pointers that will fit in the anchor word. By contrast, the deque of Herlihy et al. employs a fixed-length circular array, which is most easily understood by first considering a noncircular version. At any given time, reading from left to right, the array will contain one or more L N, or left null, values, followed by zero or more data values, followed by one or more R N, or right null, values.

To perform a push right, one must replace the leftmost R N with a data value; to perform a pop right, one must read the rightmost data value and replace it with an R N. The left-hand cases are symmetric, and to find the leftmost R N, one can start at any entry of the array: if it's an R N, scan left to find the last R N; if it's an L N or data value, scan right to find the first R N. To reduce the time consumed, it is helpful to know approximately where to start looking, but the indication need not be exact.

Given these observations, the only two really tricky parts of the algorithm are, first, how to make sure that every operation maintains the L N, V, R N structural invariant, and, second, how to join the ends of the array to make it circular. The first challenge is addressed by adding a count to every element of the array, and then arranging for every operation to modify, in an appropriate order, a pair of adjacent elements. A push right operation, for example, identifies the index, k, of the leftmost R N value. If k is the rightmost slot in the array, the operation returns a deque is full error message. Otherwise, it performs a pair of C A S operations: the first increments the count in element k minus one, and the second replaces element k with a new data value and an incremented count.

A pop right operation goes the other way: it identifies the index, j, of the rightmost data value, and then performs its own pair of C A S operations. The first increments the count in element j plus one, and the second replaces element j with R N and an incremented count. Left-hand operations are symmetric, and the key to linearizability is the observation that only the second C A S of a pair changes the actual content of the deque. The first ensures that any conflict with a concurrent operation will be noticed, and since we read both locations before attempting a C A S on either, if both C A S operations succeed, no other operation modified either location in between.

If the first C A S fails, no change has been made; if the second C A S fails, no substantive change has been made. In either case, the operation can simply start over, and updates to the global left and right pointers constitute cleanup. Because the pointers are just hints, atomicity with the rest of the operation is not required, and updates to left and right need not interfere with one another. It is easy to see that the algorithm is obstruction-free: an operation that observes an unchanging array will always complete in a bounded number of steps. It is also easy to see that the algorithm is not lock-free: if a push right and a pop right occur at just the right time, each can, in principle, succeed at its first C A S, fail at the second, and start over again, indefinitely.

A push left on an empty deque can encounter a similar issue, but in practice, randomized backoff can be expected to resolve such conflicts quickly and efficiently. To make the deque circular, as indeed it must be if pushes and pops at the two ends are not precisely balanced, Herlihy et al. introduce one new dummy null D N value. The structural invariant is then modified to allow the empty portion of the circular array to contain, in order, zero or more R N values, zero or one D N values, and zero or more L N values. At all times, however, there must be null values of at least two different kinds, at least one R N or D N, and at least one D N or L N.

A push right that finds only one R N value in the array must change the adjacent D N value, if any, into an R N first. If there is no adjacent D N, the operation must change the leftmost L N, if any, into a D N first. In all cases, changes are made with a pair of C A S es, the first of which increments a count and the second of which is substantive. But circularity is not the only option: Graichen et al. observe that the same two-C A S protocol used to manipulate a data value and the adjacent dummy value can also be used, in a linked list of arrays, to manipulate a data value at the end of a non-circular array together with an adjacent pointer to another array.

This adapted protocol can then be used to add and remove arrays on demand, allowing the now unbounded deque to expand or contract at either end. The text then transitions to the topic of Work-Stealing Queues, a prevalent paradigm in parallel programming and library design, particularly for managing threads and tasks that leverage hardware parallelism. Worker threads are typically equipped with their own local task queues, managed by a user-level scheduler. The concept of work-stealing, first developed for the Cilk programming language, aims to minimize contention and maximize data locality by distributing tasks efficiently among threads.

In a work-stealing system, each worker thread maintains a local pool of tasks, and when a worker completes its current task, it draws a new one from its local pool. If the local pool is empty, the thread then attempts to steal a task from another thread's pool. The simplest strategy involves randomly selecting a peer thread and attempting to retrieve a task from its queue. Because tasks may be quite small, it is important that insertions and deletions from the local pool be very fast. Toward that end, Arora et al. developed a special-purpose deque that is carefully optimized for the work-stealing case.

This optimization assumes that push right and pop right operations are performed by a single thread, the local one, and thus need not be synchronized with one another. It also assumes that push left operations never occur, and synchronization is required only among pop left operations and, when a deque is nearly empty, between those operations and any concurrent push right or pop right operations. The efficiency of these operations, particularly insertions and deletions from the deque, is paramount for the performance of work-stealing, and this design distinction is critical because it isolates the primary thread's operations, reducing contention and improving performance.
