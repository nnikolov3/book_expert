Section four point three: Queued Spin Locks. 

Queued spin locks are a type of synchronization mechanism designed to manage access to shared resources in multi-threaded environments, particularly on multi-processor systems. Unlike simple spin locks, where threads repeatedly attempt to acquire the lock, potentially leading to excessive contention and cache line invalidations, queued spin locks improve fairness and efficiency by arranging waiting threads in a queue.

The queued spin lock mechanism is based on a data structure called a qnode, which represents a thread awaiting a lock. Each qnode contains a pointer to the previous qnode in the queue and an atomic boolean variable named succ must wait. This variable is used to signal to the successor thread when it can proceed.

The lock class manages the queue of qnodes. It contains an atomic pointer to a qnode called tail, which always points to the last qnode added to the queue. When a new lock object is instantiated, the tail is initialized to a new qnode with its prev pointer set to null and succ must wait set to false.

The lock class defines an acquire method that takes a pointer to a qnode, named p. Inside acquire, the succ must wait field of the qnode pointed to by p is atomically stored to true with sequential consistency. A qnode pointer named pred is declared and assigned the result of an atomic swap operation on the tail pointer. This swap operation simultaneously performs two actions: it sets the global tail pointer to the current thread's qnode, thereby enqueuing p, and it returns the previous value of tail, which effectively becomes p's predecessor.

The thread then enters a spin loop, continuously loading the succ must wait field of the qnode pointed to by pred. The loop continues as long as this value is true, using sequential consistency. This causes the thread to spin until its predecessor allows it to proceed. After the loop, a memory fence operation is performed with acquire or release acquire semantics, ensuring proper memory ordering.

The lock class also defines a release method that takes a double pointer to a qnode, named pp. Inside release, a qnode pointer named pred is declared and assigned the prev pointer of the qnode that pp points to. The succ must wait field of the qnode pointed to by pp is atomically stored to false with release acquire consistency. This signals to the next waiting thread that it can proceed. Finally, pp is updated to point to pred, transferring ownership of the predecessor's qnode.

Figure four point twelve depicts the C L H queued lock, and figure four point thirteen illustrates the operation of the C L H lock. An R indicates that a thread spinning on this qnode is free to run its critical section, while a W indicates that it must wait. Dashed boxes indicate qnodes that are no longer needed by successors and may be reused by the thread releasing the lock.

The C L H lock variant with a standard interface is also discussed. This variant serves as a plug-in replacement for traditional locks, providing its inherent scalability and reduced cache contention benefits to a wider range of concurrent applications. The operation is very similar to that of the original C L H lock, with the key difference being that the caller does not need to pass a qnode to release.

Section four point three point three: Hemlock. 

Hemlock is a remarkably simple and scalable variant of the C L H lock, presented by Dice and Kogan. Like a C L H lock, a Hemlock comprises a single word that is null when the lock is free and that otherwise identifies the last thread currently in line. There are, however, no qnodes. Instead, each thread uses a single status word, located in shared memory, to link into the queue of any lock for which it is currently waiting.

A thread that wishes to enter a critical section swaps the address of its status word into the lock's tail pointer. If the return value is null, the thread has acquired the lock. Otherwise, it has learned the address of its predecessor's status word, on which it proceeds to spin. To release a lock, a thread attempts a C A S on the tail pointer; this succeeds if and only if no other thread is waiting. In the failure case, the thread writes the lock's address into its status word. This written value serves to disambiguate cases in which a thread holds more than one lock and there is more than one successor spinning on the status word.

To avoid the possibility of a lost wakeup if the thread tries to release another lock before the first successor has noticed the wakeup, the release method waits for a handshake in which the first successor confirms that it has indeed noticed. If a thread holds a large number of locks, the wakeup operation may cause a flurry of coherence activity, as multiple potential successors reload the line to see who is being awoken. In the common case, in which a thread holds a single lock, coherence traffic is comparable to that of the C L H lock.

To reduce the overhead of handshakes, in which a thread obtains a status word in shared mode and must then upgrade it to exclusive, Dice and Kogan suggest the counter-intuitive but effective strategy of spinning, in both acquire and release, with C A S instead of load. This approach can be effective because C A S, as an atomic read-modify-write operation, provides stronger memory ordering guarantees and allows a thread to directly attempt to modify the state, rather than just observing it, potentially reducing contention and improving performance in certain high-concurrency scenarios.
