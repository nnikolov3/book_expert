Transactional memory, or T M, is a concept that has been explored in the context of concurrent programming, aiming to simplify the construction of library-level concurrent data abstractions. The idea of T M originated from the database community, where transactions have been used for many years to ensure data consistency and integrity. In the realm of T M, a transaction is a sequence of operations that are executed as a single, atomic unit, ensuring that either all operations are completed successfully or none are, thereby maintaining data consistency.

The core properties of T M are based on the A C I D semantics, which include atomicity, consistency, isolation, and durability. Atomicity ensures that a transaction is executed as a single unit, consistency ensures that the transaction maintains the correctness properties of the data, isolation ensures that the internal behavior of a transaction is not visible to other transactions, and durability ensures that the effects of a transaction survive system crashes. However, in the context of T M, the term "atomic" is sometimes used loosely, and durability is often dispensed with, as T M transactions typically do not require the same level of persistence as database transactions.

Composability is another key concept in T M, referring to the ability to combine smaller transactions into larger, atomic operations. This is achieved through the use of atomic blocks, which ensure that the operations within the block are executed indivisibly. The composability of transactions is a crucial aspect of T M, as it allows for the construction of complex concurrent operations from simpler ones, while maintaining data consistency and preventing race conditions and deadlocks.

The implementation of T M can be categorized into two main approaches: hardware transactional memory, or H T M, and software transactional memory, or S T M. H T M is generally faster, as it leverages direct hardware support, but S T M offers greater flexibility, as it can run on legacy hardware and support functionalities that are too complex for hardware implementation. The majority of research in the past two decades has focused on S T M, which has led to the development of various design dimensions, including progress guarantees, buffering of speculative updates, and access tracking and conflict resolution.

Progress guarantees refer to the ability of a T M system to ensure that transactions make progress, even in the presence of conflicts. Many early S T M systems were nonblocking, but later developments have shifted towards blocking implementations to achieve better expected-case performance. Buffering of speculative updates is another critical aspect of S T M, as it requires maintaining both old and new versions of speculatively modified data. The two most common approaches for buffering are "undo logging" and "redo logging", which involve buffering old values or new values, respectively, for write-back on abort or commit.

Access tracking and conflict resolution are also essential components of S T M, as they ensure that transactions do not conflict with each other. Eager systems detect conflicts as soon as a data location is accessed in a conflicting manner, while lazy systems defer conflict detection until the transaction attempts to commit. The choice between eager and lazy conflict detection involves trade-offs in terms of performance and complexity, impacting the efficiency of rollbacks and retries.

In conclusion, transactional memory is a powerful concept that aims to simplify concurrent programming by providing atomic execution of code blocks. The implementation of T M can be categorized into H T M and S T M, each with its advantages and disadvantages. The design dimensions of S T M, including progress guarantees, buffering of speculative updates, and access tracking and conflict resolution, are critical aspects that require careful consideration to ensure the correctness and efficiency of T M systems. As the field of concurrent programming continues to evolve, the development of T M is likely to play a significant role in shaping the future of parallel computing.
