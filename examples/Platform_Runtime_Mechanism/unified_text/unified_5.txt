Four point two point three point two P R M Module Runtime M M I O Ranges.This structure defines an array of P R M Module Runtime M M I O Range structures, which are declared by a P R M module and may be used by a P R M handler within that module. The structure serves as a declarative mechanism for specifying the memory mapped I O regions required for runtime operation, enabling the system firmware or operating system to properly configure access to hardware resources.Table four dash seven, titled P R M Module Runtime M M I O Ranges Structure, outlines the layout of this data structure in memory. It consists of two primary fields: Count and Runtime M M I O Range.The first field, Count, occupies eight bytes and is located at byte offset zero. This field specifies the number of P R M Module Runtime M M I O Range elements that immediately follow the structure header. By using an eight byte field for the count, the structure supports a very large number of entries, consistent with systems requiring fine grained or extensive M M I O resource declarations. This variable length design allows the P R M module to declare only the M M I O ranges it actually needs, avoiding fixed size allocations that could lead to inefficiency or inflexibility.The second field, Runtime M M I O Range, begins at byte offset eight and represents an array of P R M Module Runtime M M I O Range structures. The number of elements in this array is determined by the value stored in the Count field. Each individual element in the array describes a specific memory mapped I O region used by the P R M module. While the exact layout of each P R M Module Runtime M M I O Range is not detailed here, such structures typically include information such as the base physical address of the M M I O range, its size in bytes, and access permissions or memory attributes like cacheability and read write semantics.Memory mapped I O is a foundational concept in modern computer architecture, where hardware device registers and control buffers are mapped into the processor's physical address space. This allows the C P U to interact with peripherals using standard load and store instructions, rather than requiring dedicated I O instructions. As a result, the same memory management unit, or M M U, mechanisms that apply to regular memory—such as virtual address translation, access protection, and caching policies—can also be applied to device access, enhancing both performance and security.The P R M Module Runtime M M I O Ranges structure acts as a formal interface between the P R M module and the system software responsible for setting up the runtime environment. It enables declarative resource management, where the module explicitly states its hardware interface requirements. This is essential for the operating system or firmware to establish correct memory mappings, prevent address space conflicts between devices, and ensure secure and reliable access to hardware during system operation. The fixed byte offsets and lengths ensure predictable memory layout, which is critical for correct interpretation by both software and firmware components, particularly in sixty four bit systems where alignment and structure padding must be strictly observed.Moving to section five, Invocation of P R M Handlers.As previously described, P R M handlers can be invoked through two distinct mechanisms. The first is a direct call from an O S driver, which is possible when both the operating system driver and the O S A C P I subsystem are P R M aware. The second is invocation from A S L context, which occurs when the O S driver is not P R M aware and instead relies on the underscore D S M, or Device Specific Method, mechanism, or when platform events trigger a System Control Interrupt, or S C I, that invokes an underscore L x x method defined in A S L.Section five point one compares direct call versus A S L based invocation. For P R M aware operating systems and drivers, a direct call is recommended and preferred for several key reasons.First, using underscore D S M introduces a programming dependency into the system A C P I firmware. Unlike purely declarative A C P I tables that describe hardware capabilities, underscore D S M methods contain executable A M L logic. This means the firmware must actively manage and update the Acpi Parameter Buffer on behalf of the O S driver when invoking a P R M handler. Debugging such logic requires an A M L debugger, and any changes to the A S L code necessitate a full system reboot to reload the updated firmware, making development and maintenance more cumbersome.Second, underscore D S M limits the O S driver's control over interactions with the P R M module. In a direct call scenario, the O S driver can explicitly invoke P R M module update lock and unlock A P I s to protect critical sections of code, ensuring atomicity and data integrity during P R M operations. In contrast, with underscore D S M, this synchronization must be handled entirely within the firmware, removing control from the driver. Similarly, in a direct call, the O S driver can dynamically allocate and populate a Parameter Buffer to pass data to the P R M handler. With underscore D S M, data sharing is restricted to a fixed size buffer allocated by firmware during boot, which is populated by A M L code. If a P R M handler update requires a new parameter layout or additional data, the A S L code must be modified and the system rebooted. In a direct call, the O S driver manages the buffer directly, allowing for runtime flexibility without requiring firmware changes.Third, underscore D S M invocation incurs higher performance overhead due to the need to execute A M L bytecode within the A C P I interpreter. This interpretive execution is inherently slower than a direct call to native firmware code, introducing latency and reducing efficiency, especially in time sensitive operations.Despite these drawbacks, underscore D S M remains widely used in existing systems as a standardized abstraction for invoking platform firmware services. To maintain backward compatibility with this large installed base, the underscore D S M invocation path is retained. Additionally, certain hardware events—such as thermal alerts, power state transitions, or P C I E hot plug events—can generate an S C I that triggers an underscore L x x method in A S L, which in turn can invoke a P R M handler. This pathway is essential for event driven firmware responses that originate outside the scope of a specific device driver.Section five point two provides an overview of the invocation mechanism. The caller—whether an O S driver performing a direct call or A S L code executing in firmware context—passes specific information to the A C P I Bridge Driver.The first piece of information is the G U I D of the P R M handler to be invoked. This Globally Unique Identifier ensures that the correct handler is selected in systems that may host multiple P R M modules with overlapping functionality.The second piece of information is the Parameter Buffer. In the case of a direct call, the caller provides a pointer to this buffer, which it has allocated and populated with relevant data. In the case of an A S L based call, the A C P I Bridge Driver extracts the Acpi Parameter Buffer pointer from the P R M Table, or P R M T. If both are present, the directly supplied Parameter Buffer takes precedence, allowing the caller to override default parameters.The A C P I Bridge Driver then performs several critical steps to prepare for handler invocation.Step one: It identifies the P R M Handler pointer that corresponds to the provided G U I D. This involves a lookup in a table or registry of known P R M handlers.Substep a: Once the handler pointer is identified, it is converted from a physical address to a virtual address. This conversion is necessary because the operating system operates in a virtual memory environment. The A C P I Bridge Driver, running within the O S kernel, must access the handler using virtual addressing, which requires proper mapping through the memory management unit.Step two: The driver extracts the Static Data Buffer pointer and the Runtime M M I O Ranges pointer associated with the P R M module. These pointers reference critical data and hardware interface regions required by the handler.Using this information, the driver constructs a Context Buffer, which encapsulates the execution environment for the P R M handler. This buffer is defined in Table five dash one, titled Context Buffer Structure.Step three: The Context Buffer is passed to the P R M handler as part of the invocation.Step four: For A S L based calls, the driver extracts the Acpi Parameter Buffer pointer from the P R M T. For direct calls, the Parameter Buffer pointer is taken directly from the caller's input, and the Acpi Parameter Buffer is ignored.Step five: The P R M handler is invoked using a standardized calling convention. The function signature is defined as follows: E F I Status P R M Export A P I, followed by a function pointer named P R M Handler. This function accepts two input parameters. The first is an optional void pointer to the Parameter Buffer, which contains caller supplied data. The second is an optional pointer to a P R M Module Context Buffer, which contains system provided context such as resource pointers and configuration data. The E F I Status return value allows the handler to report success or specific error conditions back to the caller, enabling robust error handling.Section five point three details Direct Invocation. The A C P I Bridge Driver exposes an I O C T L interface—Input Output Control—that can be called by a P R M aware O S driver. Through this I O C T L, the driver passes the G U I D of the target P R M handler and a pointer to its Parameter Buffer. This mechanism enables tight integration between the operating system and platform firmware, allowing the O S to directly manage and respond to hardware level operations. It is noted that Direct Invocation is intended for future use in environments where the O S A C P I subsystem, O S drivers, and B I O S firmware are all P R M compatible, signaling a shift toward more dynamic and flexible platform management.Section five point four covers A S L underscore D S M Based Invocation. To enable runtime code execution from A S L, a bridging mechanism is required. A S L supports OpRegion handlers, which define addressable regions that A C P I methods can access. The P R M framework extends this by introducing a new OpRegion type named P R M. This allows A S L code to directly interact with P R M modules through a standardized interface. The OpRegion handler is synchronous, meaning the A C P I interpreter waits for the P R M handler to complete before continuing execution. This ensures predictable control flow but may introduce latency in time critical scenarios. Further details on the A C P I specific structures used for P R M support are provided in the D S M invocation section of the appendix.Section five point five describes the Context Buffer in greater detail. The Context Buffer is a well defined, per handler data structure that describes the resources available to a P R M handler during its execution. It is allocated by the operating system, which is also responsible for converting any physical addresses within it to virtual addresses, ensuring compatibility with the O S memory model. This buffer serves as the execution context for the handler, providing access to static data, M M I O ranges, and other essential resources.Table five dash one, Context Buffer Structure, defines the layout of this buffer. It contains a single documented field: Signature. This field is four bytes long and located at byte offset zero. It contains the ASCII characters P R M C, serving as a magic number or signature that identifies the structure as a valid P R M Module Context Buffer. This signature allows the P R M handler and system software to verify the integrity and type of the buffer upon receipt, preventing misinterpretation of memory and enabling early detection of errors. The presence of this signature at a fixed offset ensures consistent parsing across different implementations and platforms.
