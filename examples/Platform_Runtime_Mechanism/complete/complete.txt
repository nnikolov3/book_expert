System Management Mode, or S M M, is a highly privileged operating mode within the X eighty six computer architecture, specifically designed to allow the system firmware—such as B I O S or U E F I—to execute critical, platform specific functions that operate beneath the visibility and control of the operating system or virtual machine monitor. These functions are typically essential for system reliability, availability, and serviceability, including handling memory Error Correcting Code errors, managing advanced power states, executing O E M proprietary diagnostics, responding to hardware failures, and implementing workarounds for silicon level errata. Because S M M operates at a privilege level higher than even ring zero, it has unrestricted access to all system resources, including full control over memory and I O devices, making it a powerful but opaque mechanism for deep system management.Entry into S M M is triggered by a System Management Interrupt, or S M I. Unlike standard interrupts, an S M I is non maskable, meaning it cannot be ignored or disabled by software, and it is broadcast across all processors in the system, forcing each core to immediately respond. Upon receiving an S M I, every C P U thread completes its current instruction, saves its full execution context—including register state and program counter—into a protected memory region known as System Management Ram, or S M Ram, and then transitions into S M M to execute the corresponding S M I handler. This transition is transparent to the operating system and occurs regardless of the current execution state, including during hypervisor or kernel operations.The S M I handler, which is pre installed by the platform firmware during boot, runs in its own isolated environment. It sets up independent page tables and interrupt descriptor tables, allowing it to manage virtual memory and interrupts separately from the O S. Once the handler identifies the source of the S M I, it processes the event accordingly. S M Ram itself is architecturally isolated: it is not accessible to any code running at ring zero through ring three, ensuring that the S M M code and data remain protected from tampering by the O S or applications. Only when the processor is in S M M can it fetch and execute instructions from this memory region.S M Is are categorized into two types: asynchronous and synchronous. Asynchronous S M Is are generated by hardware events such as thermal thresholds, power faults, memory errors, or general purpose input output signals. Synchronous S M Is, on the other hand, are software initiated, typically by writing to I O port hexadecimal B two on Intel Architecture platforms. These software S M Is are often used by O S level components to request firmware services through standardized interfaces like A C P I or U E F I, with the S M I generation being transparent to the O S itself.Despite its utility, S M M introduces significant challenges, particularly in modern multi core systems. One major issue is performance degradation due to S M M latency. Because an S M I is a broadcast interrupt, all processors are stalled simultaneously, leading to unpredictable execution pauses. The duration of time spent in S M M, known as S M M latency, can range from approximately three hundred microseconds to one millisecond in a typical four socket server, depending on the number of active cores, the complexity of the handler, and the nature of the triggering event. During this period, no O S threads can execute on affected cores, which disrupts real time workloads and degrades overall system Quality of Service.Further complications arise from firmware complexity in many core environments. S M M was originally designed for simpler, single processor systems and does not scale well in highly concurrent architectures. For example, some C P U threads may be in a blocked state—such as during a Wait For S I P I, V M X shutdown, or Long Term Stable state—delaying their entry into S M M. Other threads might be executing long latency microcode operations like `wbinvd`, which invalidates cache lines, or loading a microcode patch, or be in a deep power saving state such as C six, all of which can delay the processor's response to the S M I. Additionally, when multiple S M Is are generated in rapid succession, some processors may observe a merged S M I event—where two interrupts appear as one—while others process them as separate events. This leads to out of sync S M I handling across cores, creating race conditions and inconsistent system states that are extremely difficult to debug.Another architectural concern is the lack of a unified hierarchy for S M M event sources. Events can originate from disparate hardware components without a centralized coordination mechanism, complicating the design of robust, scalable S M M handlers. Moreover, the complexity threshold for modifying or replacing S M M logic is narrow, as any changes require rigorous validation across a wide range of hardware and firmware configurations, making innovation and optimization challenging.The Advanced Configuration and Power Interface, or A C P I, plays a significant role in modern firmware design by providing a standardized way for the O S to discover, configure, and manage hardware components, particularly for power management. A C P I code is written in the A C P I Source Language, or A S L, and compiled into a bytecode format called A C P I Machine Language, or A M L, which resides in the platform firmware. In many current implementations, A C P I firmware acts as a bridge to S M M by triggering an S M I to invoke platform specific functionality that cannot be handled directly by the O S. This creates a dependency where high level O S requests are funneled through a low level, disruptive interrupt mechanism, further amplifying the performance and complexity issues associated with S M M.Given these challenges, there is a broad industry movement to reduce or eliminate the use of S M M during O S runtime, especially for non critical or frequently occurring events that contribute to unpredictable performance jitters. The goal is not to remove S M M entirely—since it remains essential for certain fault recovery and security critical operations—but to minimize its footprint. For instance, S M M may still be necessary during system boot or for handling catastrophic failures such as O S crashes or A C power loss, where it can perform error harvesting or ensure data persistence on Non Volatile D I M M s. However, these planned or end of life S M I events do not contribute to runtime performance instability and are therefore outside the scope of current mitigation efforts.To address the need for runtime efficiency, the Platform Runtime Mechanism, or P R M, has been proposed as an alternative pathway for invoking firmware services. P R M allows certain functions traditionally handled by S M M to be executed in a less intrusive manner, either through native O S drivers or by offloading tasks to dedicated hardware engines. This approach maintains compatibility with existing software interfaces—such as A C P I and U E F I—so that O S level components can continue to make the same requests without modification, while the underlying execution mechanism shifts away from S M M.For hardware triggered S M Is, such as those arising from memory errors or thermal events, migration strategies involve a combination of P R M and assistance from Out Of Band management agents. A Baseboard Management Controller, or B M C, is a prime example of such an agent. It is an independent microcontroller that operates even when the main C P U is powered down or unresponsive, capable of monitoring hardware sensors, logging events, and taking corrective actions without relying on S M M. By offloading these responsibilities to the B M C, the main processor avoids entering S M M for routine hardware events, thereby improving system responsiveness and reducing firmware complexity.Understanding current S M M usage is critical for identifying viable alternatives. S M Is are broadly classified by their trigger source: software or hardware. Software S M Is are initiated by writes to specific I O ports, such as hexadecimal B two, and are used by the O S or firmware to request runtime services. These are typically abstracted through A C P I or U E F I, so the O S remains unaware that an S M I has occurred. The challenge is to preserve this abstraction while replacing the S M M backend with a more efficient execution model. Hardware S M Is, in contrast, are generated autonomously by the platform in response to critical system events. While some of these must remain in S M M for immediate response, others can be redirected to alternative handlers via P R M or managed entirely by the B M C.In summary, S M M remains a foundational component of system management in X eighty six architectures, providing a secure and isolated environment for executing critical firmware code. However, its broadcast, non maskable nature and the resulting S M M latency introduce significant performance and complexity challenges in modern multi core, high availability systems. The industry is actively pursuing architectural evolutions—such as P R M and Out Of Band management—to reduce reliance on S M M during O S runtime, aiming to preserve system stability and firmware capability while eliminating unpredictable performance jitters and enhancing overall system transparency and maintainability.


Figure two one, titled S M I Triggers, depicts the architectural framework governing System Management Interrupts within a modern computing platform. At the highest layer is the O S, or Operating System, along with its associated drivers. This software layer interacts bidirectionally with three key firmware abstraction components: A C P I Tables, such as the Platform Communications Channel Table, or P C C T; A C P I Device Specific Methods, or _ D S M, exemplified by Address Range Scrubbing, or A R S; and U E F I Runtime Services, such as Set Variable. Collectively, these components form the O S to Platform Firmware Abstraction Interface, enabling the operating system to access platform-specific functionalities without requiring direct knowledge of the underlying hardware implementation.Beneath this abstraction layer lies the System Management Mode, or S M M, represented as a privileged execution environment isolated from the O S. S M M serves as the handler for System Management Interrupts and operates at a higher privilege level than the operating system or hypervisor, often referred to as ring minus two. It communicates bidirectionally with both the firmware abstraction layer above and the Platform Hardware below, which includes the C P U, memory subsystem, I I O controllers, and the Platform Controller Hub, or P C H. Two horizontal arrows indicate that both Software S M I Triggers—initiated by software writes to I O ports—and Hardware S M I Triggers—generated by physical events such as thermal thresholds or memory errors—are transparent to the O S. This transparency means the O S is unaware when an S M I occurs; the processor suspends normal execution, enters S M M, executes the firmware handler, and then resumes the O S seamlessly, preserving the illusion of uninterrupted operation.The reliance of O S and V M M entities on platform firmware abstractions stems from the fact that firmware maintains detailed, proprietary knowledge of silicon-specific features, configurations, and hardware dependencies. Embedding this knowledge directly into off the shelf operating systems would be impractical and unscalable across diverse hardware platforms. Therefore, standardized interfaces like A C P I are used to abstract these complexities. However, A C P I Source Language, or A S L, which defines A C P I methods and tables, operates in an interpreted environment with strict limitations. It cannot execute native Instruction Set Architecture, or I S A, specific instructions and lacks the flexibility required for complex firmware tasks. As a result, B I O S developers have historically resorted to invoking S M I handlers to transition into S M M, where they can run compiled native code with full hardware access.To address this limitation, a mechanism is proposed that allows A S L code to invoke platform runtime native code at the same privilege level as S M M, without requiring an uncontrolled drop into the S M M handler. This approach eliminates the need to use S M I solely for the purpose of executing native code, thereby reducing the attack surface and improving system transparency and debuggability.One illustrative example is the translation of a System Physical Address, or S P A, to a D I M M Address, or D A. This mapping is essential for memory error handling, particularly by the Linux E D A C driver, which must locate the physical position of a memory error within a D R A M module—specifically, the socket, memory controller, channel, rank, bank, column, and row. This translation logic is highly dependent on the specific processor generation, memory controller design, and even third party components such as X N C, or Node Controllers, used by some O E M s. Future platforms incorporating C X L, or Compute Express Link, devices will introduce additional complexity. To abstract this silicon-specific behavior, an A C P I _ D S M method was introduced, allowing the O S to query the firmware for the correct address mapping without encoding hardware-specific algorithms.A second example involves the P S H E D, or Platform Specific Hardware Error Driver, which operates as part of the Windows Hardware Error Architecture, or W H E A, and the Advanced Platform Error Interface, or A P E I. These O S level drivers manage hardware error reporting and recovery. Initially, a plug in model was developed to accommodate variations across platforms, but deployment proved difficult due to the need for platform-specific code in the driver. To resolve this, standardized A C P I tables were introduced: the Error Injection Table, or E I N J; the Error Record Serialization Table, or E R S T; and the Hardware Error Source Table, or H E S T. These tables allow the platform firmware to handle error injection, logging, and source identification, abstracting the hardware variance from the O S.A third example is the integration of N V D I M M s, or Non Volatile Dual In Line Memory Modules. These persistent memory devices require firmware-level management for tasks such as namespace configuration, health monitoring, and security operations. To support this, a dedicated set of A C P I _ D S M interfaces was defined, documented in the specification available at H T T P colon slash slash P M E M dot I O slash documents slash N V D I M M D S M Interface hyphen V one point six dot P D F. These _ D S M methods often trigger an S M I to execute within S M M, where firmware can perform privileged operations on the N V D I M M hardware. This pattern reflects a broader trend: O S entities rely on firmware abstractions to manage complex, hardware-specific behaviors, but the reliance on S M M introduces challenges in security, performance, and maintainability.S M I handlers are categorized into four distinct types based on their invocation source and privilege requirements. Category one consists of Software S M I Handlers that do not require S M M privileges. These are triggered by software, such as an O S calling an A C P I _ D S M, but their tasks do not involve accessing S M M restricted registers or memory. Category two includes Software S M I Handlers that do require S M M privileges, typically for operations involving secure variables or hardware configuration that must be protected from O S access. Category three comprises Hardware S M I Handlers that do not require S M M privileges; these are initiated by hardware events such as correctable memory errors or thermal alerts, but their handling does not necessitate exclusive S M M resources. Category four includes Hardware S M I Handlers that do require S M M privileges, such as those responding to uncorrectable hardware errors or critical system failures, where full control over hardware is essential.The term S M M privileges refers to the ability to access hardware resources that are only writable when the processor is in System Management Mode. These include registers with S M M only attributes, which are inaccessible to the O S, hypervisor, or even ring zero code. This isolation ensures that critical system management functions remain secure and tamper-proof.Software S M I s, encompassing Categories one and two, are typically invoked by writing to a specific I O port or executing a special instruction that signals the processor to enter S M M. Hardware S M I s, in Categories three and four, are generated autonomously by hardware components in response to events such as parity errors, power faults, or thermal excursions.The Platform Runtime Mechanism, or P R M, is introduced as a strategic evolution to reduce dependence on S M M. P R M provides a controlled, secure interface through which the O S can invoke native firmware code without triggering a full S M I. This mechanism is particularly effective for eliminating Category one S M I handlers, which perform useful but non-privileged tasks such as address translation or N V D I M M management. By migrating these handlers to P R M, the system reduces the amount of code running in the highly privileged S M M context, thereby enhancing security, improving debuggability, and decreasing latency.Figure two two, titled Categories of S M I Handlers, illustrates this classification within the current system model. On the left, a vertical bracket separates Software S M I handlers from Hardware S M I handlers. The top section, Category one, labeled S W S M I that don’t require S M M privileges, includes examples such as address translation and N V D I M M D S Ms. Two pathways emerge from this category: one leading to Native O S Support, indicating that some functions can be handled directly by the operating system, and another leading to A S L plus P R M, showing that firmware can use A C P I methods in conjunction with the Platform Runtime Mechanism to execute native code safely.Category two, under Software S M I, is noted to be primarily associated with U E F I authenticated variable services, such as secure boot variables, and is explicitly out of scope for this specification. These services require the full security guarantees of S M M and are not candidates for migration.Category three, Hardware S M I and R A S Handlers that don’t require privileges, includes events like correctable memory errors or platform health monitoring. These can, in some cases, be handled by P R M or Out of Band, or O O B, mechanisms, reducing the need for S M M invocation. An arrow labeled U E F I Variable Services and B I O S update connects Category two and Category three to a process involving Capsule Update, O S Driver, and O O B, indicating that firmware updates may leverage multiple pathways depending on privilege requirements.Category four, Hardware S M I and R A S Handlers that require privileges, deals with critical system events such as uncorrectable hardware errors and advanced Reliability, Availability, and Serviceability, or R A S, features. These handlers remain in S M M due to their need for direct, privileged access to hardware resources and are also out of scope for this specification.Section two point two elaborates on Category one usages. These are Software S M I triggers initiated through abstraction interfaces like A C P I _ D S M methods. Numerous such methods currently invoke S M I to execute complex algorithms—such as memory scrubbing, topology discovery, or firmware-assisted virtualization—in a native code environment. By providing an alternative execution path via P R M, the system can perform these tasks without entering S M M. This shift not only reduces the footprint of S M M code but also enables better integration with O S level debugging, logging, and security monitoring. Examples include R A S related D S M methods, such as address translation for error containment, and D S M methods supporting Non Volatile D I M M operations, including firmware activation, security erase, and health status reporting. The migration of these handlers to P R M represents a foundational step toward a more transparent, secure, and maintainable firmware architecture.


Two point three. Category three usages.Hardware System Management Interrupts, or H W S M I s, can be generated in response to asynchronous platform events such as memory errors and I O errors. These events occur independently of the processor’s normal execution flow and require immediate attention at the firmware level. When triggered, the System Management Interrupt, or S M I, causes the processor to enter System Management Mode, or S M M, a highly privileged and isolated execution environment. Within this mode, S M I handlers take control to diagnose and respond to the error condition.The primary function of these handlers is to gather detailed diagnostic information about the error. Once collected, this data is either surfaced to the operating system for further processing or logged to a Baseboard Management Controller, or B M C, enabling out of band monitoring and long term system health analysis. In addition to reporting, S M I handlers can initiate Reliability, Availability, and Serviceability, or R A S, events. These actions may include error remediation—such as correcting transient memory faults using Error Correcting Code, or E C C—or mitigation strategies like isolating faulty hardware components to prevent system instability or data corruption.Although the Platform Runtime Mechanism, or P R M, was primarily designed with Category one S M I handlers in mind—those managing time critical and security sensitive platform functions—Category three S M I handlers are also candidates for migration to the P R M framework. This transition is optional and determined by the platform vendor or Original Equipment Manufacturer, or O E M, based on system design goals and operational requirements.Category three S M I handlers are most commonly used for correctable error harvesting and reporting. Correctable errors, while not immediately catastrophic, provide valuable insight into system reliability trends and potential hardware degradation. Instead of invoking a full S M I for these events, a more efficient approach involves generating a System Control Interrupt, or S C I. An S C I operates within the normal operating system context and does not require entry into S M M. When an S C I is issued, it triggers the execution of A C P I Source Language, or A S L, code by the operating system’s A C P I driver. This A S L code can then leverage the P R M infrastructure to perform error data collection and reporting in a less intrusive and more standardized manner. This shift reduces the overhead associated with S M M entry and exit, improves system responsiveness, and enables greater integration with operating system level management tools.Section three. Platform Runtime Mechanism Overview.The Platform Runtime Mechanism, or P R M, represents a significant evolution in system firmware architecture by enabling the migration of certain platform management functions from System Management Mode, or S M M, to the operating system or Virtual Machine Monitor, or V M M, execution context. This transition applies specifically to operations that do not require the extreme privilege level of S M M, including certain Category one usages and a subset of Category three hardware S M I handlers.By moving these functions out of S M M, P R M eliminates many of the drawbacks associated with executing code in that environment. S M M is non preemptable, operates outside the purview of the operating system, and introduces potential latency and security risks due to its opaque nature. In contrast, P R M allows runtime platform firmware handlers to execute within the O S context, where they benefit from better debuggability, lower complexity, and the ability to be updated dynamically without requiring a system reset.The P R M infrastructure is built upon the A C P I Interpreter, providing a standardized mechanism for invoking runtime platform firmware handlers. These handlers, known as P R M Handlers, are placed in a reserved firmware runtime area—such as the U E F I Runtime Services region—by the B I O S during system boot. Importantly, these handlers are updatable during O S runtime, allowing for targeted online servicing of specific platform functionalities without full firmware updates.The A C P I Interpreter based P R M infrastructure is formally referred to as the P R M Op Region Handler within the A C P I C A or A C P I subsystem. In some implementations, it may be logically realized as an independent driver, commonly called a Bridge Driver. The specification uses the terms Bridge Driver, P R M Op Region Handler, A C P I Driver, A C P I Interpreter, and A C P I C A interchangeably, as they all refer to the same underlying mechanism responsible for mediating between the O S and P R M Handlers.P R M Handlers can be invoked through two distinct pathways. The first is direct invocation from an O S driver, which requires both the driver and the O S A C P I subsystem to be P R M aware. This enables efficient, low latency communication between the operating system and platform firmware, supporting modern, integrated system management designs.The second invocation method occurs from the A S L context. This is used when the O S driver is not P R M aware or relies on legacy mechanisms such as the underscore D S M, or Device Specific Method. In this case, platform events that trigger a System Control Interrupt, or S C I, cause the O S A C P I driver to execute A S L code, which then interfaces with the P R M infrastructure. This approach maintains backward compatibility while still enabling the benefits of P R M execution.Figure three one illustrates the P R M overview, depicting two main invocation paths. On the left, an O S driver invokes A S L methods such as underscore D S M through the A C P I interface. A red X clearly marks that S M I is not used in this path, indicating a deliberate move away from S M I based handling for these operations. This branch represents legacy usage models transitioning to P R M execution via the P R M Op Region interface, which connects to the A C P I slash Bridge Driver.On the right, a P R M aware O S driver performs a direct invocation of the A C P I slash Bridge Driver, representing new usage models designed specifically for the P R M framework. The A C P I slash Bridge Driver encapsulates the P R M T, or P R M Table, a critical data structure that defines the metadata and permissions for P R M Handlers. From this driver, control flows to the P R M Infrastructure and then to the P R M Handlers, shown as a stack of three green blocks, emphasizing their modular and updatable nature. The diagram explicitly labels this block as P R M Handlers in lieu of S M I Handlers, underscoring the architectural intent to replace traditional S M I handlers with a more secure and manageable alternative.Section three point one outlines the core requirements for P R M Handlers. First, they must be capable of executing within the context of a running operating system. This means they operate under O S scheduling and memory management, rather than in an isolated, high privilege mode like S M M.Second, P R M Handlers loaded at boot time must be part of the firmware boot chain of trust. This ensures their authenticity and integrity are verified during the secure boot process, preventing unauthorized or malicious code from being loaded.Third, any internal pointers within a P R M Handler must be fixed up during boot based on the O S virtual address space. This allows the handler to be properly relocated and integrated into the O S’s virtual memory layout, supporting dynamic memory allocation and avoiding address conflicts.Fourth, P R M Handlers must be O S agnostic and must not depend on any operating system provided support A P I’s. This requirement ensures portability across different operating systems and prevents tight coupling that could hinder deployment or updates.Fifth, a P R M Handler must be securely replaceable or over rideable during runtime without requiring a system reset. This enables live updates for bug fixes, security patches, or feature enhancements, which is essential for high availability systems.Sixth, P R M Handlers must be executable by the O S, interruptible, and single threaded. Being interruptible ensures they do not block other system operations, allowing the O S scheduler to maintain responsiveness. The single threaded requirement simplifies design and avoids concurrency issues such as race conditions.Seventh, P R M Handlers shall only access Memory Mapped I O, or M M I O, registers that are explicitly listed in the handler’s parent module’s `RuntimeM M I O Pages` field within the P R M T. This creates a strict access control policy, limiting hardware interaction to only those registers necessary for the handler’s function and preventing unauthorized access to sensitive system resources.Eighth, P R M Handlers must not contain any privileged instructions. This restriction is fundamental to the security model of P R M. By prohibiting instructions that manipulate processor privilege levels, control registers, or other protected state, the handlers are confined to user level or ring zero O S context without the ability to escalate privileges or bypass O S protections. This significantly reduces the attack surface and ensures that even if a handler is compromised, its potential for harm is strictly bounded by the permissions granted through the P R M T and enforced by the O S and hardware.


Platform Runtime Modules, or P R M, represent a critical class of firmware components designed to extend system functionality directly into the operating system runtime environment. Any platform firmware or B I O S environment that satisfies the necessary technical requirements can utilize P R M, with the Unified Extensible Firmware Interface, U E F I, offering particularly efficient support due to its standardized architecture and minimal overhead.While P R M is not restricted exclusively to U E F I based systems, the U E F I specification inherently supports many of the foundational mechanisms required for P R M operation. This compatibility arises primarily from the presence of U E F I Runtime Services, which provide an industry standard method for firmware to expose executable code during operating system runtime. These services define a stable Application Binary Interface, A B I, ensuring that P R M handlers can be invoked under consistent execution conditions, including guaranteed stack size availability. This standardization eliminates the need for platform-specific workarounds and ensures predictable behavior across diverse hardware implementations.Security is another key aspect addressed by the U E F I framework. The U E F I Secure Boot chain-of-trust mechanism provides a built-in method for authenticating P R M modules that are embedded within the firmware boot image. By cryptographically verifying the integrity and origin of these modules, U E F I Secure Boot helps prevent unauthorized or malicious code from executing in the runtime environment, thereby preserving system security throughout the boot and runtime phases.Additionally, U E F I supports runtime virtual address fixups, a crucial capability for enabling firmware-resident code to operate correctly in an operating system environment where virtual memory management is active. During runtime, drivers and firmware components often need to access memory-mapped I O, or M M I O, regions using virtual addresses rather than physical ones. U E F I firmware includes provisions to map physical addresses to their corresponding virtual addresses, allowing P R M handlers to seamlessly interact with hardware resources even after the operating system has enabled paging and virtual memory.A comparison between U E F I based and non-U E F I boot environments highlights the advantages of the U E F I approach. In U E F I systems, P R M handlers execute during O S runtime and are published by the firmware via U E F I Runtime Services, which serve as a standardized, O S independent interface. In contrast, non-U E F I environments lack such a standard mechanism, requiring custom, implementation-specific solutions to expose runtime code to the operating system. This absence of standardization increases complexity and reduces portability.Regarding chain-of-trust, U E F I Secure Boot offers a well-defined, widely adopted authentication framework. Non-U E F I systems typically do not have an equivalent standardized mechanism, leaving security implementation to individual vendors and often resulting in inconsistent or weaker protection. Similarly, for pointer fixups—necessary for translating physical memory addresses into virtual addresses during O S runtime—U E F I provides built-in support, while non-U E F I platforms must implement this functionality ad hoc, if at all.Furthermore, P R M implementations in U E F I environments are inherently O S independent, meaning they can function across different operating systems without modification. In non-U E F I contexts, support is generally implementation specific, tightly coupling the firmware interface to a particular operating system and limiting flexibility.The process of loading and invoking P R M modules follows a structured sequence during system initialization. First, during the pre-operating system boot phase, the firmware scans its flash memory image to discover all P R M modules included in the platform firmware. Once identified, the firmware constructs and publishes the P R M A C P I table, known as the P R M T, which serves as a central descriptor for all available P R M components. This table provides detailed information about each module, including its handlers and associated data structures such as context buffers.Concurrently, the firmware allocates any required memory buffers needed for P R M operation. In some cases, such as with static data buffers, the firmware also initializes the contents of these buffers during boot. This pre-allocation ensures that when the operating system later invokes a P R M handler, all necessary resources are already in place and properly configured.Once the operating system is running, it can invoke P R M handlers through one of two primary mechanisms: direct function calls or Device Specific Methods, D S M. The choice of mechanism depends on the specific use case and the level of abstraction required. Direct calls offer low-latency access to handler functionality, while D S Ms provide a more flexible, scriptable interface through A C P I Source Language, or A S L, code.At the core of this interaction is the P R M T table, an A C P I compliant structure published by the B I O S during boot. This table acts as a discovery and advertisement mechanism, exposing pointers to all P R M handlers so that the operating system can locate and invoke them as needed. The A C P I Interpreter, a component within the operating system kernel, parses the P R M T and uses its contents to route invocations to the appropriate handler. The table is designed with a hierarchical layout, enabling logical organization of complex platform services and facilitating extensibility.Each P R M module encapsulates a set of related handlers centered around a specific platform feature. For example, a Reliability, Availability, and Serviceability, or R A S, module might include handlers for error logging and system diagnostics, while a Non Volatile D Ram, or N V D I M M, module could provide functions for managing persistent memory devices. The P R M T table begins with a standard A C P I header, which includes fields such as Signature, Length, Revision, and Checksum to ensure proper identification and data integrity.The Signature field contains the four-character identifier 'P R M T', allowing the operating system to recognize the table type. The Length field specifies the total size of the table in bytes, enabling correct memory allocation and parsing. The Revision field, set to zero for this version, indicates the current schema version. The Checksum field, computed over the entire table, allows the operating system to verify that the table has not been corrupted during transmission or loading.Following the standard header are identification fields: O E M I D, O E M Table I D, and O E M Revision, which uniquely identify the manufacturer and version of the table. The Creator I D and Creator Revision fields specify the tool or utility that generated the table, aiding in debugging and compatibility assessment.A sixteen-byte field named P R M Platform G U I D provides a unique identifier for the platform itself. This G U I D assists operating system power management, or O S P M, components in targeting specific platforms for runtime updates or feature enablement. While some O S P Ms may use proprietary mechanisms for platform identification, this field offers a standardized alternative.Two critical fields—P R M Module Info Offset and P R M Module Info Count—define the location and number of P R M Module Information structures within the table. The offset specifies the byte distance from the start of the P R M T to the beginning of the first module entry, while the count indicates how many such entries exist. Together, they define a variable-length array of P R M Module Information structures, each describing a distinct P R M module on the platform.Each P R M Module Information Structure contains metadata about a single module. It begins with a two-byte Structure Revision field, indicating the version of this structure format, followed by a two-byte Structure Length field, which specifies the total size of the structure, including any embedded arrays of handler information. This length enables the operating system to correctly traverse the array of module entries.The Identifier field, sixteen bytes in size, holds a G U I D that uniquely identifies the P R M module. This allows the operating system to distinguish between different modules and manage them independently.Within each module structure is an array of P R M Handler Info Structures, the number of which is specified by the P R M Handler Count field. Each Handler Info Structure includes its own revision and length fields, a G U I D that uniquely identifies the handler, a pointer to the executable handler code, and an optional pointer to an A C P I Parameter Buffer.The pointer to the handler provides the entry point for execution, while the optional parameter buffer serves as a shared memory region for passing data between the invoker—such as A S L code—and the handler. The format of the data within this buffer is governed by a contractual agreement between the two parties. For direct invocation scenarios, the invoker is responsible for allocating and populating this buffer, providing flexibility in how arguments are prepared.Additionally, each P R M Module Structure includes a pointer to runtime M M I O Ranges, which refer to memory-mapped I O regions used by the handlers to communicate directly with hardware. These ranges allow the handlers to read from and write to device registers, enabling low-level control and monitoring of platform components.In summary, the P R M T table provides a robust, hierarchical, and extensible framework for exposing platform runtime services to the operating system. By leveraging standardized A C P I mechanisms, G U I D based identification, and pointer-based linking to code and data, it enables secure, efficient, and O S independent interaction between firmware and the operating system, supporting advanced system management, diagnostics, and hardware control throughout the system lifecycle.


The text describes a set of interrelated data structures and mechanisms used in low level system firmware, particularly within a Platform Runtime Module, or P R M, environment. These structures facilitate communication between firmware components, the operating system, and hardware, enabling secure and efficient management of platform resources during system runtime.At the core is the **P R M Module Information Structure**, which acts as a top level descriptor for a P R M module. This structure begins with versioning fields: **Major Revision**, a two byte field at byte offset twenty, indicates the primary version of the P R M module, reflecting significant changes in functionality or interface. Following it at byte offset twenty two is **Minor Revision**, also two bytes, which captures incremental updates. Together, these fields support compatibility checking and evolution tracking.Next is **Handler Count**, a two byte field at byte offset twenty four, specifying the number of **P R M Handler Information Structure** entries associated with this module. This value determines the size of the subsequent array of handler descriptors. Directly after, at byte offset twenty six, is **Handler Info Offset**, a four byte field that provides the byte offset from the start of the P R M Module Information Structure to the beginning of the first **P R M Handler Information Structure**. This indirection allows flexibility in memory layout, supporting alignment requirements or dynamic placement.At byte offset thirty, the **Runtime M M I O Pages** field occupies eight bytes and holds a physical address pointer to a **P R M underscore R U N T I M E underscore M M I O underscore R A N G E S** structure. This structure contains an array of descriptors defining Memory Mapped I O regions that the P R M module may access during runtime. The operating system is responsible for mapping these physical M M I O ranges into virtual memory and populating the corresponding virtual addresses. If no runtime M M I O access is required, this pointer may be N U L L.Finally, starting at byte offset thirty eight, the **Handler Info Structure** array begins. Its total size is the product of **Handler Count** and the size of each **P R M Handler Info Structure**. Each entry in this array describes an individual P R M handler within the module, providing metadata such as identifier, address, and associated data buffers.Each **P R M Handler Information Structure** is detailed in Table four dash three. It starts with **Structure Revision**, a two byte field at byte offset zero, indicating the version of this descriptor structure. Adjacent to it at byte offset two is **Structure Length**, another two byte field, which specifies the total size in bytes of the entire **P R M Handler Info Structure**. This self describing property enables robust parsing, especially when multiple such structures are present in a stream.At byte offset four, the **Identifier** field spans sixteen bytes and contains a G U I D, or Globally Unique Identifier, that uniquely identifies the P R M handler. This allows the operating system or other components to recognize and dispatch to the correct handler logic based on type or function.At byte offset twenty, the **Physical Address** field, eight bytes in size, holds the physical memory address of the P R M handler's code or entry point. This is used by the system to invoke the handler directly in the firmware execution environment.At byte offset twenty eight, the **Static Data Buffer** field is an eight byte physical address pointer to a dedicated data buffer allocated during the B I O S boot phase. This buffer is intended to hold configuration data such as B I O S setup options, board strap settings, or S o C fuse values, and is populated by the firmware before runtime. A pointer to this buffer is passed to the handler upon invocation. This pointer may be N U L L if no static data is required.Additionally, at byte offset thirty six, the **Acpi Parameter Buffer** field, also eight bytes, holds a physical address pointer to a parameter buffer used exclusively when the handler is invoked via A S L, or A C P I Source Language. This buffer facilitates parameter passing between A S L methods and the P R M handler. Like the static data buffer, it is allocated during the firmware boot environment and may be updated at runtime by A S L code. If A S L invocation is not used or no parameters are needed, this pointer may be N U L L.Section four point two elaborates on the two primary buffer types used by P R M handlers.The **Static Data Buffer**, described in subsection four point two point one, is allocated during the B I O S boot phase. While its contents and size are implementation specific, its header follows a standardized format defined in Table four dash four: **P R M Static Data Buffer Structure**. The header begins with a **Signature** field at byte offset zero, four bytes long, containing the ASCII characters 'P R M S'. This acts as a magic number to validate the buffer's type and integrity. Following it at byte offset four is the **Length** field, also four bytes, which specifies the total size of the buffer, including the header. The actual data payload starts at byte offset eight and varies in length depending on the module's needs. This header design enables safe and reliable parsing of the buffer contents by the handler.Subsection four point two point two covers the **Acpi Parameter Buffer**, which is used only in the A S L invocation path. Its internal format is a contract between the A S L caller and the P R M handler, ensuring consistent interpretation of the data. The structure of this buffer is defined in Table four dash five: **P R M A C P I Data Buffer Structure**. It mirrors the static data buffer in layout: the **Signature** field at byte offset zero contains 'P R M P', identifying it as an A C P I parameter buffer. The **Length** field at byte offset four, four bytes in size, specifies the total buffer size including the header. The **Data** field begins at byte offset eight and contains the variable length payload specific to the P R M module. If no parameter buffer is provided, a N U L L pointer is passed to the handler.Subsection four point two point three addresses **Module Runtime M M I O Ranges**. A P R M module must declare any M M I O regions it intends to access by creating an array of **P R M underscore M O D U L E underscore R U N T I M E underscore M M I O underscore R A N G E** descriptors. A pointer to this array is passed to the handler via the **Runtime M M I O Pages** field. Each descriptor, detailed in Table four dash six, consists of three fields. The **Physical Base Address**, eight bytes at byte offset zero, specifies the starting physical address of the M M I O range. The **Virtual Base Address**, eight bytes at byte offset eight, is populated by the operating system with the corresponding virtual address mapping. This allows the handler to access the hardware through virtual memory once the O S has set up the page tables. The **Length** field, four bytes at byte offset sixteen, specifies the size of the M M I O region in bytes.This cooperative model ensures that the firmware declares its hardware access requirements, while the operating system retains control over virtual memory management, enforcing memory protection and isolation. The separation of physical and virtual addressing reflects modern memory management principles, where hardware resources are abstracted through virtualization for security and flexibility.In summary, these structures form a comprehensive framework for low level system firmware to expose runtime capabilities, manage hardware access, and exchange data with both the operating system and A C P I components. They emphasize versioning, self describing layouts, standardized headers, and clear ownership of responsibilities between firmware and operating system. The use of G U I D s, magic signatures, and length fields enhances robustness, while pointer indirection and variable length payloads provide flexibility. These mechanisms are essential for enabling secure, portable, and maintainable platform runtime services in complex computing environments.


Four point two point three point two P R M Module Runtime M M I O Ranges.This structure defines an array of P R M Module Runtime M M I O Range structures, which are declared by a P R M module and may be used by a P R M handler within that module. The structure serves as a declarative mechanism for specifying the memory mapped I O regions required for runtime operation, enabling the system firmware or operating system to properly configure access to hardware resources.Table four dash seven, titled P R M Module Runtime M M I O Ranges Structure, outlines the layout of this data structure in memory. It consists of two primary fields: Count and Runtime M M I O Range.The first field, Count, occupies eight bytes and is located at byte offset zero. This field specifies the number of P R M Module Runtime M M I O Range elements that immediately follow the structure header. By using an eight byte field for the count, the structure supports a very large number of entries, consistent with systems requiring fine grained or extensive M M I O resource declarations. This variable length design allows the P R M module to declare only the M M I O ranges it actually needs, avoiding fixed size allocations that could lead to inefficiency or inflexibility.The second field, Runtime M M I O Range, begins at byte offset eight and represents an array of P R M Module Runtime M M I O Range structures. The number of elements in this array is determined by the value stored in the Count field. Each individual element in the array describes a specific memory mapped I O region used by the P R M module. While the exact layout of each P R M Module Runtime M M I O Range is not detailed here, such structures typically include information such as the base physical address of the M M I O range, its size in bytes, and access permissions or memory attributes like cacheability and read write semantics.Memory mapped I O is a foundational concept in modern computer architecture, where hardware device registers and control buffers are mapped into the processor's physical address space. This allows the C P U to interact with peripherals using standard load and store instructions, rather than requiring dedicated I O instructions. As a result, the same memory management unit, or M M U, mechanisms that apply to regular memory—such as virtual address translation, access protection, and caching policies—can also be applied to device access, enhancing both performance and security.The P R M Module Runtime M M I O Ranges structure acts as a formal interface between the P R M module and the system software responsible for setting up the runtime environment. It enables declarative resource management, where the module explicitly states its hardware interface requirements. This is essential for the operating system or firmware to establish correct memory mappings, prevent address space conflicts between devices, and ensure secure and reliable access to hardware during system operation. The fixed byte offsets and lengths ensure predictable memory layout, which is critical for correct interpretation by both software and firmware components, particularly in sixty four bit systems where alignment and structure padding must be strictly observed.Moving to section five, Invocation of P R M Handlers.As previously described, P R M handlers can be invoked through two distinct mechanisms. The first is a direct call from an O S driver, which is possible when both the operating system driver and the O S A C P I subsystem are P R M aware. The second is invocation from A S L context, which occurs when the O S driver is not P R M aware and instead relies on the underscore D S M, or Device Specific Method, mechanism, or when platform events trigger a System Control Interrupt, or S C I, that invokes an underscore L x x method defined in A S L.Section five point one compares direct call versus A S L based invocation. For P R M aware operating systems and drivers, a direct call is recommended and preferred for several key reasons.First, using underscore D S M introduces a programming dependency into the system A C P I firmware. Unlike purely declarative A C P I tables that describe hardware capabilities, underscore D S M methods contain executable A M L logic. This means the firmware must actively manage and update the Acpi Parameter Buffer on behalf of the O S driver when invoking a P R M handler. Debugging such logic requires an A M L debugger, and any changes to the A S L code necessitate a full system reboot to reload the updated firmware, making development and maintenance more cumbersome.Second, underscore D S M limits the O S driver's control over interactions with the P R M module. In a direct call scenario, the O S driver can explicitly invoke P R M module update lock and unlock A P I s to protect critical sections of code, ensuring atomicity and data integrity during P R M operations. In contrast, with underscore D S M, this synchronization must be handled entirely within the firmware, removing control from the driver. Similarly, in a direct call, the O S driver can dynamically allocate and populate a Parameter Buffer to pass data to the P R M handler. With underscore D S M, data sharing is restricted to a fixed size buffer allocated by firmware during boot, which is populated by A M L code. If a P R M handler update requires a new parameter layout or additional data, the A S L code must be modified and the system rebooted. In a direct call, the O S driver manages the buffer directly, allowing for runtime flexibility without requiring firmware changes.Third, underscore D S M invocation incurs higher performance overhead due to the need to execute A M L bytecode within the A C P I interpreter. This interpretive execution is inherently slower than a direct call to native firmware code, introducing latency and reducing efficiency, especially in time sensitive operations.Despite these drawbacks, underscore D S M remains widely used in existing systems as a standardized abstraction for invoking platform firmware services. To maintain backward compatibility with this large installed base, the underscore D S M invocation path is retained. Additionally, certain hardware events—such as thermal alerts, power state transitions, or P C I E hot plug events—can generate an S C I that triggers an underscore L x x method in A S L, which in turn can invoke a P R M handler. This pathway is essential for event driven firmware responses that originate outside the scope of a specific device driver.Section five point two provides an overview of the invocation mechanism. The caller—whether an O S driver performing a direct call or A S L code executing in firmware context—passes specific information to the A C P I Bridge Driver.The first piece of information is the G U I D of the P R M handler to be invoked. This Globally Unique Identifier ensures that the correct handler is selected in systems that may host multiple P R M modules with overlapping functionality.The second piece of information is the Parameter Buffer. In the case of a direct call, the caller provides a pointer to this buffer, which it has allocated and populated with relevant data. In the case of an A S L based call, the A C P I Bridge Driver extracts the Acpi Parameter Buffer pointer from the P R M Table, or P R M T. If both are present, the directly supplied Parameter Buffer takes precedence, allowing the caller to override default parameters.The A C P I Bridge Driver then performs several critical steps to prepare for handler invocation.Step one: It identifies the P R M Handler pointer that corresponds to the provided G U I D. This involves a lookup in a table or registry of known P R M handlers.Substep a: Once the handler pointer is identified, it is converted from a physical address to a virtual address. This conversion is necessary because the operating system operates in a virtual memory environment. The A C P I Bridge Driver, running within the O S kernel, must access the handler using virtual addressing, which requires proper mapping through the memory management unit.Step two: The driver extracts the Static Data Buffer pointer and the Runtime M M I O Ranges pointer associated with the P R M module. These pointers reference critical data and hardware interface regions required by the handler.Using this information, the driver constructs a Context Buffer, which encapsulates the execution environment for the P R M handler. This buffer is defined in Table five dash one, titled Context Buffer Structure.Step three: The Context Buffer is passed to the P R M handler as part of the invocation.Step four: For A S L based calls, the driver extracts the Acpi Parameter Buffer pointer from the P R M T. For direct calls, the Parameter Buffer pointer is taken directly from the caller's input, and the Acpi Parameter Buffer is ignored.Step five: The P R M handler is invoked using a standardized calling convention. The function signature is defined as follows: E F I Status P R M Export A P I, followed by a function pointer named P R M Handler. This function accepts two input parameters. The first is an optional void pointer to the Parameter Buffer, which contains caller supplied data. The second is an optional pointer to a P R M Module Context Buffer, which contains system provided context such as resource pointers and configuration data. The E F I Status return value allows the handler to report success or specific error conditions back to the caller, enabling robust error handling.Section five point three details Direct Invocation. The A C P I Bridge Driver exposes an I O C T L interface—Input Output Control—that can be called by a P R M aware O S driver. Through this I O C T L, the driver passes the G U I D of the target P R M handler and a pointer to its Parameter Buffer. This mechanism enables tight integration between the operating system and platform firmware, allowing the O S to directly manage and respond to hardware level operations. It is noted that Direct Invocation is intended for future use in environments where the O S A C P I subsystem, O S drivers, and B I O S firmware are all P R M compatible, signaling a shift toward more dynamic and flexible platform management.Section five point four covers A S L underscore D S M Based Invocation. To enable runtime code execution from A S L, a bridging mechanism is required. A S L supports OpRegion handlers, which define addressable regions that A C P I methods can access. The P R M framework extends this by introducing a new OpRegion type named P R M. This allows A S L code to directly interact with P R M modules through a standardized interface. The OpRegion handler is synchronous, meaning the A C P I interpreter waits for the P R M handler to complete before continuing execution. This ensures predictable control flow but may introduce latency in time critical scenarios. Further details on the A C P I specific structures used for P R M support are provided in the D S M invocation section of the appendix.Section five point five describes the Context Buffer in greater detail. The Context Buffer is a well defined, per handler data structure that describes the resources available to a P R M handler during its execution. It is allocated by the operating system, which is also responsible for converting any physical addresses within it to virtual addresses, ensuring compatibility with the O S memory model. This buffer serves as the execution context for the handler, providing access to static data, M M I O ranges, and other essential resources.Table five dash one, Context Buffer Structure, defines the layout of this buffer. It contains a single documented field: Signature. This field is four bytes long and located at byte offset zero. It contains the ASCII characters P R M C, serving as a magic number or signature that identifies the structure as a valid P R M Module Context Buffer. This signature allows the P R M handler and system software to verify the integrity and type of the buffer upon receipt, preventing misinterpretation of memory and enabling early detection of errors. The presence of this signature at a fixed offset ensures consistent parsing across different implementations and platforms.


The Platform Runtime Management, or P R M, Module Context Buffer is a structured data container used to convey configuration and operational parameters from the operating system to firmware-level handlers during runtime. This buffer is essential for enabling secure and efficient communication between the O S and platform-specific management code, ensuring that the necessary contextual information is available when executing low-level operations.The structure begins with the Revision field, which occupies two bytes at offset zero and is intended to expand to four bytes in future implementations. This field indicates the version of the P R M Module Context Buffer structure itself, allowing for backward and forward compatibility as the specification evolves. A higher revision number signals the presence of additional or modified fields, enabling the system to interpret the buffer correctly based on its version.Following this is the Reserved field, which currently uses two bytes starting at offset two, with a planned expansion to six bytes. This field is reserved for future use or for alignment purposes, ensuring that subsequent fields are properly aligned in memory according to architectural requirements. It must be ignored by software implementations and may be zero-initialized.At offset four, the Identifier field spans sixteen bytes and contains a Globally Unique Identifier, or G U I D, that uniquely identifies the P R M handler associated with this context buffer. This G U I D serves as a key for routing and dispatching operations to the correct handler implementation. Although the current size is sixteen bytes, the target size is eight bytes, suggesting a potential future optimization or reinterpretation of this field, possibly as a pointer or truncated identifier.Next is the StaticDataBuffer field, located at offset twenty, occupying eight bytes. This field is a virtual address pointer labeled as P R M underscore D A T A underscore B U F F E R, pointing to a static data buffer allocated for the P R M handler. This buffer is intended to be populated during the firmware boot environment, prior to O S runtime, and contains configuration data that remains constant throughout execution. The use of a virtual address implies that memory management is active when this pointer is accessed, requiring translation via the Memory Management Unit. If no static data is required, this pointer may be N U L L, and P R M handler code must be designed to check for and handle this condition gracefully.At offset twenty eight, the RuntimeMmioRanges field occupies another eight bytes and is labeled P R M underscore M O D U L E underscore C O N F I G underscore R U N T I M underscore M M I O underscore R A N G E S. This is a virtual address pointer to an array of P R M runtime M M I O range structures. Each structure describes a Memory Mapped I O, or M M I O, physical address range that has been mapped into virtual memory for access during O S runtime. These mappings allow the P R M handler to directly interact with hardware registers and device memory without relying on traditional I O port instructions. Like the StaticDataBuffer, this pointer is set during the firmware boot environment and may be N U L L if no runtime M M I O access is needed. The handler must validate this pointer before dereferencing it.The total size of the Context Buffer is forty bytes in its current form, with potential future expansion to accommodate larger fields. This buffer is allocated and constructed by the O S Bridge Driver, which retrieves the necessary information from the P R M T, or Platform Runtime Management Table, an A C P I defined table that describes available P R M modules and their associated resources. Specifically, the Bridge Driver uses the StaticDataBuffer and RuntimeMmioPages entries from the P R M T to populate the corresponding pointers in the Context Buffer. If any of these entries are absent or invalid in the A C P I table, the Bridge Driver passes a N U L L pointer to the P R M handler. Therefore, robust P R M handler implementations must include null pointer checks and alternative execution paths to ensure reliability under all conditions.Figure five dash one illustrates the invocation model for P R M handlers. It shows two primary pathways by which an O S Driver, such as a R A S Handler for Reliability, Availability, and Serviceability, can trigger a P R M operation.The first path is labeled Invocation through A C P I. In this scenario, the O S Driver calls an A C P I underscore D S M, or Device Specific Method, which is a vendor-defined A C P I function. This method then invokes a P R M Operation Region, passing a G U I D to identify the target handler and a pointer to a parameter buffer containing input data. A red cross over the S M I, or System Management Interrupt, path indicates that this invocation mechanism explicitly avoids entering System Management Mode. This design choice enhances transparency and reduces latency, as S M I handlers operate in a privileged, opaque environment that can interfere with O S scheduling and debugging.The second path is a Direct Invocation, where the O S Driver directly calls the A C P I slash Bridge Driver, again providing a G U I D and a parameter buffer pointer. This bypasses the A C P I interpreter layer and allows for more direct control, potentially improving performance for frequently used operations.In both cases, the A C P I slash Bridge Driver acts as an intermediary. Upon receiving an invocation, it consults the P R M T to gather the necessary configuration data and constructs the Context Buffer. It then invokes the appropriate P R M handler by calling a function pointer, passing three arguments: the parameter buffer from the O S Driver, the newly constructed Context Buffer, and the handler's own function pointer. This invocation is represented as asterisk P R M underscore H A N D L E R, open parenthesis, asterisk ParamBuffer, comma, asterisk ContextBuffer, close parenthesis, indicating a function call through a pointer with two structured arguments.The P R M Handlers themselves are depicted as a stack of three green blocks, symbolizing modular, layered firmware components that can be independently loaded and executed. This architectural separation enables fine-grained updates and enhances system maintainability.Moving to the software organization of P R M components, the system is structured in three hierarchical levels of increasing specificity. At the top is the P R M interface, which represents the complete set of firmware functionalities exposed to the O S at runtime. This interface abstracts the underlying complexity and provides a unified A P I for platform management.Beneath the interface are P R M modules, which are independently updatable packages containing one or more P R M handlers. Each module is a self-contained unit that can be authored and distributed separately by Original Equipment Manufacturers, or O E M, and Independent Hardware Vendors, or I H V. This modularity supports targeted updates and allows different vendors to contribute to the platform's runtime management capabilities without interfering with each other.At the lowest level are P R M handlers, each implementing a single, atomic function identified by a unique G U I D. These handlers are the executable units that perform specific tasks such as error logging, power state transitions, or hardware diagnostics.The format of a P R M module is based on the P E slash C O F F, or Portable Executable slash Common Object File Format, standard. This format is widely used in executable files and dynamic libraries, providing a well-defined structure for code, data, and metadata. A P R M compliant P E slash C O F F image must include specific characteristics to be recognized as a valid module.One key feature is the Optional Header, which includes the MajorImageVersion and MinorImageVersion fields. These allow the O S loader to inspect the module's version using filesystem A P I s without loading it into memory, enabling version comparison and update decisions based on file metadata alone.Another critical component is the dot edata section, which contains export information used for dynamic linking. Within this section, the P R M Module Export Descriptor is a mandatory structure that describes the module and lists its contained handlers. This descriptor must be present for the image to be considered a valid P R M module. It must also have a valid signature and be named exactly PrmModuleExportDescriptor.The P R M Module Export Descriptor structure begins with the Signature field at byte offset zero, eight bytes long, containing the ASCII string P R M underscore M E D T. This acts as a magic number to confirm the structure's identity. At offset eight, the Revision field, two bytes in size, specifies the version of the descriptor structure itself.At offset ten, the HandlerCount field, also two bytes, indicates how many P R M Handler Export Descriptors are included in the subsequent array. This count determines the length of the variable-sized HandlerExportDescriptorStructure array that follows.At offset twelve, the PlatformGuid field, sixteen bytes in length, contains a G U I D that identifies the specific hardware platform for which this module is intended. This ensures that a module is only loaded on compatible systems, preventing misconfiguration or execution on unintended platforms.At offset twenty eight, the Identifier field, another sixteen byte G U I D, uniquely identifies the P R M module itself, distinct from the platform it targets. This allows multiple modules to exist for the same platform while maintaining individual identity and version control.Finally, starting at offset forty four, the HandlerExportDescriptorStructure array contains one entry for each handler in the module. Each entry maps a handler's G U I D to its ordinal number, enabling efficient lookup by index rather than by string comparison. This improves performance during handler invocation.The dot text section of the P E slash C O F F image contains the actual executable code for the P R M handlers. The Relative Virtual Addresses, or R V A s, of each handler's entry point are computed at compile time and stored in the export table, allowing the loader to locate and call them after the image is loaded.A critical requirement for P R M modules is the presence of a valid relocation table. This allows the P R M loader to load the module at a dynamic base address, avoiding conflicts with other loaded images. Without relocations, the module would be position-dependent and could only be loaded at a fixed address, which is impractical in modern virtual memory systems.In summary, the P R M architecture is designed for modularity, extensibility, and runtime flexibility. The Context Buffer provides essential configuration data to handlers, the Bridge Driver orchestrates invocation and context construction, and the P E slash C O F F based module format enables secure, versioned, and dynamically loadable firmware components. The use of G U I D s for identification, combined with structured metadata and robust error handling, ensures reliable operation across diverse platforms and update scenarios.


Six point one point one point two, P R M Handler Export Descriptor Structure.The structure of the P R M Handler Export Descriptor is defined by two primary fields: Handler G U I D and Handler Name. This descriptor serves as a bridge between a unique binary identifier and a human readable label for a specific Platform Runtime Mechanism handler.The first field, Handler G U I D, occupies sixteen bytes beginning at byte offset zero. This G U I D is a one hundred twenty eight bit globally unique identifier that provides an unambiguous reference to a specific P R M handler. It maps directly to the corresponding handler name within the same descriptor, ensuring that each handler can be uniquely identified across different systems and software components. The use of a fixed sixteen byte length guarantees consistent parsing and alignment in memory, which is essential for reliable firmware and operating system interactions.Following the G U I D, at byte offset sixteen, is the Handler Name field, which spans one hundred twenty eight bytes. This field contains a null terminated or padded string that represents the human readable name of the P R M handler. The name is intended for diagnostic, logging, or administrative purposes, allowing developers and system tools to identify the handler without requiring interpretation of the raw G U I D. The fixed size ensures predictable memory layout and simplifies allocation, though it may result in unused padding if the actual name is shorter than the maximum allowed length. Together, the pairing of a cryptographically unique G U I D with a descriptive name enables both machine level precision and user level clarity in system management.Six point two, P R M Module Loader.The P R M module loader is a software component responsible for managing the lifecycle of P R M modules within the system. Its responsibilities include four key actions: first, authenticating P R M module binary images; second, validating that the image complies with the architectural and functional requirements specified in the document; third, loading the P R M module into a valid memory address range that is executable by the host operating system; and fourth, updating relevant system data structures to make the P R M module available for use by other system components.Authentication involves verifying the integrity and origin of the binary, typically through cryptographic means such as digital signature validation using trusted root keys and hash verification to detect tampering. This step is critical for maintaining the security and trustworthiness of the system, especially when loading code that operates in a privileged runtime environment.Validation ensures that the binary conforms to expected structural and behavioral standards. This may include checking version compatibility, verifying metadata, confirming adherence to the required binary format, and ensuring compliance with the Application Binary Interface expected by the system. This process prevents malformed or incompatible modules from being loaded, thereby avoiding potential system instability or undefined behavior.Loading the module requires allocating executable memory, copying the binary content into that region, and configuring the memory management unit to mark the region as executable while preserving memory protection boundaries. The allocated memory must reside within an address range accessible and permissible for execution by the host operating system.Finally, the loader updates system data structures such as dispatch tables, service registries, or control blocks to register the newly loaded module. These updates allow other components to discover and invoke the services provided by the P R M module, effectively integrating it into the system’s operational framework.Six point two point one, Firmware P R M Loader.The baseline P R M module is distributed as part of the platform firmware image, and its loading is managed by a firmware based P R M loader. This loader operates during the early stages of system boot, typically as a component within the B I O S or U E F I firmware environment, such as a U E F I D X E driver. It executes before the operating system is initialized, making it suitable for establishing foundational runtime services.The P R M module image is usually stored on the same non volatile storage device that holds the system boot firmware, such as a flash memory chip on the motherboard. However, the specification allows for loading from alternative storage media, including external drives or network sources, providing flexibility in deployment and update scenarios.A distinctive responsibility of the firmware P R M loader is the creation and publication of the P R M T A C P I table. This table is dynamically generated based on the P R M modules discovered and successfully loaded during the boot process. The P R M T table is then made available to the operating system through the A C P I interface, enabling the O S to enumerate and interact with the available P R M handlers. This mechanism ensures standardized, cross platform compatibility and allows the operating system to manage platform specific runtime functionalities in a consistent manner.Six point two point two, O S P R M Loader.The O S P R M loader enables updates to P R M modules during operating system runtime, allowing modifications to platform runtime functionality without requiring a system reboot. This capability supports continuous operation and high availability, particularly in enterprise or mission critical environments where downtime must be minimized.When a P R M update is initiated at runtime, an operating system level software component assumes the role of the P R M loader. This component must enforce two primary requirements. First, P R M updates must be applied in a monotonically increasing version sequence. That is, an update with a version number less than or equal to the currently installed version must be rejected. This rule prevents accidental or malicious downgrades, ensuring that the system state progresses forward in a controlled and secure manner.Second, the update process must be designed to minimize disruption to P R M functionalities that are in use by other operating system components. This implies the use of atomic update techniques, hot swapping mechanisms, or shadowing strategies that allow the transition between old and new module versions to occur with minimal or zero downtime.An important limitation of the O S P R M loader is that it can only replace existing P R M modules that were originally published during the firmware boot phase and registered in the P R M T A C P I table. It cannot introduce new P R M handlers that were not previously declared by the firmware. This restriction ensures that the firmware retains authoritative control over the initial set of available platform services, preserving system integrity and preventing unauthorized expansion of the runtime interface surface.Six point three, P R M Handler.A P R M handler is a function contained within a P R M module. It represents a callable entry point that provides a specific runtime service or functionality to the system.Six point three point one, Overview.Each P R M handler must be assigned a unique G U I D by the module author. This G U I D, along with the corresponding function name, must be recorded as a pair in the P R M Module Export Descriptor. This descriptor acts as a manifest that enables the P R M module loader to resolve the G U I D to the physical memory address of the handler function at load time.The resolution process allows the system to dynamically bind callers to the correct handler implementation, supporting modularity and late binding. This mechanism is essential for enabling updates, replacements, and dynamic discovery of services without requiring recompilation of dependent components.Six point three point two, Function Signature.All P R M handlers must adhere to the architecture specific calling convention defined for U E F I Runtime Services in the U E F I specification. This ensures binary compatibility and predictable behavior across different implementations and compilers.The standard function signature for a P R M handler returns an E F I underscore S T A T U S type, indicating the success or failure of the operation through a detailed status code. The function is declared with the P R M underscore E X P O R T underscore A P I keyword, which instructs the compiler to include the function in the module’s export table, making it accessible to external components.The function takes two parameters, both optional and passed by reference as virtual address pointers. The first parameter is Parameter Buffer, a pointer to a V O I D type buffer allocated by the caller. This buffer carries input or output data whose internal structure is defined by a private contract between the caller and the handler. If no data is to be passed, the caller provides a N U L L pointer, and the handler must check for this condition before accessing the buffer.The second parameter is Context Buffer, a pointer to a P R M underscore M O D U L E underscore C O N T E X T underscore B U F F E R. This buffer contains context specific information such as module state, configuration data, or virtual address references to other resources. All addresses contained within the Context Buffer must be virtual addresses, consistent with the virtual memory model used by the operating system and runtime environment. The Context Buffer may be N U L L if no context is available, and the handler must perform a null check before dereferencing it.The E F I underscore S T A T U S return type and the E F I A P I calling convention are adopted directly from the U E F I specification, ensuring consistency with existing runtime service interfaces. The P R M underscore E X P O R T underscore A P I macro ensures that the function is properly exported in the object file, enabling symbol resolution during module loading.Additional requirements for P R M handlers include the use of the P R M underscore E X P O R T underscore A P I macro to place the function into the image’s export table. This is mandatory for any function to be recognized as a publicly accessible P R M handler.The maximum name length for a P R M handler function is one hundred twenty eight bytes. This limit ensures predictable memory usage in symbol tables and prevents potential buffer overflow issues during name resolution or logging operations.Every P R M handler must have a corresponding entry in the P R M Export Descriptor Table. Without such an entry, the handler will not be recognized as a valid service endpoint by the P R M module loader, and thus will not be available for invocation.Functions within the P R M module that are not intended for external use are considered private to the module. These internal functions must not be exported and should not appear in the module’s export table. This encapsulation principle ensures that only designated A P I entry points are exposed, reducing the attack surface, preventing unintended dependencies, and supporting clean module boundaries. By enforcing strict separation between public handlers and private implementation details, the architecture promotes maintainability, security, and long term evolvability of the P R M system.


Seven. Servicable P R M.Over time, a Platform Runtime Mechanism handler, or P R M handler, may require updates for various reasons, including bug fixes, workarounds for hardware or software anomalies, or to enhance the system's runtime capabilities and feature set. These updates are applied at the module level, meaning that it is not possible to update an individual handler in isolation. Any modification necessitates updating the entire P R M Module. Consequently, versioning for P R M components is managed at the module level. Traditionally, such firmware updates would require a system reboot, allowing the new firmware code to be loaded during the next boot sequence from non volatile storage into the system's memory.However, in modern cloud services environments, system reboots are highly disruptive and are avoided whenever possible. Reboots introduce service downtime, complicate orchestration, and degrade availability. Therefore, a mechanism is required to update P R M modules dynamically during operating system runtime, without requiring a system restart.This document outlines a generic framework to enable such runtime updates by extending the Advanced Configuration and Power Interface, or A C P I, Bridge driver with the capability to switch to a new P R M Module image while the system remains operational.Seven point one. High Level Flows.When a new P R M Module update is required, the system B I O S build process generates a new module image, as described in Section six, or retrieves an O S specific format from a designated repository. The generation and delivery of this image are implementation specific and fall outside the scope of this specification.During O S runtime, an O S updater consumes the newly delivered P R M Module. The process proceeds in three main steps. First, the updater parses the P E slash C O F F Export Descriptor structure embedded in the module. This parsing serves two purposes: to confirm that the binary is a valid P R M Module, and to verify that it targets the correct platform. Platform targeting is achieved by matching the P R M Platform G U I D in the module to the PrmPlatformGuid field in the P R M T Table. Some implementations may instead use the E S R T mechanism or another proprietary method for platform validation.Second, the updater loads the P R M module into system memory, typically D Ram, and performs necessary fix ups. These fix ups include address relocation, symbol resolution, and pointer patching to ensure the module integrates correctly into the current runtime memory layout.Third, the updater sends a request to the A C P I Subsystem to update its internal pointers to the P R M handlers, so that subsequent invocations are directed to the new module.Upon receiving this request, the A C P I Subsystem performs a series of checks. First, it determines whether updates are currently locked or allowed. If updates are locked, the new P R M image is staged—held in memory but not activated—until the lock is released. If updates are unlocked, the A C P I Subsystem atomically switches the handler pointers to the new P R M Module, effectively activating the update without interrupting system operation.Seven point one point one. Update Lock slash Unlock.Most P R M Handler invocations are stateless, meaning they do not maintain internal state between calls. This allows updates to be applied between individual invocations. However, certain operations require a sequence of P R M invocations that must complete as an atomic unit. In such cases, a runtime update to the P R M Module must be blocked until the sequence is complete to prevent inconsistencies or failures.An example of such a sequence is Address Range Scrub, or A R S, for persistent memory, as defined in the N V D I M M D S M Interface specification. A R S is a long latency operation involving multiple steps, each implemented as a D S M call that invokes a corresponding P R M Handler.The A R S operation consists of three primary functions:First, Query A R S Capabilities, using Function Index one.Second, Start A R S, using Function Index two.Third, Get A R S Status, using Function Index three.The P M E M Driver initiates the sequence by calling Query A R S Capabilities to determine supported features, then invokes Start A R S to begin the scrubbing process. Since A R S may take a significant amount of time, Start A R S returns immediately after initiating the background task. The driver then periodically polls for completion by calling Get A R S Status.Each of these D S M functions triggers a corresponding P R M Handler. If a P R M Module update were to occur mid sequence, the handlers could be replaced while the operation is in progress, leading to undefined behavior or data corruption.To prevent this, a Lock slash Unlock mechanism is provided as part of the A C P I subsystem. This mechanism is detailed in Section eight point one point two and Table eight one.A D S M Method that initiates a multi step sequence must first invoke a Lock request, as defined in Section eight point two point one, before executing the sequence. At the end of the sequence, it must invoke an Unlock request, as defined in Section eight point two point two.In the A R S example:First, after Query A R S Capabilities is invoked, the A S L code issues a Lock request by passing the P R M Handler G U I D, which corresponds to the D S M U U I D. The A C P I Interpreter identifies the associated P R M Module and locks it, preventing any update from taking effect. Importantly, the P R M Handler itself is not invoked during the Lock operation.Second, any update request received by A C P I while the module is locked is staged but not activated.Third, once the Get A R S Status call returns indicating that the A R S operation is complete, the A S L code invokes the Unlock method, passing the same G U I D. The A C P I Interpreter then unlocks the module, allowing future updates to proceed.If a previous update was staged during the lock period, the A C P I Subsystem may choose to switch to the staged P R M Module at the moment of unlock, completing the update in a safe and atomic manner.The responsibility for invoking Lock and Unlock rests with the entity initiating the sequence—either the D S M method in A S L code or an O S driver in the case of direct invocation. This entity has the necessary context to determine whether the operation is part of a multi step sequence or a standalone, stateless call.An operating system may choose not to support runtime P R M updates at all, relying solely on firmware updates during reboots. Alternatively, it may implement a robust framework to support live updates and minimize downtime. Since this decision is O S specific, the specification does not define a universal implementation. However, the runtime update process in Microsoft Windows is described as a concrete example.Seven point two. Installation in Windows.In the Windows operating system, the runtime update process follows a structured approach.First, during O S runtime, an O S owned updater validates the new P R M Module image for authenticity and integrity. Once validated, it writes the module to a well known location on disk. For example, in Windows, this location is typically `system thirty two backslash P R M backslash modules backslash left curly brace G U I D right curly brace`.Second, the updater parses metadata from the module and persists the following information to the system registry, ensuring it survives reboots:One, the full file path of the P R M module.Two, the module version number.Three, the list of P R M handler G U I D s contained within the module.Third, the updater loads the module into memory, performs fix ups, and sends a request to A C P I to update its handler pointers to the new module.Seven point two point one. Persisting P R M Module Updates Across Reboot slash K S R.After a system reboot or Kernel State Restore, the Windows boot loader, known as winload, reads the system hive from the registry. It checks whether any P R M module updates have been applied beyond the firmware's original base image.For each updated module, winload loads the latest version—determined by the version number stored in the registry—from the on disk location into memory. It then adds the module to the boot start driver list, a mechanism already used for early loaded kernel drivers.This approach leverages existing Memory Manager, or M M, support for relocating drivers in memory, ensuring compatibility with the system's boot time loading infrastructure.After the kernel initializes, the A C P I dot sys driver reinitializes. It reads the loader block, which contains information about the loaded P R M modules, and reconstructs an up to date view of the available P R M handlers.For both cold boot and K S R scenarios, the A C P I interpreter is paused until all P R M updates have been processed. This ensures that no P R M invocations occur with stale or inconsistent handler pointers, maintaining system stability during the critical early boot phase.Seven point three. Rollback.It is essential that platforms supporting P R M functionality provide a rollback mechanism in case an update causes instability or incompatibility. This requirement is analogous to the rollback capability now standard for microcode updates.To simplify the update model, rollback is treated not as a reversal, but as a forward update to a prior known good version. This is accomplished by incrementing the module version number to designate a previous, stable version. Each rollback is thus a new update that reverts behavior to an earlier state, ensuring that all versions are managed uniformly within the versioning system.A diagram titled P R M Module Versioning Update Example illustrates this progression. It shows three states of Module one, labeled Version one, Version two, and Version three. Each version contains the same set of handlers: Handler one, Handler two, and Handler three. Arrows connect the versions sequentially, indicating the flow of updates. The diagram emphasizes that while the module version advances, the exposed handlers remain consistent, supporting API stability and backward compatibility.A critical consideration in rollback scenarios is hardware state. The model assumes that hardware behavior is stateless with respect to P R M updates. However, in practice, a P R M update might set reserved bits in hardware registers, altering the hardware's configuration. If a rollback is performed—such as moving from Version three back to Version two—the system must ensure that any such hardware bits are either reset to a known good state or that their presence does not interfere with the operation of the older P R M Module.This highlights the need for careful design at the hardware software interface. Down level P R M modules must be able to function correctly even if hardware state reflects configurations established by newer versions, ensuring system resilience during version transitions.


Eight. Appendix A: P R M Handler D S M Invocation.There is a significant installed base in the industry that relies on Device Specific Method, or _D S M, mechanisms as an abstraction to invoke platform firmware services. In addition to device hardware interrupts, category three H W S M I s can generate a System Control Interrupt, or S C I, event, which enters the A C P I context via an _L X X method. Therefore, it is essential to provide a mechanism that bridges A C P I Source Language, or A S L, code with the Platform Runtime Mechanism, or P R M, handler to support these invocation scenarios.In essence, the P R M provides a method to execute native machine code from within the A C P I execution environment. A S L serves as the entry point for both software and hardware triggered runtime events. When necessary, A S L invokes the P R M, effectively acting as a proxy for P R M service calls.Eight point one. P R M Op Region Definition.The syntax for the Operation Region construct is defined as follows: Operation Region, followed by a left parenthesis, then four arguments — Region Name, Region Space, Offset, and Length — followed by a right parenthesis. Region Name is a name string that uniquely identifies the region. Region Space is a keyword that specifies the type of address space being accessed. Offset is a term argument representing an integer value that indicates the starting address within the address space. Length is another term argument representing an integer that defines the size of the region in bytes.Accordingly, the P R M Operation Region within the A C P I namespace is declared as: Operation Region, with the arguments [subspace name], Platform R T Mechanism, zero, and one.Here, Region Name is set to [subspace name], a unique identifier for this particular P R M subspace. Region Space must be set to Platform R T Mechanism, which corresponds to operation region type hexadecimal zero B. Offset must be zero, indicating the region starts at the base address. Length must be one, meaning the region spans a single byte.The Platform R T Mechanism operation region supports only one permitted access type: Buffer Access. This means that all reads and writes to this region are performed using a region specific data buffer. Unlike direct memory mapped I O or port I O, Buffer Access requires that data be transferred in complete, atomic units via a structured buffer, ensuring data integrity and simplifying firmware interface design.Eight point one point one. Declaring Fields in the P R M Operation Region.For every Platform R T Mechanism Operation Region, the associated Field declaration must follow the standard Field syntax: Field, followed by a left parenthesis, then Region Name, Access Type, Lock Rule, and Update Rule, followed by a right parenthesis, and then a Field Unit List enclosed in curly braces.For P R M Operation Regions, specific constraints apply. Region Name refers to the previously declared Operation Region, in this case, the one defined with Platform R T Mechanism. Access Type must be set to Buffer Acc, enforcing the use of buffer based data transfers. Lock Rule must be set to No Lock, indicating that access to this region does not require acquisition of the Global Lock for synchronization. This implies that the underlying mechanism either handles synchronization internally or that operations are inherently atomic. Update Rule is not applicable for P R M accesses because each operation is performed in its entirety, ensuring transactional atomicity — the operation either completes fully or not at all.The Field Unit List defines a single field unit of eight bits. The P R M handler is invoked when data is written to this field unit. An example declaration is as follows: Operation Region (P R M R, Platform R T Mechanism, hexadecimal zero, hexadecimal one). Then, Field (P R M R, Buffer Acc, No Lock, Preserve) containing P R M F, eight, enclosed in curly braces.In this example, P R M R is the name of the Operation Region. The Field declaration associates with it using the same name. The access type is Buffer Acc, synchronization is disabled via No Lock, and the Update Rule is Preserve, meaning any bits not explicitly written remain unchanged. P R M F is the name of the field unit, defined as eight bits wide.Eight point one point two. Declaring and Using a P R M Data Buffer.To invoke the P R M Operation Region handler, a buffer object of twenty six bytes must be written to the field unit. This buffer serves a dual purpose: it acts as both the input and the output for the transaction. Similar to protocols such as S M Bus, I P M I, and Generic Serial Bus, the same buffer is used to send a request and receive a response, enabling bidirectional communication through a single data structure.The P R M data buffer is an A S L buffer object that functions as a request and response container for interactions with the P R M handler. Writing this buffer to the P R M field unit triggers the invocation of the handler. Upon completion, the handler populates the buffer with the result, including status codes and any returned data. This bidirectional capability allows the A S L code to capture the outcome of the transaction and perform appropriate error handling when necessary.Table eight dash one. P R M Data Buffer, an A S L Buffer Object.The buffer is structured as follows:Byte offset zero, length one: Data buffer status value. This field is populated by the P R M Operation Region handler and indicates the overall result of the operation. Valid values are:Hexadecimal zero zero: success.Hexadecimal zero one: the P R M handler returned an error. This value is only valid when the command value is zero.Hexadecimal zero two: invalid command value.Hexadecimal zero three: invalid G U I D.Hexadecimal zero four: back to back lock command — an attempt to lock while already in a locked state.Hexadecimal zero five: unlock command called without a prior lock — an attempt to release a lock that was not acquired.Hexadecimal zero six: back to back call to unlock command — an attempt to unlock twice in succession.Hexadecimal zero seven through hexadecimal F F: reserved for future use.Byte offset one, length eight: P R M handler status value. This field is populated by the handler only when the command value is zero. In all other cases, the contents of this field are undefined and must not be interpreted.Byte offset nine, length one: Command value. This field is set by the caller and determines the action to be taken by the P R M handler. Supported values are:Hexadecimal zero zero: run the P R M service associated with the G U I D parameter. This executes the actual service routine.Hexadecimal zero one: start a sequence of P R M calls. This command signals the beginning of a transactional sequence for a specific G U I D. Once started, the P R M module associated with that G U I D must not be updated until the corresponding terminate command is issued. This command does not execute a service; it establishes a protected context for subsequent operations.Hexadecimal zero two: terminate a sequence of P R M calls. This must be called after a start sequence command and signals that the sequence has ended. It allows the P R M module to be safely updated again. Like the start command, this does not invoke a service but closes the transactional context.Hexadecimal zero three through hexadecimal F F: reserved for future command definitions.This structured buffer format enables reliable, stateful communication between A S L and the P R M handler. The use of explicit status codes, conditional field validity, and sequence control commands ensures robustness, error detection, and safe concurrent access to platform runtime services. The design reflects a message based, transactional interface that abstracts low level hardware interactions while preserving the integrity of firmware operations.


The text describes a mechanism within the Advanced Configuration and Power Interface, or A C P I, for enabling communication between the operating system and platform firmware using its source language, A S L, the A C P I Source Language. This interaction is facilitated through a runtime service known as the Platform Runtime Mechanism, or P R M, which allows dynamic invocation of device-specific firmware functions via a standardized interface.At the heart of this system is a Globally Unique Identifier, or G U I D, referred to as the D S M G U I D. This identifier spans from offset ten to offset sixteen within a data structure and is populated by the caller. The D S M G U I D uniquely identifies a Device Specific Method, allowing the operating system to request specific firmware-level operations that are not part of standard hardware abstractions. For the request to be valid, this G U I D must be present in the list of available handlers published by the P R M T table—the Platform Runtime Mechanism Table—which acts as a registry ensuring only authorized and recognized services can be invoked, thus preserving system integrity and security.To manipulate the byte fields within the communication buffer, A S L provides several field creation operators: Create Byte Field, Create Q Word Field, and Create Field. These operators allow structured access to specific regions of a buffer by defining symbolic names for data segments at given offsets. For example, Create Byte Field defines a single byte-sized field, Create Q Word Field defines an eight-byte, or sixty-four-bit, field, and Create Field allows the definition of a field with arbitrary bit length and alignment. By using these constructs, A S L code can read from and write to the buffer using a single store operator, enabling efficient and atomic access to hardware or firmware interfaces.Section eight point two presents an example of how data is written to the P R M data buffer. A control method named R U N S is defined, which takes one argument, Arg zero. This argument is expected to contain a buffer representing the D S M G U I D. Inside the method, a local variable, Local zero, is initialized as a buffer of twenty-six bytes, serving as the communication payload for the P R M service.Within this buffer, several fields are defined. A byte field named P S T A is created at offset hexadecimal zero, likely representing platform status. A Q Word field named U S T A is created at offset hexadecimal one, occupying eight bytes, which may be used to store a large identifier, address, or status code. A byte field named C M D is created at offset hexadecimal nine to hold a command code. Finally, a field named D A T A is defined starting at offset hexadecimal fifty with a length of hexadecimal eighty bits, equivalent to one hundred twenty-eight bits, or sixteen bytes. This field is used to carry the primary data payload.The method then populates the command and data fields. The C M D field is set to zero, indicating a run command, and the D A T A field is assigned the value of Arg zero, effectively passing the D S M G U I D into the payload. To invoke the P R M Operation Region Handler, the contents of Local zero must be written to a designated P R M Operation Region Field Unit. The result from the handler is retrieved by reading the contents of that field unit back into Local zero.An Operation Region named P R M R is defined using the Platform R T Mechanism type, mapped to a hardware or logical address space starting at offset hexadecimal zero with a length of one byte. Within this region, a field named P R M F is defined with a bit length of eight, accessed using Buffer Access mode, with No Lock synchronization and a Preserve write policy. This means that when the field is written, its previous content is preserved unless explicitly overwritten, and no internal locking is applied, implying that external synchronization is managed by the caller or firmware.The invocation of the handler is performed by the statement Local zero equals the result of P R M F being assigned Local zero. This expression writes the Local zero buffer to the P R M F field, triggering the firmware handler to process the request. Upon completion, the handler writes the response back into the same buffer space, which is then read back into Local zero. After this operation, the P S T A and U S T A fields contain the status results. If P S T A is not true, indicating a failure at the platform level, an error handling routine is executed. Similarly, if U S T A is not true, an optional user-level status check is performed. The method concludes by returning the value of P S T A, indicating the overall success or failure of the operation.Section eight point two point one provides an example of locking a P R M transaction. A method named L O C K is defined, also taking one argument, Arg zero, which contains the D S M G U I D. Inside the method, Local zero is initialized as a twenty-six-byte buffer. Fields are defined over this buffer: a byte field named S T A T at offset hexadecimal zero, a byte field named C M D at offset hexadecimal nine, and a field named G U I D starting at offset hexadecimal fifty with a length of hexadecimal eighty bits.The C M D field is set to one, representing a lock command, and the G U I D field is populated with the value from Arg zero. The method then invokes the P R M F handler by assigning Local zero to P R M F and simultaneously capturing the result back into Local zero. The S T A T field now contains the return status of the lock operation. The method returns this status value, allowing the caller to determine whether the lock was successfully acquired.Section eight point two point two describes a method named U L C K, designed to unlock the P R M transaction. This method also takes a single argument, Arg zero, containing the D S M G U I D. Although the body of the method is not fully detailed in the provided text, the implied structure mirrors that of the L O C K and R U N S methods. It would involve initializing Local zero, defining the same field layout, setting the C M D field to a value corresponding to an unlock command—likely two or another designated code—populating the G U I D field with Arg zero, invoking the P R M F handler, and returning the resulting status from the S T A T field.These examples illustrate a structured, low-level protocol for secure and synchronized interaction between the operating system and firmware. The use of G U I Ds enables precise targeting of device-specific services, while the field creation operators provide a high-level abstraction over raw memory, enhancing code clarity and maintainability. The locking and unlocking mechanisms enforce mutual exclusion, ensuring that P R M transactions occur atomically and without interference from concurrent operations. This is essential for maintaining data consistency and system stability when accessing critical platform resources.The overall design reflects a transactional model where each operation is encapsulated in a well-defined buffer, triggered through a standardized interface, and returns status information to enable robust error handling. This layered approach separates the command trigger—handled via the compact P R M F field—from the larger data payload in Local zero, optimizing both performance and modularity. Such patterns are foundational in modern firmware design, particularly in U E F I and B I O S environments, where reliable, secure, and efficient system management is paramount.


Local zero is the P R M data buffer. Local zero is assigned buffer index twenty six, indicating it references a block of twenty six bytes within a larger memory structure. This buffer serves as a shared data area between software and platform firmware, likely part of a Platform Runtime Mechanism interface defined under A C P I specifications.To enable structured access to specific portions of this buffer, byte fields are created at designated offsets. The function create byte field is invoked with three arguments: the buffer Local zero, an offset, and a symbolic name. The first invocation maps a one byte field named S T A T at offset hexadecimal zero — that is, the very beginning of the buffer. This field is intended to hold a status value, typically used to report the outcome of a command operation. The second call defines another one byte field, C M D, located at offset hexadecimal nine, or nine bytes into the buffer. This field is designated for command codes that instruct the firmware or hardware component on the action to perform.Additionally, the function create field is used to define a larger, multi byte region within the same buffer. This call specifies that starting at bit offset hexadecimal fifty — which corresponds to byte offset ten — a field named G U I D is established, spanning hexadecimal eighty bits, or one hundred twenty eight bits, equivalent to sixteen bytes. This size aligns with the standard format of a Globally Unique Identifier. The G U I D field likely serves to identify a specific instance, session, or target for the operation being requested.Following the definition of these fields, the code populates them with appropriate values. The C M D field is assigned the value two, which is documented as representing an unlock command. This implies the software is requesting that a protected resource or interface be unlocked, possibly to allow further configuration or access. Concurrently, the G U I D field is assigned the value of argument zero, suggesting that the caller has passed a unique identifier as input, which is now embedded into the request structure.After setting up the command and its associated identifier, the line Local zero equals open parenthesis P R M F equals Local zero close parenthesis appears to perform a type assignment or casting operation. Here, Local zero — the buffer containing the formatted data — is being interpreted as an instance of P R M F, which may stand for Platform Runtime Mechanism Format. This construct signals that the buffer is now properly structured according to the expected format for P R M operations, making it ready for submission to the firmware interface.Finally, the function returns the value contained in the S T A T field. Although the S T A T field was not explicitly written to in this code segment, its value may have been previously set by a prior operation or could be populated asynchronously by firmware. Returning S T A T allows the caller to immediately check the result or current state of the P R M interface, completing a typical request status exchange pattern.This entire sequence exemplifies a low level data marshaling technique common in firmware and system software development. By overlaying named fields onto a raw memory buffer, developers achieve precise control over data layout while maintaining code readability and type safety. Such patterns are essential in environments where direct memory manipulation is required, such as device drivers, operating system kernels, or embedded systems.Moving to Appendix B, which covers underscore O S C and OpRegion, the discussion shifts to platform level coordination between the operating system and firmware.Section nine point one, Platform Wide O S P M Capabilities, introduces a new bit in the underscore O S C capabilities D Word. The underscore O S C method, or Operating System Capabilities method, is a standardized A C P I mechanism through which the operating system informs the Basic Input Output System, or B I O S, of the advanced features it supports. This handshake allows the firmware to adjust its behavior accordingly, enabling more efficient and modern interfaces while preserving backward compatibility.Specifically, bit twenty one of D Word two is newly designated to indicate operating system support for the Platform Runtime Mechanism. When the O S sets this bit, it declares its ability to interact with P R M services directly. In response, the B I O S can transition from legacy handling mechanisms — such as System Management Interrupts, or S M I — to using the more efficient and scalable P R M interface. S M I based approaches are known for their complexity and performance overhead, so moving away from them is a significant architectural improvement.The table titled Platform Wide underscore O S C Capabilities D Word two lists the interpretation of specific bit ranges. Bit twenty one is marked as reserved for future use, with the clarification that it indicates O S support for P R M. Bits thirty one through twenty two are also reserved and must be set to zero by the operating system. This ensures that undefined bits do not interfere with current or future functionality and maintains a clean, extensible bit field layout for future specification updates.Section nine point two, P R M Operation Region, defines a new operation region address space identifier for the Platform Runtime Mechanism. In A C P I, an operation region is a logical construct that maps a range of addresses to a specific hardware or firmware interface, allowing the O S to perform reads and writes that are interpreted as control or data operations by the platform.The table Operation Region Address Space Identifiers Value assigns the hexadecimal value zero B — that is, eleven in decimal — to the name Platform R T Mechanism. This identifier will be used in A C P I source language definitions to declare regions associated with P R M services. The accompanying note states that this identifier is reserved for future use by a mechanism developed in the code first approach. This indicates that while the identifier is formally reserved in the specification, the exact implementation details of the P R M interface are still under development and will be shaped by practical coding, testing, and integration efforts rather than being fully defined in advance.The code first approach reflects a modern software engineering practice where real world implementation drives the refinement of specifications. This allows for greater adaptability, performance optimization, and discovery of edge cases during development. By reserving the identifier early, the specification ensures that no other mechanism will conflict with it, providing a stable foundation for ongoing development.Together, these elements — the structured buffer manipulation, the underscore O S C capability bit, and the operation region identifier — form a cohesive framework for enabling advanced runtime interactions between the operating system and platform firmware. They represent a shift from interrupt driven, opaque firmware interfaces to a more transparent, memory mapped, and software controlled model, enhancing both system performance and maintainability.


